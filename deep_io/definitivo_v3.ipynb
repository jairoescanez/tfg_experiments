{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versión no tiene nada especial, la red simplemente devuelve un vector x que supongo yo que es el minimo del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import deep_inv_opt as io\n",
    "import deep_inv_opt.plot as iop\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 0  # Let the plots flow!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5000],\n",
       "        [-1.4941],\n",
       "        [-1.4883],\n",
       "        [-1.4824],\n",
       "        [-1.4765],\n",
       "        [-1.4706],\n",
       "        [-1.4648],\n",
       "        [-1.4589],\n",
       "        [-1.4530],\n",
       "        [-1.4472],\n",
       "        [-1.4413],\n",
       "        [-1.4354],\n",
       "        [-1.4295],\n",
       "        [-1.4237],\n",
       "        [-1.4178],\n",
       "        [-1.4119],\n",
       "        [-1.4061],\n",
       "        [-1.4002],\n",
       "        [-1.3943],\n",
       "        [-1.3885],\n",
       "        [-1.3826],\n",
       "        [-1.3767],\n",
       "        [-1.3708],\n",
       "        [-1.3650],\n",
       "        [-1.3591],\n",
       "        [-1.3532],\n",
       "        [-1.3474],\n",
       "        [-1.3415],\n",
       "        [-1.3356],\n",
       "        [-1.3297],\n",
       "        [-1.3239],\n",
       "        [-1.3180],\n",
       "        [-1.3121],\n",
       "        [-1.3063],\n",
       "        [-1.3004],\n",
       "        [-1.2945],\n",
       "        [-1.2886],\n",
       "        [-1.2828],\n",
       "        [-1.2769],\n",
       "        [-1.2710],\n",
       "        [-1.2652],\n",
       "        [-1.2593],\n",
       "        [-1.2534],\n",
       "        [-1.2476],\n",
       "        [-1.2417],\n",
       "        [-1.2358],\n",
       "        [-1.2299],\n",
       "        [-1.2241],\n",
       "        [-1.2182],\n",
       "        [-1.2123],\n",
       "        [-1.2065],\n",
       "        [-1.2006],\n",
       "        [-1.1947],\n",
       "        [-1.1888],\n",
       "        [-1.1830],\n",
       "        [-1.1771],\n",
       "        [-1.1712],\n",
       "        [-1.1654],\n",
       "        [-1.1595],\n",
       "        [-1.1536],\n",
       "        [-1.1477],\n",
       "        [-1.1419],\n",
       "        [-1.1360],\n",
       "        [-1.1301],\n",
       "        [-1.1243],\n",
       "        [-1.1184],\n",
       "        [-1.1125],\n",
       "        [-1.1067],\n",
       "        [-1.1008],\n",
       "        [-1.0949],\n",
       "        [-1.0890],\n",
       "        [-1.0832],\n",
       "        [-1.0773],\n",
       "        [-1.0714],\n",
       "        [-1.0656],\n",
       "        [-1.0597],\n",
       "        [-1.0538],\n",
       "        [-1.0479],\n",
       "        [-1.0421],\n",
       "        [-1.0362],\n",
       "        [-1.0303],\n",
       "        [-1.0245],\n",
       "        [-1.0186],\n",
       "        [-1.0127],\n",
       "        [-1.0068],\n",
       "        [-1.0010],\n",
       "        [-0.9951],\n",
       "        [-0.9892],\n",
       "        [-0.9834],\n",
       "        [-0.9775],\n",
       "        [-0.9716],\n",
       "        [-0.9658],\n",
       "        [-0.9599],\n",
       "        [-0.9540],\n",
       "        [-0.9481],\n",
       "        [-0.9423],\n",
       "        [-0.9364],\n",
       "        [-0.9305],\n",
       "        [-0.9247],\n",
       "        [-0.9188],\n",
       "        [-0.9129],\n",
       "        [-0.9070],\n",
       "        [-0.9012],\n",
       "        [-0.8953],\n",
       "        [-0.8894],\n",
       "        [-0.8836],\n",
       "        [-0.8777],\n",
       "        [-0.8718],\n",
       "        [-0.8659],\n",
       "        [-0.8601],\n",
       "        [-0.8542],\n",
       "        [-0.8483],\n",
       "        [-0.8425],\n",
       "        [-0.8366],\n",
       "        [-0.8307],\n",
       "        [-0.8249],\n",
       "        [-0.8190],\n",
       "        [-0.8131],\n",
       "        [-0.8072],\n",
       "        [-0.8014],\n",
       "        [-0.7955],\n",
       "        [-0.7896],\n",
       "        [-0.7838],\n",
       "        [-0.7779],\n",
       "        [-0.7720],\n",
       "        [-0.7661],\n",
       "        [-0.7603],\n",
       "        [-0.7544],\n",
       "        [-0.7485],\n",
       "        [-0.7427],\n",
       "        [-0.7368],\n",
       "        [-0.7309],\n",
       "        [-0.7250],\n",
       "        [-0.7192],\n",
       "        [-0.7133],\n",
       "        [-0.7074],\n",
       "        [-0.7016],\n",
       "        [-0.6957],\n",
       "        [-0.6898],\n",
       "        [-0.6840],\n",
       "        [-0.6781],\n",
       "        [-0.6722],\n",
       "        [-0.6663],\n",
       "        [-0.6605],\n",
       "        [-0.6546],\n",
       "        [-0.6487],\n",
       "        [-0.6429],\n",
       "        [-0.6370],\n",
       "        [-0.6311],\n",
       "        [-0.6252],\n",
       "        [-0.6194],\n",
       "        [-0.6135],\n",
       "        [-0.6076],\n",
       "        [-0.6018],\n",
       "        [-0.5959],\n",
       "        [-0.5900],\n",
       "        [-0.5841],\n",
       "        [-0.5783],\n",
       "        [-0.5724],\n",
       "        [-0.5665],\n",
       "        [-0.5607],\n",
       "        [-0.5548],\n",
       "        [-0.5489],\n",
       "        [-0.5431],\n",
       "        [-0.5372],\n",
       "        [-0.5313],\n",
       "        [-0.5254],\n",
       "        [-0.5196],\n",
       "        [-0.5137],\n",
       "        [-0.5078],\n",
       "        [-0.5020],\n",
       "        [-0.4961],\n",
       "        [-0.4902],\n",
       "        [-0.4843],\n",
       "        [-0.4785],\n",
       "        [-0.4726],\n",
       "        [-0.4667],\n",
       "        [-0.4609],\n",
       "        [-0.4550],\n",
       "        [-0.4491],\n",
       "        [-0.4432],\n",
       "        [-0.4374],\n",
       "        [-0.4315],\n",
       "        [-0.4256],\n",
       "        [-0.4198],\n",
       "        [-0.4139],\n",
       "        [-0.4080],\n",
       "        [-0.4022],\n",
       "        [-0.3963],\n",
       "        [-0.3904],\n",
       "        [-0.3845],\n",
       "        [-0.3787],\n",
       "        [-0.3728],\n",
       "        [-0.3669],\n",
       "        [-0.3611],\n",
       "        [-0.3552],\n",
       "        [-0.3493],\n",
       "        [-0.3434],\n",
       "        [-0.3376],\n",
       "        [-0.3317],\n",
       "        [-0.3258],\n",
       "        [-0.3200],\n",
       "        [-0.3141],\n",
       "        [-0.3082],\n",
       "        [-0.3023],\n",
       "        [-0.2965],\n",
       "        [-0.2906],\n",
       "        [-0.2847],\n",
       "        [-0.2789],\n",
       "        [-0.2730],\n",
       "        [-0.2671],\n",
       "        [-0.2613],\n",
       "        [-0.2554],\n",
       "        [-0.2495],\n",
       "        [-0.2436],\n",
       "        [-0.2378],\n",
       "        [-0.2319],\n",
       "        [-0.2260],\n",
       "        [-0.2202],\n",
       "        [-0.2143],\n",
       "        [-0.2084],\n",
       "        [-0.2025],\n",
       "        [-0.1967],\n",
       "        [-0.1908],\n",
       "        [-0.1849],\n",
       "        [-0.1791],\n",
       "        [-0.1732],\n",
       "        [-0.1673],\n",
       "        [-0.1614],\n",
       "        [-0.1556],\n",
       "        [-0.1497],\n",
       "        [-0.1438],\n",
       "        [-0.1380],\n",
       "        [-0.1321],\n",
       "        [-0.1262],\n",
       "        [-0.1204],\n",
       "        [-0.1145],\n",
       "        [-0.1086],\n",
       "        [-0.1027],\n",
       "        [-0.0969],\n",
       "        [-0.0910],\n",
       "        [-0.0851],\n",
       "        [-0.0793],\n",
       "        [-0.0734],\n",
       "        [-0.0675],\n",
       "        [-0.0616],\n",
       "        [-0.0558],\n",
       "        [-0.0499],\n",
       "        [-0.0440],\n",
       "        [-0.0382],\n",
       "        [-0.0323],\n",
       "        [-0.0264],\n",
       "        [-0.0205],\n",
       "        [-0.0147],\n",
       "        [-0.0088],\n",
       "        [-0.0029],\n",
       "        [ 0.0029],\n",
       "        [ 0.0088],\n",
       "        [ 0.0147],\n",
       "        [ 0.0205],\n",
       "        [ 0.0264],\n",
       "        [ 0.0323],\n",
       "        [ 0.0382],\n",
       "        [ 0.0440],\n",
       "        [ 0.0499],\n",
       "        [ 0.0558],\n",
       "        [ 0.0616],\n",
       "        [ 0.0675],\n",
       "        [ 0.0734],\n",
       "        [ 0.0793],\n",
       "        [ 0.0851],\n",
       "        [ 0.0910],\n",
       "        [ 0.0969],\n",
       "        [ 0.1027],\n",
       "        [ 0.1086],\n",
       "        [ 0.1145],\n",
       "        [ 0.1204],\n",
       "        [ 0.1262],\n",
       "        [ 0.1321],\n",
       "        [ 0.1380],\n",
       "        [ 0.1438],\n",
       "        [ 0.1497],\n",
       "        [ 0.1556],\n",
       "        [ 0.1614],\n",
       "        [ 0.1673],\n",
       "        [ 0.1732],\n",
       "        [ 0.1791],\n",
       "        [ 0.1849],\n",
       "        [ 0.1908],\n",
       "        [ 0.1967],\n",
       "        [ 0.2025],\n",
       "        [ 0.2084],\n",
       "        [ 0.2143],\n",
       "        [ 0.2202],\n",
       "        [ 0.2260],\n",
       "        [ 0.2319],\n",
       "        [ 0.2378],\n",
       "        [ 0.2436],\n",
       "        [ 0.2495],\n",
       "        [ 0.2554],\n",
       "        [ 0.2613],\n",
       "        [ 0.2671],\n",
       "        [ 0.2730],\n",
       "        [ 0.2789],\n",
       "        [ 0.2847],\n",
       "        [ 0.2906],\n",
       "        [ 0.2965],\n",
       "        [ 0.3023],\n",
       "        [ 0.3082],\n",
       "        [ 0.3141],\n",
       "        [ 0.3200],\n",
       "        [ 0.3258],\n",
       "        [ 0.3317],\n",
       "        [ 0.3376],\n",
       "        [ 0.3434],\n",
       "        [ 0.3493],\n",
       "        [ 0.3552],\n",
       "        [ 0.3611],\n",
       "        [ 0.3669],\n",
       "        [ 0.3728],\n",
       "        [ 0.3787],\n",
       "        [ 0.3845],\n",
       "        [ 0.3904],\n",
       "        [ 0.3963],\n",
       "        [ 0.4022],\n",
       "        [ 0.4080],\n",
       "        [ 0.4139],\n",
       "        [ 0.4198],\n",
       "        [ 0.4256],\n",
       "        [ 0.4315],\n",
       "        [ 0.4374],\n",
       "        [ 0.4432],\n",
       "        [ 0.4491],\n",
       "        [ 0.4550],\n",
       "        [ 0.4609],\n",
       "        [ 0.4667],\n",
       "        [ 0.4726],\n",
       "        [ 0.4785],\n",
       "        [ 0.4843],\n",
       "        [ 0.4902],\n",
       "        [ 0.4961],\n",
       "        [ 0.5020],\n",
       "        [ 0.5078],\n",
       "        [ 0.5137],\n",
       "        [ 0.5196],\n",
       "        [ 0.5254],\n",
       "        [ 0.5313],\n",
       "        [ 0.5372],\n",
       "        [ 0.5431],\n",
       "        [ 0.5489],\n",
       "        [ 0.5548],\n",
       "        [ 0.5607],\n",
       "        [ 0.5665],\n",
       "        [ 0.5724],\n",
       "        [ 0.5783],\n",
       "        [ 0.5841],\n",
       "        [ 0.5900],\n",
       "        [ 0.5959],\n",
       "        [ 0.6018],\n",
       "        [ 0.6076],\n",
       "        [ 0.6135],\n",
       "        [ 0.6194],\n",
       "        [ 0.6252],\n",
       "        [ 0.6311],\n",
       "        [ 0.6370],\n",
       "        [ 0.6429],\n",
       "        [ 0.6487],\n",
       "        [ 0.6546],\n",
       "        [ 0.6605],\n",
       "        [ 0.6663],\n",
       "        [ 0.6722],\n",
       "        [ 0.6781],\n",
       "        [ 0.6840],\n",
       "        [ 0.6898],\n",
       "        [ 0.6957],\n",
       "        [ 0.7016],\n",
       "        [ 0.7074],\n",
       "        [ 0.7133],\n",
       "        [ 0.7192],\n",
       "        [ 0.7250],\n",
       "        [ 0.7309],\n",
       "        [ 0.7368],\n",
       "        [ 0.7427],\n",
       "        [ 0.7485],\n",
       "        [ 0.7544],\n",
       "        [ 0.7603],\n",
       "        [ 0.7661],\n",
       "        [ 0.7720],\n",
       "        [ 0.7779],\n",
       "        [ 0.7838],\n",
       "        [ 0.7896],\n",
       "        [ 0.7955],\n",
       "        [ 0.8014],\n",
       "        [ 0.8072],\n",
       "        [ 0.8131],\n",
       "        [ 0.8190],\n",
       "        [ 0.8249],\n",
       "        [ 0.8307],\n",
       "        [ 0.8366],\n",
       "        [ 0.8425],\n",
       "        [ 0.8483],\n",
       "        [ 0.8542],\n",
       "        [ 0.8601],\n",
       "        [ 0.8659],\n",
       "        [ 0.8718],\n",
       "        [ 0.8777],\n",
       "        [ 0.8836],\n",
       "        [ 0.8894],\n",
       "        [ 0.8953],\n",
       "        [ 0.9012],\n",
       "        [ 0.9070],\n",
       "        [ 0.9129],\n",
       "        [ 0.9188],\n",
       "        [ 0.9247],\n",
       "        [ 0.9305],\n",
       "        [ 0.9364],\n",
       "        [ 0.9423],\n",
       "        [ 0.9481],\n",
       "        [ 0.9540],\n",
       "        [ 0.9599],\n",
       "        [ 0.9658],\n",
       "        [ 0.9716],\n",
       "        [ 0.9775],\n",
       "        [ 0.9834],\n",
       "        [ 0.9892],\n",
       "        [ 0.9951],\n",
       "        [ 1.0010],\n",
       "        [ 1.0068],\n",
       "        [ 1.0127],\n",
       "        [ 1.0186],\n",
       "        [ 1.0245],\n",
       "        [ 1.0303],\n",
       "        [ 1.0362],\n",
       "        [ 1.0421],\n",
       "        [ 1.0479],\n",
       "        [ 1.0538],\n",
       "        [ 1.0597],\n",
       "        [ 1.0656],\n",
       "        [ 1.0714],\n",
       "        [ 1.0773],\n",
       "        [ 1.0832],\n",
       "        [ 1.0890],\n",
       "        [ 1.0949],\n",
       "        [ 1.1008],\n",
       "        [ 1.1067],\n",
       "        [ 1.1125],\n",
       "        [ 1.1184],\n",
       "        [ 1.1243],\n",
       "        [ 1.1301],\n",
       "        [ 1.1360],\n",
       "        [ 1.1419],\n",
       "        [ 1.1477],\n",
       "        [ 1.1536],\n",
       "        [ 1.1595],\n",
       "        [ 1.1654],\n",
       "        [ 1.1712],\n",
       "        [ 1.1771],\n",
       "        [ 1.1830],\n",
       "        [ 1.1888],\n",
       "        [ 1.1947],\n",
       "        [ 1.2006],\n",
       "        [ 1.2065],\n",
       "        [ 1.2123],\n",
       "        [ 1.2182],\n",
       "        [ 1.2241],\n",
       "        [ 1.2299],\n",
       "        [ 1.2358],\n",
       "        [ 1.2417],\n",
       "        [ 1.2476],\n",
       "        [ 1.2534],\n",
       "        [ 1.2593],\n",
       "        [ 1.2652],\n",
       "        [ 1.2710],\n",
       "        [ 1.2769],\n",
       "        [ 1.2828],\n",
       "        [ 1.2886],\n",
       "        [ 1.2945],\n",
       "        [ 1.3004],\n",
       "        [ 1.3063],\n",
       "        [ 1.3121],\n",
       "        [ 1.3180],\n",
       "        [ 1.3239],\n",
       "        [ 1.3297],\n",
       "        [ 1.3356],\n",
       "        [ 1.3415],\n",
       "        [ 1.3474],\n",
       "        [ 1.3532],\n",
       "        [ 1.3591],\n",
       "        [ 1.3650],\n",
       "        [ 1.3708],\n",
       "        [ 1.3767],\n",
       "        [ 1.3826],\n",
       "        [ 1.3885],\n",
       "        [ 1.3943],\n",
       "        [ 1.4002],\n",
       "        [ 1.4061],\n",
       "        [ 1.4119],\n",
       "        [ 1.4178],\n",
       "        [ 1.4237],\n",
       "        [ 1.4295],\n",
       "        [ 1.4354],\n",
       "        [ 1.4413],\n",
       "        [ 1.4472],\n",
       "        [ 1.4530],\n",
       "        [ 1.4589],\n",
       "        [ 1.4648],\n",
       "        [ 1.4706],\n",
       "        [ 1.4765],\n",
       "        [ 1.4824],\n",
       "        [ 1.4883],\n",
       "        [ 1.4941],\n",
       "        [ 1.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_train = io.tensor(np.linspace(-1.5, 1.5, 1024).reshape((-1, 1)))\n",
    "u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000],\n",
       "        [-1.9365],\n",
       "        [-1.8730],\n",
       "        [-1.8095],\n",
       "        [-1.7460],\n",
       "        [-1.6825],\n",
       "        [-1.6190],\n",
       "        [-1.5556],\n",
       "        [-1.4921],\n",
       "        [-1.4286],\n",
       "        [-1.3651],\n",
       "        [-1.3016],\n",
       "        [-1.2381],\n",
       "        [-1.1746],\n",
       "        [-1.1111],\n",
       "        [-1.0476],\n",
       "        [-0.9841],\n",
       "        [-0.9206],\n",
       "        [-0.8571],\n",
       "        [-0.7937],\n",
       "        [-0.7302],\n",
       "        [-0.6667],\n",
       "        [-0.6032],\n",
       "        [-0.5397],\n",
       "        [-0.4762],\n",
       "        [-0.4127],\n",
       "        [-0.3492],\n",
       "        [-0.2857],\n",
       "        [-0.2222],\n",
       "        [-0.1587],\n",
       "        [-0.0952],\n",
       "        [-0.0317],\n",
       "        [ 0.0317],\n",
       "        [ 0.0952],\n",
       "        [ 0.1587],\n",
       "        [ 0.2222],\n",
       "        [ 0.2857],\n",
       "        [ 0.3492],\n",
       "        [ 0.4127],\n",
       "        [ 0.4762],\n",
       "        [ 0.5397],\n",
       "        [ 0.6032],\n",
       "        [ 0.6667],\n",
       "        [ 0.7302],\n",
       "        [ 0.7937],\n",
       "        [ 0.8571],\n",
       "        [ 0.9206],\n",
       "        [ 0.9841],\n",
       "        [ 1.0476],\n",
       "        [ 1.1111],\n",
       "        [ 1.1746],\n",
       "        [ 1.2381],\n",
       "        [ 1.3016],\n",
       "        [ 1.3651],\n",
       "        [ 1.4286],\n",
       "        [ 1.4921],\n",
       "        [ 1.5556],\n",
       "        [ 1.6190],\n",
       "        [ 1.6825],\n",
       "        [ 1.7460],\n",
       "        [ 1.8095],\n",
       "        [ 1.8730],\n",
       "        [ 1.9365],\n",
       "        [ 2.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_val = io.tensor(np.linspace(-2, 2, 64).reshape((-1, 1)))\n",
    "u_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora generamos los x correspondientes del modelo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamplePLP(io.ParametricLP):\n",
    "    # Generate an LP from a given feature vector u and weight vector w.\n",
    "    def generate(self, u, w):\n",
    "        c = [[torch.cos(w[0] + w[1]*u)],\n",
    "             [torch.sin(w[0] + w[1]*u)]]\n",
    "\n",
    "        A_ub = [[-1.0,  0.0],\n",
    "                [ 0.0, -1.0],\n",
    "                [ w[0], 1 + w[1]*u/3]]\n",
    "\n",
    "        b_ub = [[ 0.2*w[0]*u],\n",
    "                [-0.2*w[1]*u],\n",
    "                [ w[0] + 0.1*u]]\n",
    "        \n",
    "        return c, A_ub, b_ub, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plp_true = ExamplePLP(weights=[1.0, 1.0])\n",
    "\n",
    "# Generate training targets by solve the true PLP at each u value.\n",
    "x_train = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_train])\n",
    "torch.save(x_train, \"x_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_val = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_val])\n",
    "torch.save(x_val, \"x_val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4000,  1.2000],\n",
       "        [ 0.3873,  1.1821],\n",
       "        [ 0.3746,  1.1662],\n",
       "        [ 0.3619,  1.1520],\n",
       "        [ 0.3492,  1.1392],\n",
       "        [ 0.3365,  1.1277],\n",
       "        [ 0.3238,  1.1172],\n",
       "        [ 0.3111,  1.1077],\n",
       "        [ 0.2984,  1.0989],\n",
       "        [ 0.2857,  1.0909],\n",
       "        [ 0.2730,  1.0835],\n",
       "        [ 0.2603,  1.0766],\n",
       "        [ 0.2476,  1.0702],\n",
       "        [ 0.2349,  1.0643],\n",
       "        [ 0.2222,  1.0588],\n",
       "        [ 0.2095,  1.0535],\n",
       "        [ 0.1968, -0.1965],\n",
       "        [ 0.1841, -0.1841],\n",
       "        [ 0.1714, -0.1714],\n",
       "        [ 0.1587, -0.1587],\n",
       "        [ 0.1460, -0.1460],\n",
       "        [ 0.1333, -0.1333],\n",
       "        [ 0.1206, -0.1206],\n",
       "        [ 0.1079, -0.1079],\n",
       "        [ 0.0952, -0.0952],\n",
       "        [ 0.0825, -0.0825],\n",
       "        [ 0.0698, -0.0698],\n",
       "        [ 0.0571, -0.0571],\n",
       "        [ 0.0444, -0.0444],\n",
       "        [ 0.0318, -0.0317],\n",
       "        [ 0.0191, -0.0190],\n",
       "        [ 0.0064, -0.0063],\n",
       "        [-0.0063,  0.0064],\n",
       "        [-0.0190,  0.0191],\n",
       "        [-0.0317,  0.0318],\n",
       "        [-0.0444,  0.0444],\n",
       "        [-0.0571,  0.0571],\n",
       "        [-0.0698,  0.0698],\n",
       "        [-0.0825,  0.0825],\n",
       "        [-0.0952,  0.0952],\n",
       "        [-0.1078,  0.1079],\n",
       "        [ 0.9153,  0.1206],\n",
       "        [ 0.9037,  0.1333],\n",
       "        [ 0.8914,  0.1460],\n",
       "        [ 0.8786,  0.1587],\n",
       "        [ 0.8653,  0.1714],\n",
       "        [ 0.8514,  0.1841],\n",
       "        [ 0.8370,  0.1968],\n",
       "        [ 0.8221,  0.2095],\n",
       "        [ 0.8066,  0.2222],\n",
       "        [ 0.7905,  0.2349],\n",
       "        [ 0.7740,  0.2476],\n",
       "        [ 0.7569,  0.2603],\n",
       "        [ 0.7392,  0.2730],\n",
       "        [ 0.7211,  0.2857],\n",
       "        [ 0.7024,  0.2984],\n",
       "        [ 0.6831,  0.3111],\n",
       "        [ 0.6633,  0.3238],\n",
       "        [ 0.6430,  0.3365],\n",
       "        [ 0.6221,  0.3492],\n",
       "        [ 0.6007,  0.3619],\n",
       "        [ 0.5788,  0.3746],\n",
       "        [ 0.5563,  0.3873],\n",
       "        [ 0.5333,  0.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.load(\"x_val.pt\")\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 1.1000],\n",
       "        [0.2988, 1.0992],\n",
       "        [0.2977, 1.0984],\n",
       "        ...,\n",
       "        [0.7035, 0.2977],\n",
       "        [0.7017, 0.2988],\n",
       "        [0.7000, 0.3000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.load(\"x_train.pt\")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: definimos la red y la entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# ver si estoy usando GPU\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "tol=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el dataset\n",
    "class UDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data.clone().to(dtype=torch.float32) # nota: esta dando el warning porque estoy convirtiendo un tensor a otro, en ese caso es mejor usar clone()\n",
    "        # si los datos de entrada no los voy a dar como un tensor, entonces hay que poner lo que he puesto: self.data = torch.tensor(data, dtype=torch.float32), self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        self.targets = targets.clone().to(dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Dataset con pares (u, x)\n",
    "dataset = UDataset(u_train, x_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = UDataset(u_val, x_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que resuelve el problema de programacion lineal (por ahora nos la creemos, pero hay que revisarla)\n",
    "# hay que tener en cuenta que esta funcion debe realizarse con operaciones de pytorch para\n",
    "# preservar el grafo de computo para poder hacer backpropagation\n",
    "# def smooth_lp(c, A, b):\n",
    "#     # Inicializar x con gradientes habilitados\n",
    "#     x = torch.zeros(A.shape[1], requires_grad=True)\n",
    "#     optimizer = torch.optim.SGD([x], lr=1e-3)\n",
    "\n",
    "#     for _ in range(1000):\n",
    "#         optimizer.zero_grad()\n",
    "#         constraint_penalty = torch.sum(torch.relu(A @ x - b))\n",
    "#         objective = torch.dot(c, x) + 100.0 * constraint_penalty\n",
    "#         objective.backward(retain_graph=True)  # Mantén el grafo activo\n",
    "#         optimizer.step()\n",
    "#     return x  # Sin detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy descartado porque no funciona\n",
    "# voy a probar con cvxpy\n",
    "\n",
    "import torch\n",
    "import cvxpylayers.torch as cvx\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "def solver(c_, A_, b_):\n",
    "    m,n = A_.shape\n",
    "\n",
    "    A = cp.Parameter((m, n))\n",
    "    b = cp.Parameter(m)\n",
    "    c = cp.Parameter(n)\n",
    "    x = cp.Variable(n)\n",
    "\n",
    "    obj = cp.Minimize(c.T @ x)\n",
    "    cons = [ A @ x <= b ]\n",
    "    prob = cp.Problem(obj, cons)\n",
    "\n",
    "    layer = CvxpyLayer(prob, parameters=[c,A,b], variables=[x])\n",
    "\n",
    "    solution, = layer(c_, A_, b_)\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1616e-06, -6.1616e-06])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([-1.0, -1.0])\n",
    "\n",
    "A = torch.tensor([[1.0, 0.0],\n",
    "                  [0.0, 1.0]])\n",
    "b = torch.tensor([0.0,\n",
    "                  0.0])\n",
    "\n",
    "print(solver(c, A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta version es la red neuronal en la que la resolucion del problema de optimizacion esta dentro de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la red (hay que revisar la forma de la red y el por qué)\n",
    "class ParametricLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParametricLPNet, self).__init__()\n",
    "        # Entrada de dimensión 1, salida 8 (2 para c, 4 para A, 2 para b)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, u):\n",
    "        output = self.fc(u)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion de perdida\n",
    "# def loss_fn(rs, target):\n",
    "#     '''\n",
    "#     rs: lista de tensores que son las salidas de la red\n",
    "#     target: lista de tensores que son las salidas deseadas\n",
    "\n",
    "#     Esta función calcula la suma de las distancias al cuadrado entre las salidas de la red y las salidas deseadas.\n",
    "#     '''\n",
    "#     return torch.sum(torch.linalg.vector_norm(rs-target, ord=2, dim=1).pow(2))\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la red neuronal\n",
    "model = ParametricLPNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # elegir una de las dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametricLPNet(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para ver el modelo\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamod los pesos de la red \n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu') # inicializamos los pesos de la red con Kaiming\n",
    "        nn.init.zeros_(m.bias) # inicializamos los bias a 0\n",
    "\n",
    "initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss_media = 0.0\n",
    "    accuracy = 0.0\n",
    "    batch_size = dataloader.batch_size\n",
    "    for batch, (u_batch, x_batch) in enumerate(dataloader):\n",
    "\n",
    "        rs = model(u_batch)\n",
    "        loss = loss_fn(rs, x_batch) # Calcular la pérdida\n",
    "\n",
    "        # Backpropagation y optimización\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 8 == 0: # cambiar este numero para que salga cada cierto numero de iteraciones\n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        loss_media += loss\n",
    "        accuracy += near(rs, x_batch, tol)\n",
    "\n",
    "    return loss_media / num_batches, accuracy / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for u_batch, x_batch in dataloader:\n",
    "        rs = model(u_batch)\n",
    "        test_loss += loss_fn(rs, x_batch).item()\n",
    "        correct += near(rs, x_batch, tol) # consideramos correcto si se acerca a la solucion en la distancia euclidea \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.136345  [   32/  512]\n",
      "loss: 0.177001  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.138126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.140520 \n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.127070  [   32/  512]\n",
      "loss: 0.117360  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.118671 \n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.097086  [   32/  512]\n",
      "loss: 0.112366  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.112141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.108035 \n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.107938  [   32/  512]\n",
      "loss: 0.080704  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.105055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097675 \n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.111450  [   32/  512]\n",
      "loss: 0.116217  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088304 \n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.098432  [   32/  512]\n",
      "loss: 0.085534  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078577 \n",
      "\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.084010  [   32/  512]\n",
      "loss: 0.085983  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081072 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073202 \n",
      "\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.069819  [   32/  512]\n",
      "loss: 0.100163  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065916 \n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.081680  [   32/  512]\n",
      "loss: 0.069606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061383 \n",
      "\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.056641  [   32/  512]\n",
      "loss: 0.047458  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057279 \n",
      "\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.047467  [   32/  512]\n",
      "loss: 0.053353  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055300 \n",
      "\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.055281  [   32/  512]\n",
      "loss: 0.063544  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052242 \n",
      "\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.067742  [   32/  512]\n",
      "loss: 0.067510  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051634 \n",
      "\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.049660  [   32/  512]\n",
      "loss: 0.055976  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050970 \n",
      "\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.059286  [   32/  512]\n",
      "loss: 0.065701  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048604 \n",
      "\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.049397  [   32/  512]\n",
      "loss: 0.042020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048374 \n",
      "\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.045913  [   32/  512]\n",
      "loss: 0.050304  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047933 \n",
      "\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.029201  [   32/  512]\n",
      "loss: 0.051612  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047766 \n",
      "\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.063292  [   32/  512]\n",
      "loss: 0.034344  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045748 \n",
      "\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.062154  [   32/  512]\n",
      "loss: 0.043260  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045381 \n",
      "\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.043448  [   32/  512]\n",
      "loss: 0.040980  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044734 \n",
      "\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.042589  [   32/  512]\n",
      "loss: 0.056502  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043796 \n",
      "\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.027716  [   32/  512]\n",
      "loss: 0.041664  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042274 \n",
      "\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.051230  [   32/  512]\n",
      "loss: 0.046729  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044155 \n",
      "\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.030614  [   32/  512]\n",
      "loss: 0.027024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041797 \n",
      "\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.033402  [   32/  512]\n",
      "loss: 0.033567  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042916 \n",
      "\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.041811  [   32/  512]\n",
      "loss: 0.057220  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041364 \n",
      "\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.031211  [   32/  512]\n",
      "loss: 0.039685  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037617 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041397 \n",
      "\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.045011  [   32/  512]\n",
      "loss: 0.032580  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043093 \n",
      "\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.029385  [   32/  512]\n",
      "loss: 0.028251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040313 \n",
      "\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.027661  [   32/  512]\n",
      "loss: 0.022710  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042230 \n",
      "\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.040432  [   32/  512]\n",
      "loss: 0.022550  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042010 \n",
      "\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.024897  [   32/  512]\n",
      "loss: 0.022256  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041923 \n",
      "\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.028388  [   32/  512]\n",
      "loss: 0.024713  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041267 \n",
      "\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.020128  [   32/  512]\n",
      "loss: 0.039547  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045001 \n",
      "\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.028163  [   32/  512]\n",
      "loss: 0.031834  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044707 \n",
      "\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.023235  [   32/  512]\n",
      "loss: 0.024047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044221 \n",
      "\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.024384  [   32/  512]\n",
      "loss: 0.019516  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027083 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044544 \n",
      "\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.022057  [   32/  512]\n",
      "loss: 0.031125  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047884 \n",
      "\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.033580  [   32/  512]\n",
      "loss: 0.028233  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047275 \n",
      "\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.021684  [   32/  512]\n",
      "loss: 0.023010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049330 \n",
      "\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.019879  [   32/  512]\n",
      "loss: 0.032393  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047926 \n",
      "\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.030427  [   32/  512]\n",
      "loss: 0.026931  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045806 \n",
      "\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.018606  [   32/  512]\n",
      "loss: 0.027028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048868 \n",
      "\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.010575  [   32/  512]\n",
      "loss: 0.018257  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046534 \n",
      "\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.022864  [   32/  512]\n",
      "loss: 0.042656  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045668 \n",
      "\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.017844  [   32/  512]\n",
      "loss: 0.027359  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048793 \n",
      "\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.024188  [   32/  512]\n",
      "loss: 0.018738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020971 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047039 \n",
      "\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.014652  [   32/  512]\n",
      "loss: 0.022978  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049816 \n",
      "\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.021316  [   32/  512]\n",
      "loss: 0.020560  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047775 \n",
      "\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.028296  [   32/  512]\n",
      "loss: 0.017653  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051042 \n",
      "\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.003007  [   32/  512]\n",
      "loss: 0.015134  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050709 \n",
      "\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.013836  [   32/  512]\n",
      "loss: 0.022915  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044601 \n",
      "\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.021703  [   32/  512]\n",
      "loss: 0.016546  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050809 \n",
      "\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.018057  [   32/  512]\n",
      "loss: 0.012330  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047386 \n",
      "\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.005599  [   32/  512]\n",
      "loss: 0.011797  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047752 \n",
      "\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.020954  [   32/  512]\n",
      "loss: 0.029800  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048287 \n",
      "\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.014568  [   32/  512]\n",
      "loss: 0.021148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052512 \n",
      "\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.024351  [   32/  512]\n",
      "loss: 0.020365  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045096 \n",
      "\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.006587  [   32/  512]\n",
      "loss: 0.012158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048945 \n",
      "\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.012955  [   32/  512]\n",
      "loss: 0.006961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016348 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050795 \n",
      "\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.008237  [   32/  512]\n",
      "loss: 0.021138  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046605 \n",
      "\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.015643  [   32/  512]\n",
      "loss: 0.011890  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049505 \n",
      "\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.016449  [   32/  512]\n",
      "loss: 0.013497  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046075 \n",
      "\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.009815  [   32/  512]\n",
      "loss: 0.017892  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047529 \n",
      "\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.014279  [   32/  512]\n",
      "loss: 0.021249  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046912 \n",
      "\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.009785  [   32/  512]\n",
      "loss: 0.015473  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047794 \n",
      "\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.011317  [   32/  512]\n",
      "loss: 0.021275  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043226 \n",
      "\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.008724  [   32/  512]\n",
      "loss: 0.018047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049461 \n",
      "\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.010273  [   32/  512]\n",
      "loss: 0.014979  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014832 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045040 \n",
      "\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.014477  [   32/  512]\n",
      "loss: 0.018336  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047527 \n",
      "\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.018424  [   32/  512]\n",
      "loss: 0.018565  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049394 \n",
      "\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.008862  [   32/  512]\n",
      "loss: 0.009307  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045621 \n",
      "\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.008794  [   32/  512]\n",
      "loss: 0.025629  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049865 \n",
      "\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.011390  [   32/  512]\n",
      "loss: 0.022066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044813 \n",
      "\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.022364  [   32/  512]\n",
      "loss: 0.010543  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045711 \n",
      "\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.006635  [   32/  512]\n",
      "loss: 0.018081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013921 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047701 \n",
      "\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.006996  [   32/  512]\n",
      "loss: 0.023565  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013824 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043939 \n",
      "\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.019021  [   32/  512]\n",
      "loss: 0.015443  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048468 \n",
      "\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.004689  [   32/  512]\n",
      "loss: 0.027542  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045696 \n",
      "\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.020862  [   32/  512]\n",
      "loss: 0.010159  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050060 \n",
      "\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.011080  [   32/  512]\n",
      "loss: 0.020485  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045379 \n",
      "\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.015139  [   32/  512]\n",
      "loss: 0.007889  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040949 \n",
      "\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.014451  [   32/  512]\n",
      "loss: 0.004577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046434 \n",
      "\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.009025  [   32/  512]\n",
      "loss: 0.011494  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043321 \n",
      "\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.017780  [   32/  512]\n",
      "loss: 0.006529  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042457 \n",
      "\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.014274  [   32/  512]\n",
      "loss: 0.023830  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043818 \n",
      "\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.019413  [   32/  512]\n",
      "loss: 0.008795  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041969 \n",
      "\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.009740  [   32/  512]\n",
      "loss: 0.011927  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044062 \n",
      "\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.027095  [   32/  512]\n",
      "loss: 0.007952  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042292 \n",
      "\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.008929  [   32/  512]\n",
      "loss: 0.009030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012399 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039123 \n",
      "\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.014928  [   32/  512]\n",
      "loss: 0.007108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043542 \n",
      "\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.014280  [   32/  512]\n",
      "loss: 0.006673  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038215 \n",
      "\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.013331  [   32/  512]\n",
      "loss: 0.011099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044067 \n",
      "\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.007602  [   32/  512]\n",
      "loss: 0.018757  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012121 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038853 \n",
      "\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.016654  [   32/  512]\n",
      "loss: 0.020175  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038777 \n",
      "\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.006382  [   32/  512]\n",
      "loss: 0.010545  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039637 \n",
      "\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.011668  [   32/  512]\n",
      "loss: 0.012741  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040837 \n",
      "\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.007874  [   32/  512]\n",
      "loss: 0.013940  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011369 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038230 \n",
      "\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.009567  [   32/  512]\n",
      "loss: 0.019663  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039316 \n",
      "\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.012844  [   32/  512]\n",
      "loss: 0.002316  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037819 \n",
      "\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.020617  [   32/  512]\n",
      "loss: 0.011536  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011264 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038460 \n",
      "\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.006025  [   32/  512]\n",
      "loss: 0.008279  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037281 \n",
      "\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.009309  [   32/  512]\n",
      "loss: 0.005175  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035116 \n",
      "\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.008048  [   32/  512]\n",
      "loss: 0.015291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040112 \n",
      "\n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.007942  [   32/  512]\n",
      "loss: 0.013039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035958 \n",
      "\n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.018218  [   32/  512]\n",
      "loss: 0.018128  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037357 \n",
      "\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.017821  [   32/  512]\n",
      "loss: 0.018576  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033915 \n",
      "\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.010632  [   32/  512]\n",
      "loss: 0.007889  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033033 \n",
      "\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.013123  [   32/  512]\n",
      "loss: 0.006615  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034276 \n",
      "\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.007015  [   32/  512]\n",
      "loss: 0.012954  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034845 \n",
      "\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.006650  [   32/  512]\n",
      "loss: 0.014697  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010134 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035982 \n",
      "\n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.011344  [   32/  512]\n",
      "loss: 0.008634  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032973 \n",
      "\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.007428  [   32/  512]\n",
      "loss: 0.014191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032113 \n",
      "\n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.011769  [   32/  512]\n",
      "loss: 0.007148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010201 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032893 \n",
      "\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.011964  [   32/  512]\n",
      "loss: 0.002046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032828 \n",
      "\n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.015507  [   32/  512]\n",
      "loss: 0.004254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031845 \n",
      "\n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.017851  [   32/  512]\n",
      "loss: 0.006961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032670 \n",
      "\n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.002128  [   32/  512]\n",
      "loss: 0.012998  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031873 \n",
      "\n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.007214  [   32/  512]\n",
      "loss: 0.012665  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031551 \n",
      "\n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.007300  [   32/  512]\n",
      "loss: 0.011597  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032127 \n",
      "\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.017085  [   32/  512]\n",
      "loss: 0.005738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032796 \n",
      "\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.003923  [   32/  512]\n",
      "loss: 0.012600  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029951 \n",
      "\n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.009969  [   32/  512]\n",
      "loss: 0.014885  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029920 \n",
      "\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.017873  [   32/  512]\n",
      "loss: 0.011154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031713 \n",
      "\n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.014403  [   32/  512]\n",
      "loss: 0.010018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029839 \n",
      "\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.011160  [   32/  512]\n",
      "loss: 0.008935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008827 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030359 \n",
      "\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.001054  [   32/  512]\n",
      "loss: 0.010282  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028886 \n",
      "\n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.009714  [   32/  512]\n",
      "loss: 0.006677  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031077 \n",
      "\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.004124  [   32/  512]\n",
      "loss: 0.005291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027771 \n",
      "\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.005136  [   32/  512]\n",
      "loss: 0.006760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028872 \n",
      "\n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.006860  [   32/  512]\n",
      "loss: 0.006739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028331 \n",
      "\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.003851  [   32/  512]\n",
      "loss: 0.007195  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027157 \n",
      "\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.010592  [   32/  512]\n",
      "loss: 0.014502  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026472 \n",
      "\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.016248  [   32/  512]\n",
      "loss: 0.006960  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026438 \n",
      "\n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.011572  [   32/  512]\n",
      "loss: 0.012200  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027252 \n",
      "\n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.012919  [   32/  512]\n",
      "loss: 0.007852  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028545 \n",
      "\n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.004729  [   32/  512]\n",
      "loss: 0.005558  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029358 \n",
      "\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.016101  [   32/  512]\n",
      "loss: 0.002719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008104 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028056 \n",
      "\n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.003638  [   32/  512]\n",
      "loss: 0.003387  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028303 \n",
      "\n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.011219  [   32/  512]\n",
      "loss: 0.009251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027996 \n",
      "\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.006383  [   32/  512]\n",
      "loss: 0.012023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027279 \n",
      "\n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.007083  [   32/  512]\n",
      "loss: 0.009001  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024805 \n",
      "\n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.003545  [   32/  512]\n",
      "loss: 0.012390  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026200 \n",
      "\n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.007035  [   32/  512]\n",
      "loss: 0.009994  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007787 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025039 \n",
      "\n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.004438  [   32/  512]\n",
      "loss: 0.012129  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025647 \n",
      "\n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.002942  [   32/  512]\n",
      "loss: 0.010270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025162 \n",
      "\n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.006112  [   32/  512]\n",
      "loss: 0.001649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026498 \n",
      "\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.010194  [   32/  512]\n",
      "loss: 0.007315  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024286 \n",
      "\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.018394  [   32/  512]\n",
      "loss: 0.009657  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022802 \n",
      "\n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.001558  [   32/  512]\n",
      "loss: 0.006019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026198 \n",
      "\n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.005889  [   32/  512]\n",
      "loss: 0.002990  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023346 \n",
      "\n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.004316  [   32/  512]\n",
      "loss: 0.012524  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022794 \n",
      "\n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.013557  [   32/  512]\n",
      "loss: 0.009593  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022966 \n",
      "\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.001497  [   32/  512]\n",
      "loss: 0.004994  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023474 \n",
      "\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.005772  [   32/  512]\n",
      "loss: 0.008045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022927 \n",
      "\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.004094  [   32/  512]\n",
      "loss: 0.001912  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022296 \n",
      "\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.006825  [   32/  512]\n",
      "loss: 0.012369  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024794 \n",
      "\n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.009070  [   32/  512]\n",
      "loss: 0.002840  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021887 \n",
      "\n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.004319  [   32/  512]\n",
      "loss: 0.002734  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021724 \n",
      "\n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.001374  [   32/  512]\n",
      "loss: 0.003292  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021309 \n",
      "\n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.007996  [   32/  512]\n",
      "loss: 0.014559  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019406 \n",
      "\n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.001708  [   32/  512]\n",
      "loss: 0.002457  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021365 \n",
      "\n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.007307  [   32/  512]\n",
      "loss: 0.005728  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021288 \n",
      "\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.007570  [   32/  512]\n",
      "loss: 0.012699  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020193 \n",
      "\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.005743  [   32/  512]\n",
      "loss: 0.005832  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020721 \n",
      "\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.004409  [   32/  512]\n",
      "loss: 0.002926  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019842 \n",
      "\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.005613  [   32/  512]\n",
      "loss: 0.012780  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018843 \n",
      "\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.003303  [   32/  512]\n",
      "loss: 0.004033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019905 \n",
      "\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.009025  [   32/  512]\n",
      "loss: 0.001525  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019010 \n",
      "\n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.007357  [   32/  512]\n",
      "loss: 0.006552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017726 \n",
      "\n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.006555  [   32/  512]\n",
      "loss: 0.005483  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018969 \n",
      "\n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.008519  [   32/  512]\n",
      "loss: 0.000895  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020061 \n",
      "\n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.005086  [   32/  512]\n",
      "loss: 0.012048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019463 \n",
      "\n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.002012  [   32/  512]\n",
      "loss: 0.002248  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018191 \n",
      "\n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.001545  [   32/  512]\n",
      "loss: 0.003714  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019053 \n",
      "\n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.009185  [   32/  512]\n",
      "loss: 0.009376  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017396 \n",
      "\n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.001788  [   32/  512]\n",
      "loss: 0.004299  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017624 \n",
      "\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.006756  [   32/  512]\n",
      "loss: 0.004394  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018179 \n",
      "\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.001468  [   32/  512]\n",
      "loss: 0.003495  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017208 \n",
      "\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.002038  [   32/  512]\n",
      "loss: 0.000291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017400 \n",
      "\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.004529  [   32/  512]\n",
      "loss: 0.003963  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016859 \n",
      "\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.003124  [   32/  512]\n",
      "loss: 0.002310  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018630 \n",
      "\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.002339  [   32/  512]\n",
      "loss: 0.000927  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016298 \n",
      "\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.006266  [   32/  512]\n",
      "loss: 0.011052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015339 \n",
      "\n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.015266  [   32/  512]\n",
      "loss: 0.003203  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015275 \n",
      "\n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.008106  [   32/  512]\n",
      "loss: 0.006360  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015227 \n",
      "\n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.010681  [   32/  512]\n",
      "loss: 0.005690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015508 \n",
      "\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.007520  [   32/  512]\n",
      "loss: 0.003634  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016203 \n",
      "\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.002097  [   32/  512]\n",
      "loss: 0.001139  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015355 \n",
      "\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.013531  [   32/  512]\n",
      "loss: 0.005072  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015405 \n",
      "\n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.008224  [   32/  512]\n",
      "loss: 0.007771  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015600 \n",
      "\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.009813  [   32/  512]\n",
      "loss: 0.004422  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014017 \n",
      "\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.004002  [   32/  512]\n",
      "loss: 0.011788  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013406 \n",
      "\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.003858  [   32/  512]\n",
      "loss: 0.005051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014108 \n",
      "\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.004646  [   32/  512]\n",
      "loss: 0.004554  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014379 \n",
      "\n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.001168  [   32/  512]\n",
      "loss: 0.002905  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014896 \n",
      "\n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.001449  [   32/  512]\n",
      "loss: 0.003135  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014476 \n",
      "\n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.001615  [   32/  512]\n",
      "loss: 0.003404  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014214 \n",
      "\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.002513  [   32/  512]\n",
      "loss: 0.000696  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014145 \n",
      "\n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.001633  [   32/  512]\n",
      "loss: 0.006990  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012783 \n",
      "\n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.001453  [   32/  512]\n",
      "loss: 0.006059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004979 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012691 \n",
      "\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.003852  [   32/  512]\n",
      "loss: 0.006223  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013647 \n",
      "\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.005877  [   32/  512]\n",
      "loss: 0.010249  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004968 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014317 \n",
      "\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.004874  [   32/  512]\n",
      "loss: 0.016333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012743 \n",
      "\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.008110  [   32/  512]\n",
      "loss: 0.005011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011620 \n",
      "\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.001056  [   32/  512]\n",
      "loss: 0.003759  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012814 \n",
      "\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.002832  [   32/  512]\n",
      "loss: 0.001324  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012568 \n",
      "\n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.002780  [   32/  512]\n",
      "loss: 0.001501  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012641 \n",
      "\n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.006078  [   32/  512]\n",
      "loss: 0.007045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004752 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011857 \n",
      "\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.006673  [   32/  512]\n",
      "loss: 0.003294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012059 \n",
      "\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.002728  [   32/  512]\n",
      "loss: 0.007230  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011578 \n",
      "\n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.001005  [   32/  512]\n",
      "loss: 0.003998  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010902 \n",
      "\n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000777  [   32/  512]\n",
      "loss: 0.002164  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011562 \n",
      "\n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.002482  [   32/  512]\n",
      "loss: 0.008166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010996 \n",
      "\n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.001102  [   32/  512]\n",
      "loss: 0.008341  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010751 \n",
      "\n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.001288  [   32/  512]\n",
      "loss: 0.005925  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011328 \n",
      "\n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.005730  [   32/  512]\n",
      "loss: 0.008027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010444 \n",
      "\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.005192  [   32/  512]\n",
      "loss: 0.001552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010828 \n",
      "\n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.007693  [   32/  512]\n",
      "loss: 0.007661  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010804 \n",
      "\n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.002492  [   32/  512]\n",
      "loss: 0.000572  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010912 \n",
      "\n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.001704  [   32/  512]\n",
      "loss: 0.003909  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004576 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011174 \n",
      "\n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000752  [   32/  512]\n",
      "loss: 0.011002  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009544 \n",
      "\n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.005820  [   32/  512]\n",
      "loss: 0.005991  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009379 \n",
      "\n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.002807  [   32/  512]\n",
      "loss: 0.003431  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010029 \n",
      "\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.007886  [   32/  512]\n",
      "loss: 0.005140  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010524 \n",
      "\n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.004358  [   32/  512]\n",
      "loss: 0.000742  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009429 \n",
      "\n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000769  [   32/  512]\n",
      "loss: 0.007278  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009300 \n",
      "\n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.007083  [   32/  512]\n",
      "loss: 0.003699  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009588 \n",
      "\n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.009155  [   32/  512]\n",
      "loss: 0.001692  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008668 \n",
      "\n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000820  [   32/  512]\n",
      "loss: 0.001022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008993 \n",
      "\n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.004930  [   32/  512]\n",
      "loss: 0.003042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009524 \n",
      "\n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.001590  [   32/  512]\n",
      "loss: 0.003204  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008697 \n",
      "\n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000545  [   32/  512]\n",
      "loss: 0.000649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008549 \n",
      "\n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.007099  [   32/  512]\n",
      "loss: 0.001811  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008662 \n",
      "\n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.004521  [   32/  512]\n",
      "loss: 0.004028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008741 \n",
      "\n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.005071  [   32/  512]\n",
      "loss: 0.004548  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007870 \n",
      "\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.008376  [   32/  512]\n",
      "loss: 0.011012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004132 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008869 \n",
      "\n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.004003  [   32/  512]\n",
      "loss: 0.000441  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008530 \n",
      "\n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.002803  [   32/  512]\n",
      "loss: 0.008727  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006789 \n",
      "\n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.006285  [   32/  512]\n",
      "loss: 0.003492  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006875 \n",
      "\n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.007042  [   32/  512]\n",
      "loss: 0.003917  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007627 \n",
      "\n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.015266  [   32/  512]\n",
      "loss: 0.002270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007127 \n",
      "\n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.007205  [   32/  512]\n",
      "loss: 0.002452  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007476 \n",
      "\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.002818  [   32/  512]\n",
      "loss: 0.006364  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006931 \n",
      "\n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.004348  [   32/  512]\n",
      "loss: 0.010534  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007588 \n",
      "\n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.004467  [   32/  512]\n",
      "loss: 0.008004  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007082 \n",
      "\n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000391  [   32/  512]\n",
      "loss: 0.003472  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006624 \n",
      "\n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000521  [   32/  512]\n",
      "loss: 0.002637  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006888 \n",
      "\n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.003795  [   32/  512]\n",
      "loss: 0.007846  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006393 \n",
      "\n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000388  [   32/  512]\n",
      "loss: 0.014789  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008274 \n",
      "\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.003303  [   32/  512]\n",
      "loss: 0.002724  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007442 \n",
      "\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.008633  [   32/  512]\n",
      "loss: 0.007401  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003474 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006396 \n",
      "\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.005010  [   32/  512]\n",
      "loss: 0.002101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007430 \n",
      "\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.003717  [   32/  512]\n",
      "loss: 0.001237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006572 \n",
      "\n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.002306  [   32/  512]\n",
      "loss: 0.001433  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005838 \n",
      "\n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.006099  [   32/  512]\n",
      "loss: 0.003935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005638 \n",
      "\n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.009008  [   32/  512]\n",
      "loss: 0.002741  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005693 \n",
      "\n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000316  [   32/  512]\n",
      "loss: 0.000276  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006085 \n",
      "\n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.004897  [   32/  512]\n",
      "loss: 0.006989  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005328 \n",
      "\n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.006851  [   32/  512]\n",
      "loss: 0.006894  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006418 \n",
      "\n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.003193  [   32/  512]\n",
      "loss: 0.019760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004166 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005917 \n",
      "\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000211  [   32/  512]\n",
      "loss: 0.000294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005426 \n",
      "\n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.004208  [   32/  512]\n",
      "loss: 0.002911  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005395 \n",
      "\n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000448  [   32/  512]\n",
      "loss: 0.005011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005877 \n",
      "\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000121  [   32/  512]\n",
      "loss: 0.008693  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005735 \n",
      "\n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.012355  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005186 \n",
      "\n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.005385  [   32/  512]\n",
      "loss: 0.002936  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005606 \n",
      "\n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.009038  [   32/  512]\n",
      "loss: 0.007665  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005355 \n",
      "\n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.003402  [   32/  512]\n",
      "loss: 0.001758  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005863 \n",
      "\n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.007401  [   32/  512]\n",
      "loss: 0.004331  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004806 \n",
      "\n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.002887  [   32/  512]\n",
      "loss: 0.005057  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005365 \n",
      "\n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.006364  [   32/  512]\n",
      "loss: 0.004892  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005883 \n",
      "\n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.004097  [   32/  512]\n",
      "loss: 0.004272  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005077 \n",
      "\n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000148  [   32/  512]\n",
      "loss: 0.006670  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004484 \n",
      "\n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000133  [   32/  512]\n",
      "loss: 0.009168  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004803 \n",
      "\n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.004461  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004618 \n",
      "\n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.005635  [   32/  512]\n",
      "loss: 0.001739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005321 \n",
      "\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000175  [   32/  512]\n",
      "loss: 0.005042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004803 \n",
      "\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.005668  [   32/  512]\n",
      "loss: 0.000278  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005977 \n",
      "\n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.003075  [   32/  512]\n",
      "loss: 0.003154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004812 \n",
      "\n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.005550  [   32/  512]\n",
      "loss: 0.002284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003411 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004295 \n",
      "\n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000279  [   32/  512]\n",
      "loss: 0.004304  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004642 \n",
      "\n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000445  [   32/  512]\n",
      "loss: 0.001577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004703 \n",
      "\n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.000821  [   32/  512]\n",
      "loss: 0.005327  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004613 \n",
      "\n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.002759  [   32/  512]\n",
      "loss: 0.007123  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005092 \n",
      "\n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.000645  [   32/  512]\n",
      "loss: 0.000261  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004529 \n",
      "\n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.008719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004427 \n",
      "\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.003189  [   32/  512]\n",
      "loss: 0.001228  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005083 \n",
      "\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000643  [   32/  512]\n",
      "loss: 0.002047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004391 \n",
      "\n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.002462  [   32/  512]\n",
      "loss: 0.008431  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004138 \n",
      "\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000118  [   32/  512]\n",
      "loss: 0.001461  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005093 \n",
      "\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.002309  [   32/  512]\n",
      "loss: 0.001117  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004083 \n",
      "\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000203  [   32/  512]\n",
      "loss: 0.011285  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003743 \n",
      "\n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.005542  [   32/  512]\n",
      "loss: 0.001023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003660 \n",
      "\n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.006605  [   32/  512]\n",
      "loss: 0.006690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003827 \n",
      "\n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.004771  [   32/  512]\n",
      "loss: 0.001384  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003847 \n",
      "\n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.001378  [   32/  512]\n",
      "loss: 0.000831  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004960 \n",
      "\n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.002125  [   32/  512]\n",
      "loss: 0.002010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004894 \n",
      "\n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.002240  [   32/  512]\n",
      "loss: 0.003317  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004336 \n",
      "\n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.004412  [   32/  512]\n",
      "loss: 0.007284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004584 \n",
      "\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.000180  [   32/  512]\n",
      "loss: 0.005232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003154 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004125 \n",
      "\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.000968  [   32/  512]\n",
      "loss: 0.000380  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004345 \n",
      "\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.004188  [   32/  512]\n",
      "loss: 0.012664  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003806 \n",
      "\n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.001907  [   32/  512]\n",
      "loss: 0.009520  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002953 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003990 \n",
      "\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.005810  [   32/  512]\n",
      "loss: 0.006980  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003290 \n",
      "\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.000248  [   32/  512]\n",
      "loss: 0.000838  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004239 \n",
      "\n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.000095  [   32/  512]\n",
      "loss: 0.000070  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003966 \n",
      "\n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.000224  [   32/  512]\n",
      "loss: 0.001936  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003723 \n",
      "\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000396  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004058 \n",
      "\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.003503  [   32/  512]\n",
      "loss: 0.000067  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004316 \n",
      "\n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.001740  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004841 \n",
      "\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.000525  [   32/  512]\n",
      "loss: 0.013398  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003928 \n",
      "\n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.002638  [   32/  512]\n",
      "loss: 0.000666  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003365 \n",
      "\n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000218  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004899 \n",
      "\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.006599  [   32/  512]\n",
      "loss: 0.001441  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004355 \n",
      "\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.001838  [   32/  512]\n",
      "loss: 0.000215  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004165 \n",
      "\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.002666  [   32/  512]\n",
      "loss: 0.000937  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003444 \n",
      "\n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.004798  [   32/  512]\n",
      "loss: 0.004719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004586 \n",
      "\n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.004674  [   32/  512]\n",
      "loss: 0.000577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003766 \n",
      "\n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.000059  [   32/  512]\n",
      "loss: 0.003380  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003365 \n",
      "\n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.002685  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004022 \n",
      "\n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.000880  [   32/  512]\n",
      "loss: 0.000083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003658 \n",
      "\n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.003606  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003450 \n",
      "\n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.000074  [   32/  512]\n",
      "loss: 0.000287  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003370 \n",
      "\n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.002446  [   32/  512]\n",
      "loss: 0.004359  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003616 \n",
      "\n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.004378  [   32/  512]\n",
      "loss: 0.000483  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003439 \n",
      "\n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.004775  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004330 \n",
      "\n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.003073  [   32/  512]\n",
      "loss: 0.000193  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003357 \n",
      "\n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.000058  [   32/  512]\n",
      "loss: 0.000191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003965 \n",
      "\n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.007219  [   32/  512]\n",
      "loss: 0.000219  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004230 \n",
      "\n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.003321  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003705 \n",
      "\n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.001020  [   32/  512]\n",
      "loss: 0.000186  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003095 \n",
      "\n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.006519  [   32/  512]\n",
      "loss: 0.003165  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004171 \n",
      "\n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.002849  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003424 \n",
      "\n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.000201  [   32/  512]\n",
      "loss: 0.005537  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004160 \n",
      "\n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003204 \n",
      "\n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.000384  [   32/  512]\n",
      "loss: 0.009612  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.001695  [   32/  512]\n",
      "loss: 0.006795  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003169 \n",
      "\n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000247  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003473 \n",
      "\n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.003372  [   32/  512]\n",
      "loss: 0.003552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003093 \n",
      "\n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.000263  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003178 \n",
      "\n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.005488  [   32/  512]\n",
      "loss: 0.000606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004139 \n",
      "\n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.003769  [   32/  512]\n",
      "loss: 0.001690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003187 \n",
      "\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.000249  [   32/  512]\n",
      "loss: 0.002800  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002859 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003102 \n",
      "\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.003269  [   32/  512]\n",
      "loss: 0.004746  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003033 \n",
      "\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.000181  [   32/  512]\n",
      "loss: 0.001931  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003528 \n",
      "\n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.001656  [   32/  512]\n",
      "loss: 0.000232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003757 \n",
      "\n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.002053  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003614 \n",
      "\n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.005188  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003580 \n",
      "\n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003999 \n",
      "\n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003474 \n",
      "\n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.000319  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.001151  [   32/  512]\n",
      "loss: 0.001570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003217 \n",
      "\n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.003004  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003808 \n",
      "\n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.005752  [   32/  512]\n",
      "loss: 0.001616  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002622 \n",
      "\n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.001680  [   32/  512]\n",
      "loss: 0.012328  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003604 \n",
      "\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.000892  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003385 \n",
      "\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003055 \n",
      "\n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.005664  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003403 \n",
      "\n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.000229  [   32/  512]\n",
      "loss: 0.000696  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003201 \n",
      "\n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.001031  [   32/  512]\n",
      "loss: 0.002993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003328 \n",
      "\n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.004126  [   32/  512]\n",
      "loss: 0.002288  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003252 \n",
      "\n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.001214  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003548 \n",
      "\n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.000128  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003134 \n",
      "\n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.000054  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003060 \n",
      "\n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.004328  [   32/  512]\n",
      "loss: 0.000181  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003471 \n",
      "\n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.000280  [   32/  512]\n",
      "loss: 0.003205  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003507 \n",
      "\n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.000089  [   32/  512]\n",
      "loss: 0.005861  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003378 \n",
      "\n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.008148  [   32/  512]\n",
      "loss: 0.001628  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003551 \n",
      "\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.005786  [   32/  512]\n",
      "loss: 0.000271  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004355 \n",
      "\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.003745  [   32/  512]\n",
      "loss: 0.000785  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003730 \n",
      "\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.000735  [   32/  512]\n",
      "loss: 0.000764  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002986 \n",
      "\n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.000882  [   32/  512]\n",
      "loss: 0.004548  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003419 \n",
      "\n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.000090  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003399 \n",
      "\n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.003633  [   32/  512]\n",
      "loss: 0.000135  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004465 \n",
      "\n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.003755  [   32/  512]\n",
      "loss: 0.000095  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002971 \n",
      "\n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.001245  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004157 \n",
      "\n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.000141  [   32/  512]\n",
      "loss: 0.006381  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003371 \n",
      "\n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.001736  [   32/  512]\n",
      "loss: 0.000667  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003279 \n",
      "\n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.000377  [   32/  512]\n",
      "loss: 0.001036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002262 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003715 \n",
      "\n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002988 \n",
      "\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.004597  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003108 \n",
      "\n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.000743  [   32/  512]\n",
      "loss: 0.003765  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004055 \n",
      "\n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.002987  [   32/  512]\n",
      "loss: 0.004856  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.000027  [   32/  512]\n",
      "loss: 0.000277  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003283 \n",
      "\n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.003520  [   32/  512]\n",
      "loss: 0.003165  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001995 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004331 \n",
      "\n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.008510  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003480 \n",
      "\n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.005951  [   32/  512]\n",
      "loss: 0.005016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002947 \n",
      "\n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.000134  [   32/  512]\n",
      "loss: 0.005315  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003520 \n",
      "\n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.000339  [   32/  512]\n",
      "loss: 0.000302  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003358 \n",
      "\n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.005096  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003436 \n",
      "\n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.000748  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002940 \n",
      "\n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.000115  [   32/  512]\n",
      "loss: 0.014115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003183 \n",
      "\n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.000100  [   32/  512]\n",
      "loss: 0.000294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003422 \n",
      "\n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.002022  [   32/  512]\n",
      "loss: 0.007570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003252 \n",
      "\n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.004485  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003012 \n",
      "\n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.003962  [   32/  512]\n",
      "loss: 0.000349  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003447 \n",
      "\n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000026  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003171 \n",
      "\n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.003170  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003359 \n",
      "\n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.003464  [   32/  512]\n",
      "loss: 0.000202  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004731 \n",
      "\n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.000103  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002618 \n",
      "\n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.000099  [   32/  512]\n",
      "loss: 0.001266  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003483 \n",
      "\n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.003657  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003654 \n",
      "\n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.004820  [   32/  512]\n",
      "loss: 0.005887  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002782 \n",
      "\n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.000171  [   32/  512]\n",
      "loss: 0.002576  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003588 \n",
      "\n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.002344  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003325 \n",
      "\n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.000141  [   32/  512]\n",
      "loss: 0.004176  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002479 \n",
      "\n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.000461  [   32/  512]\n",
      "loss: 0.003138  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002958 \n",
      "\n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.000591  [   32/  512]\n",
      "loss: 0.000288  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002701 \n",
      "\n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.002959  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003629 \n",
      "\n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000212  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003317 \n",
      "\n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.000474  [   32/  512]\n",
      "loss: 0.006200  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003234 \n",
      "\n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.000333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002630 \n",
      "\n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.000185  [   32/  512]\n",
      "loss: 0.001968  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003719 \n",
      "\n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.000689  [   32/  512]\n",
      "loss: 0.000270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003144 \n",
      "\n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.000287  [   32/  512]\n",
      "loss: 0.011265  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003229 \n",
      "\n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.000074  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.002485  [   32/  512]\n",
      "loss: 0.004831  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002672 \n",
      "\n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000386  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003288 \n",
      "\n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.002470  [   32/  512]\n",
      "loss: 0.003116  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003098 \n",
      "\n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.003103  [   32/  512]\n",
      "loss: 0.005616  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003572 \n",
      "\n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.000717  [   32/  512]\n",
      "loss: 0.000296  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002626 \n",
      "\n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.004144  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003059 \n",
      "\n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.007343  [   32/  512]\n",
      "loss: 0.000096  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003254 \n",
      "\n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.010695  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.000687  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003281 \n",
      "\n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.000653  [   32/  512]\n",
      "loss: 0.003348  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003620 \n",
      "\n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.006897  [   32/  512]\n",
      "loss: 0.002979  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002977 \n",
      "\n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.002954  [   32/  512]\n",
      "loss: 0.007114  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002841 \n",
      "\n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.004977  [   32/  512]\n",
      "loss: 0.000077  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001992 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003048 \n",
      "\n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.001119  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003221 \n",
      "\n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.006237  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003454 \n",
      "\n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.002977  [   32/  512]\n",
      "loss: 0.011074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002480 \n",
      "\n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.000068  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004000 \n",
      "\n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.007032  [   32/  512]\n",
      "loss: 0.000850  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002295 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002275 \n",
      "\n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.009418  [   32/  512]\n",
      "loss: 0.000457  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003248 \n",
      "\n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.001568  [   32/  512]\n",
      "loss: 0.001414  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003220 \n",
      "\n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.000727  [   32/  512]\n",
      "loss: 0.000064  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002750 \n",
      "\n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.002503  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003103 \n",
      "\n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.000652  [   32/  512]\n",
      "loss: 0.000280  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003466 \n",
      "\n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.000058  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002608 \n",
      "\n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.000113  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.004648  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002816 \n",
      "\n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.000248  [   32/  512]\n",
      "loss: 0.004269  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003762 \n",
      "\n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.001280  [   32/  512]\n",
      "loss: 0.011427  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.000109  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003003 \n",
      "\n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002981 \n",
      "\n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.000930  [   32/  512]\n",
      "loss: 0.004735  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002962 \n",
      "\n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.001183  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002840 \n",
      "\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.001058  [   32/  512]\n",
      "loss: 0.000823  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002972 \n",
      "\n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.000046  [   32/  512]\n",
      "loss: 0.001083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002927 \n",
      "\n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.000175  [   32/  512]\n",
      "loss: 0.000423  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002828 \n",
      "\n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.002359  [   32/  512]\n",
      "loss: 0.002836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001621 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003190 \n",
      "\n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.010554  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002935 \n",
      "\n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.000949  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002992 \n",
      "\n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.002621  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003162 \n",
      "\n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.002033  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002960 \n",
      "\n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.004158  [   32/  512]\n",
      "loss: 0.000100  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.000967  [   32/  512]\n",
      "loss: 0.000205  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003308 \n",
      "\n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002840 \n",
      "\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.003823  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002502 \n",
      "\n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.000349  [   32/  512]\n",
      "loss: 0.007235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002025 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003255 \n",
      "\n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.003049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002341 \n",
      "\n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.014579  [   32/  512]\n",
      "loss: 0.000969  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004131 \n",
      "\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.000625  [   32/  512]\n",
      "loss: 0.003449  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002844 \n",
      "\n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.004039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003196 \n",
      "\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.001007  [   32/  512]\n",
      "loss: 0.007141  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002588 \n",
      "\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.000050  [   32/  512]\n",
      "loss: 0.007084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002824 \n",
      "\n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.000065  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002991 \n",
      "\n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.000836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002222 \n",
      "\n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.000081  [   32/  512]\n",
      "loss: 0.006968  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001741 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003245 \n",
      "\n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.004006  [   32/  512]\n",
      "loss: 0.000279  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002836 \n",
      "\n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001860 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002318 \n",
      "\n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.006989  [   32/  512]\n",
      "loss: 0.000547  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003072 \n",
      "\n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.002897  [   32/  512]\n",
      "loss: 0.000237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.003774  [   32/  512]\n",
      "loss: 0.000237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002705 \n",
      "\n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.003599  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003302 \n",
      "\n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.002600  [   32/  512]\n",
      "loss: 0.004563  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002601 \n",
      "\n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002906 \n",
      "\n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.002692  [   32/  512]\n",
      "loss: 0.000007  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002813 \n",
      "\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.003607  [   32/  512]\n",
      "loss: 0.005635  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003392 \n",
      "\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.000182  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002587 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002443 \n",
      "\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.008622  [   32/  512]\n",
      "loss: 0.001055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003076 \n",
      "\n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.000097  [   32/  512]\n",
      "loss: 0.001026  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002867 \n",
      "\n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.005287  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002835 \n",
      "\n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.001948  [   32/  512]\n",
      "loss: 0.000254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002537 \n",
      "\n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002882 \n",
      "\n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.000191  [   32/  512]\n",
      "loss: 0.000930  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002879 \n",
      "\n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.000649  [   32/  512]\n",
      "loss: 0.017955  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002630 \n",
      "\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.002771  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004116 \n",
      "\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.000295  [   32/  512]\n",
      "loss: 0.000106  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002229 \n",
      "\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.004479  [   32/  512]\n",
      "loss: 0.000218  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002754 \n",
      "\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.002595  [   32/  512]\n",
      "loss: 0.000071  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002525 \n",
      "\n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002971 \n",
      "\n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002668 \n",
      "\n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.004498  [   32/  512]\n",
      "loss: 0.005671  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003070 \n",
      "\n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.003645  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002655 \n",
      "\n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000238  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002823 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002796 \n",
      "\n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.001907  [   32/  512]\n",
      "loss: 0.000191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002338 \n",
      "\n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003620 \n",
      "\n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.000079  [   32/  512]\n",
      "loss: 0.005273  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002386 \n",
      "\n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.002579  [   32/  512]\n",
      "loss: 0.000190  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001627 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002732 \n",
      "\n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.001309  [   32/  512]\n",
      "loss: 0.000013  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003253 \n",
      "\n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.000031  [   32/  512]\n",
      "loss: 0.000015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002702 \n",
      "\n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002444 \n",
      "\n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.000375  [   32/  512]\n",
      "loss: 0.001939  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001734 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002933 \n",
      "\n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.000146  [   32/  512]\n",
      "loss: 0.007539  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002919 \n",
      "\n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.003046  [   32/  512]\n",
      "loss: 0.000535  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002876 \n",
      "\n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.000973  [   32/  512]\n",
      "loss: 0.011194  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003505 \n",
      "\n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002518 \n",
      "\n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.000160  [   32/  512]\n",
      "loss: 0.000062  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003003 \n",
      "\n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.000218  [   32/  512]\n",
      "loss: 0.000143  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002963 \n",
      "\n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.005580  [   32/  512]\n",
      "loss: 0.003361  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003148 \n",
      "\n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.000180  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.003346  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003195 \n",
      "\n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.006277  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002865 \n",
      "\n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.004792  [   32/  512]\n",
      "loss: 0.000083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003141 \n",
      "\n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.004450  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002921 \n",
      "\n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.004649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002761 \n",
      "\n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.004857  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002602 \n",
      "\n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002805 \n",
      "\n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.002786  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002844 \n",
      "\n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.000025  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.005286  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002768 \n",
      "\n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.004879  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003349 \n",
      "\n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.000231  [   32/  512]\n",
      "loss: 0.000326  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002366 \n",
      "\n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.004653  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002988 \n",
      "\n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.000049  [   32/  512]\n",
      "loss: 0.000131  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.000276  [   32/  512]\n",
      "loss: 0.000417  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002102 \n",
      "\n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003433 \n",
      "\n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000057  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002716 \n",
      "\n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000358  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001565 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003082 \n",
      "\n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.000097  [   32/  512]\n",
      "loss: 0.005609  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.000178  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002518 \n",
      "\n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.002313  [   32/  512]\n",
      "loss: 0.003254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002603 \n",
      "\n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.000491  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002707 \n",
      "\n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.005115  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002540 \n",
      "\n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.004751  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003023 \n",
      "\n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002543 \n",
      "\n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.004612  [   32/  512]\n",
      "loss: 0.000972  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.000216  [   32/  512]\n",
      "loss: 0.000059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002897 \n",
      "\n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.005940  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002353 \n",
      "\n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003076 \n",
      "\n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.000372  [   32/  512]\n",
      "loss: 0.005705  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002649 \n",
      "\n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.002953  [   32/  512]\n",
      "loss: 0.000991  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002372 \n",
      "\n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.005905  [   32/  512]\n",
      "loss: 0.000154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001437 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003042 \n",
      "\n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.001771  [   32/  512]\n",
      "loss: 0.000177  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002512 \n",
      "\n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.000151  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002274 \n",
      "\n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.002143  [   32/  512]\n",
      "loss: 0.000031  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002820 \n",
      "\n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.007808  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002618 \n",
      "\n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.000066  [   32/  512]\n",
      "loss: 0.006119  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002437 \n",
      "\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.000186  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003043 \n",
      "\n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.000108  [   32/  512]\n",
      "loss: 0.000258  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001334 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002388 \n",
      "\n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.005048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002572 \n",
      "\n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.000091  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.000295  [   32/  512]\n",
      "loss: 0.000318  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003264 \n",
      "\n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.002696  [   32/  512]\n",
      "loss: 0.000836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002624 \n",
      "\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.000290  [   32/  512]\n",
      "loss: 0.016493  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003056 \n",
      "\n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.000159  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002753 \n",
      "\n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.000048  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002443 \n",
      "\n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.003394  [   32/  512]\n",
      "loss: 0.000101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002571 \n",
      "\n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.001696  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001830 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003200 \n",
      "\n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.000207  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002274 \n",
      "\n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.001187  [   32/  512]\n",
      "loss: 0.000602  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002520 \n",
      "\n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002696 \n",
      "\n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.003780  [   32/  512]\n",
      "loss: 0.000235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002876 \n",
      "\n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.001067  [   32/  512]\n",
      "loss: 0.002526  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001557 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002570 \n",
      "\n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.001080  [   32/  512]\n",
      "loss: 0.002438  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002838 \n",
      "\n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.000122  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002194 \n",
      "\n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002855 \n",
      "\n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.000962  [   32/  512]\n",
      "loss: 0.007834  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002519 \n",
      "\n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.000038  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002471 \n",
      "\n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.002152  [   32/  512]\n",
      "loss: 0.002140  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.008517  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002088 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002812 \n",
      "\n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.002193  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.000207  [   32/  512]\n",
      "loss: 0.000774  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002761 \n",
      "\n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.004320  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002915 \n",
      "\n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.000380  [   32/  512]\n",
      "loss: 0.000206  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002924 \n",
      "\n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000451  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002461 \n",
      "\n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.001727  [   32/  512]\n",
      "loss: 0.010482  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001721 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002887 \n",
      "\n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.004763  [   32/  512]\n",
      "loss: 0.011040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.000138  [   32/  512]\n",
      "loss: 0.010816  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002319 \n",
      "\n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.000167  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002638 \n",
      "\n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002450 \n",
      "\n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.003784  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001254 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002321 \n",
      "\n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.003997  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002563 \n",
      "\n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002411 \n",
      "\n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.000103  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002311 \n",
      "\n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002727 \n",
      "\n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002414 \n",
      "\n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002717  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.002475  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002773 \n",
      "\n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.005146  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002256 \n",
      "\n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.000500  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003403 \n",
      "\n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.000205  [   32/  512]\n",
      "loss: 0.000056  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002267 \n",
      "\n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.000162  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003265 \n",
      "\n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.000130  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002477 \n",
      "\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.000058  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002641 \n",
      "\n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.000278  [   32/  512]\n",
      "loss: 0.000352  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002615 \n",
      "\n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.000502  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002715 \n",
      "\n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.002557  [   32/  512]\n",
      "loss: 0.000073  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002854 \n",
      "\n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.003041  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001421 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002332 \n",
      "\n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.004218  [   32/  512]\n",
      "loss: 0.001067  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002522 \n",
      "\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002578 \n",
      "\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.000096  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002264 \n",
      "\n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.000146  [   32/  512]\n",
      "loss: 0.000639  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002477 \n",
      "\n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.000184  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003077 \n",
      "\n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.002389  [   32/  512]\n",
      "loss: 0.002081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002323 \n",
      "\n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.000202  [   32/  512]\n",
      "loss: 0.000197  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002331 \n",
      "\n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003231 \n",
      "\n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.000096  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002551 \n",
      "\n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.004026  [   32/  512]\n",
      "loss: 0.005047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002795 \n",
      "\n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.002965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002385 \n",
      "\n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000050  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002468 \n",
      "\n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.004385  [   32/  512]\n",
      "loss: 0.006570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002410 \n",
      "\n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.004656  [   32/  512]\n",
      "loss: 0.002015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002309 \n",
      "\n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002832 \n",
      "\n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002271 \n",
      "\n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.003855  [   32/  512]\n",
      "loss: 0.000105  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002734 \n",
      "\n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.001467  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.003903  [   32/  512]\n",
      "loss: 0.001094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002263 \n",
      "\n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002916 \n",
      "\n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.000220  [   32/  512]\n",
      "loss: 0.000263  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.002044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002897 \n",
      "\n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.000411  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002190 \n",
      "\n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.003367  [   32/  512]\n",
      "loss: 0.004518  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002950 \n",
      "\n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000183  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.002229  [   32/  512]\n",
      "loss: 0.000097  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.000250  [   32/  512]\n",
      "loss: 0.000282  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002485 \n",
      "\n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.000117  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002899 \n",
      "\n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.001934  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002197 \n",
      "\n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.001036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001343 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000174  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.002155  [   32/  512]\n",
      "loss: 0.001641  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002692 \n",
      "\n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.000182  [   32/  512]\n",
      "loss: 0.000132  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001617 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002249 \n",
      "\n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.003864  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002651 \n",
      "\n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.001618  [   32/  512]\n",
      "loss: 0.000775  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002290 \n",
      "\n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.001445  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002488 \n",
      "\n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.000869  [   32/  512]\n",
      "loss: 0.003158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002091 \n",
      "\n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.000201  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002556 \n",
      "\n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.008570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002286 \n",
      "\n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000454  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002362 \n",
      "\n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.003606  [   32/  512]\n",
      "loss: 0.000123  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003155 \n",
      "\n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.004144  [   32/  512]\n",
      "loss: 0.000091  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002442 \n",
      "\n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.000219  [   32/  512]\n",
      "loss: 0.000152  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002517 \n",
      "\n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002168 \n",
      "\n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000967  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.000193  [   32/  512]\n",
      "loss: 0.000199  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002121 \n",
      "\n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.000037  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002632 \n",
      "\n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.000140  [   32/  512]\n",
      "loss: 0.001764  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001318 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002292 \n",
      "\n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.000031  [   32/  512]\n",
      "loss: 0.008438  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002279 \n",
      "\n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.000112  [   32/  512]\n",
      "loss: 0.000451  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002392 \n",
      "\n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.001217  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002686 \n",
      "\n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.002324  [   32/  512]\n",
      "loss: 0.000089  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002636 \n",
      "\n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.001470  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003929 \n",
      "\n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.000197  [   32/  512]\n",
      "loss: 0.005075  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001973 \n",
      "\n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.001162  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002296 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003321 \n",
      "\n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002616 \n",
      "\n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002502 \n",
      "\n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002529 \n",
      "\n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.000397  [   32/  512]\n",
      "loss: 0.002481  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003329 \n",
      "\n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002128 \n",
      "\n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.000816  [   32/  512]\n",
      "loss: 0.000044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.003337  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002459 \n",
      "\n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.000513  [   32/  512]\n",
      "loss: 0.002948  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002327 \n",
      "\n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.000140  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002429 \n",
      "\n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002307 \n",
      "\n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.010158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002432 \n",
      "\n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.000098  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002051 \n",
      "\n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002067 \n",
      "\n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.000105  [   32/  512]\n",
      "loss: 0.003803  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002093 \n",
      "\n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.000043  [   32/  512]\n",
      "loss: 0.000044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002448 \n",
      "\n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.001935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002604 \n",
      "\n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.001158  [   32/  512]\n",
      "loss: 0.000125  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002234 \n",
      "\n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.002763  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002953 \n",
      "\n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.000119  [   32/  512]\n",
      "loss: 0.000962  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002216 \n",
      "\n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.002397  [   32/  512]\n",
      "loss: 0.000074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002624 \n",
      "\n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002168 \n",
      "\n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.006867  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002748 \n",
      "\n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.002863  [   32/  512]\n",
      "loss: 0.000225  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002405 \n",
      "\n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.001646  [   32/  512]\n",
      "loss: 0.000776  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002248 \n",
      "\n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.000165  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000980 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002530 \n",
      "\n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.000183  [   32/  512]\n",
      "loss: 0.010580  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002658 \n",
      "\n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.000493  [   32/  512]\n",
      "loss: 0.005280  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002834 \n",
      "\n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.000209  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.006209  [   32/  512]\n",
      "loss: 0.000346  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003425 \n",
      "\n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.010927  [   32/  512]\n",
      "loss: 0.000202  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002548 \n",
      "\n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.000160  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003063 \n",
      "\n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.002254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.004241  [   32/  512]\n",
      "loss: 0.001232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001738 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002314 \n",
      "\n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.002524  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002240 \n",
      "\n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002180 \n",
      "\n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.005056  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002702  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.007942  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002449 \n",
      "\n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002231 \n",
      "\n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.007014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002612 \n",
      "\n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.007601  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002070 \n",
      "\n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002353 \n",
      "\n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.002761  [   32/  512]\n",
      "loss: 0.004266  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002359 \n",
      "\n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.000149  [   32/  512]\n",
      "loss: 0.006518  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000824  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002240 \n",
      "\n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.000057  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002381 \n",
      "\n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.013993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002269 \n",
      "\n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.000671  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002508 \n",
      "\n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.000044  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001192 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.003147  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002220 \n",
      "\n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.009003  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001170 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002171 \n",
      "\n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002449 \n",
      "\n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002582 \n",
      "\n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000967  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001306 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002219 \n",
      "\n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.001168  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002661 \n",
      "\n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.000599  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.004832  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002249 \n",
      "\n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.001375  [   32/  512]\n",
      "loss: 0.003491  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002319 \n",
      "\n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.002525  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002241 \n",
      "\n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002076 \n",
      "\n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.004760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002588 \n",
      "\n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.006490  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.006177  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.004890  [   32/  512]\n",
      "loss: 0.002793  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002234 \n",
      "\n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002344 \n",
      "\n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.000176  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001252 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002281 \n",
      "\n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000257  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001291 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002619 \n",
      "\n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.001080  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001138 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002294 \n",
      "\n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002211 \n",
      "\n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.003973  [   32/  512]\n",
      "loss: 0.009651  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002450 \n",
      "\n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002333 \n",
      "\n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.003501  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001261 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002265 \n",
      "\n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.000019  [   32/  512]\n",
      "loss: 0.002953  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000953 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002160 \n",
      "\n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.008517  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002243 \n",
      "\n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.003217  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002265 \n",
      "\n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.000283  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000095  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002447 \n",
      "\n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.004044  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002263 \n",
      "\n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000400  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002403 \n",
      "\n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002196 \n",
      "\n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.000100  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002233 \n",
      "\n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.004700  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002176 \n",
      "\n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.000292  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001155 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002314 \n",
      "\n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.001468  [   32/  512]\n",
      "loss: 0.004556  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002228 \n",
      "\n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.000070  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002088 \n",
      "\n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002054 \n",
      "\n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.000092  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002440 \n",
      "\n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.000029  [   32/  512]\n",
      "loss: 0.001000  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002294 \n",
      "\n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.007232  [   32/  512]\n",
      "loss: 0.007552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002178 \n",
      "\n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.000008  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002255 \n",
      "\n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002344 \n",
      "\n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.001050  [   32/  512]\n",
      "loss: 0.009519  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002164 \n",
      "\n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002130 \n",
      "\n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.002356  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001342 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002196 \n",
      "\n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.002491  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002226 \n",
      "\n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.000492  [   32/  512]\n",
      "loss: 0.002648  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000989 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002374 \n",
      "\n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.001658  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002214 \n",
      "\n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002261 \n",
      "\n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.004363  [   32/  512]\n",
      "loss: 0.000107  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.000043  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002345 \n",
      "\n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000091  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002312 \n",
      "\n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.001325  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002318 \n",
      "\n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002242 \n",
      "\n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002253 \n",
      "\n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.000066  [   32/  512]\n",
      "loss: 0.003784  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002527 \n",
      "\n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.002221  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002381 \n",
      "\n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.005735  [   32/  512]\n",
      "loss: 0.000108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002342 \n",
      "\n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.000033  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002349 \n",
      "\n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.001404  [   32/  512]\n",
      "loss: 0.007687  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002202 \n",
      "\n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.012965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002390 \n",
      "\n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002341 \n",
      "\n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.000125  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002288 \n",
      "\n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.000048  [   32/  512]\n",
      "loss: 0.002313  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002324 \n",
      "\n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.000106  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002375 \n",
      "\n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.004561  [   32/  512]\n",
      "loss: 0.001957  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002193 \n",
      "\n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000056  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002284 \n",
      "\n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.004231  [   32/  512]\n",
      "loss: 0.000291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002647 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003025 \n",
      "\n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002296 \n",
      "\n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002595 \n",
      "\n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000076  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002267 \n",
      "\n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.002993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002271 \n",
      "\n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.000060  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002569 \n",
      "\n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.000130  [   32/  512]\n",
      "loss: 0.007409  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002608 \n",
      "\n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.002782  [   32/  512]\n",
      "loss: 0.003171  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000357  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002637 \n",
      "\n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.000312  [   32/  512]\n",
      "loss: 0.001085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002651 \n",
      "\n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.000875  [   32/  512]\n",
      "loss: 0.000176  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002714 \n",
      "\n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.000525  [   32/  512]\n",
      "loss: 0.005868  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002215 \n",
      "\n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002247 \n",
      "\n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.004192  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002316 \n",
      "\n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.005749  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002428 \n",
      "\n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.000910  [   32/  512]\n",
      "loss: 0.000748  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002384 \n",
      "\n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.000098  [   32/  512]\n",
      "loss: 0.001606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002418 \n",
      "\n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.000090  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002468 \n",
      "\n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.009391  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002358 \n",
      "\n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.005183  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002545 \n",
      "\n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002367 \n",
      "\n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.002261  [   32/  512]\n",
      "loss: 0.012603  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002478 \n",
      "\n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.000019  [   32/  512]\n",
      "loss: 0.001757  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002360 \n",
      "\n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.000382  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002402 \n",
      "\n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.003557  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001272 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.001444  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001131 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000064  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002553 \n",
      "\n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002326 \n",
      "\n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.000004  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002226 \n",
      "\n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.000467  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002782 \n",
      "\n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.000086  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001864 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002348 \n",
      "\n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.000220  [   32/  512]\n",
      "loss: 0.019333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002278 \n",
      "\n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.012722  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002366 \n",
      "\n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.000054  [   32/  512]\n",
      "loss: 0.001702  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000971 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002419 \n",
      "\n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.001123  [   32/  512]\n",
      "loss: 0.003823  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004106 \n",
      "\n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002352 \n",
      "\n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.009306  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001566 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002392 \n",
      "\n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.002580  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002536 \n",
      "\n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.000331  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002331 \n",
      "\n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.000158  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002441 \n",
      "\n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.000670  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000925 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002178 \n",
      "\n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000144  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.000283  [   32/  512]\n",
      "loss: 0.010993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002455 \n",
      "\n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.003027  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002423 \n",
      "\n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002692 \n",
      "\n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.000716  [   32/  512]\n",
      "loss: 0.000077  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002428 \n",
      "\n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002445 \n",
      "\n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.003116  [   32/  512]\n",
      "loss: 0.003149  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002323 \n",
      "\n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.000988  [   32/  512]\n",
      "loss: 0.000093  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002791 \n",
      "\n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.000128  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002332 \n",
      "\n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.000046  [   32/  512]\n",
      "loss: 0.001391  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002684 \n",
      "\n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000013  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000803  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002500 \n",
      "\n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.000749  [   32/  512]\n",
      "loss: 0.000073  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002497 \n",
      "\n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.000250  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002289 \n",
      "\n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.000006  [   32/  512]\n",
      "loss: 0.008786  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002688 \n",
      "\n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002333 \n",
      "\n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.009540  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002726 \n",
      "\n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.000120  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002600 \n",
      "\n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.001525  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.000171  [   32/  512]\n",
      "loss: 0.003727  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.006013  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002327 \n",
      "\n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.000095  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002462 \n",
      "\n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000424  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002379 \n",
      "\n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.000505  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002478 \n",
      "\n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.002110  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.000729  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002322 \n",
      "\n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.000091  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002527 \n",
      "\n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000062  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002801 \n",
      "\n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.003285  [   32/  512]\n",
      "loss: 0.000238  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.003508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004958 \n",
      "\n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.000131  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002458 \n",
      "\n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.000148  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002875 \n",
      "\n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.000079  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002387 \n",
      "\n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.007213  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002417 \n",
      "\n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002454 \n",
      "\n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.000423  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002355 \n",
      "\n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002573 \n",
      "\n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.007507  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002316 \n",
      "\n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.005166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002398 \n",
      "\n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002407 \n",
      "\n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.000087  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002670 \n",
      "\n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.000178  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002732 \n",
      "\n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.000154  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002305 \n",
      "\n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.000236  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002759 \n",
      "\n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000325  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002499 \n",
      "\n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.000267  [   32/  512]\n",
      "loss: 0.003051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002457 \n",
      "\n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.001829  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002592 \n",
      "\n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000134  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002589 \n",
      "\n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.001879  [   32/  512]\n",
      "loss: 0.000299  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.003381  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002522 \n",
      "\n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.001997  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.001696  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002699 \n",
      "\n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.001522  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002599 \n",
      "\n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002406 \n",
      "\n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002416 \n",
      "\n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.002965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002558 \n",
      "\n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.003095  [   32/  512]\n",
      "loss: 0.003738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002532 \n",
      "\n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.002041  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002512 \n",
      "\n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.000149  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002550 \n",
      "\n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000955 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002485 \n",
      "\n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.001127  [   32/  512]\n",
      "loss: 0.003404  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002657 \n",
      "\n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.000049  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002409 \n",
      "\n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.000009  [   32/  512]\n",
      "loss: 0.000008  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002705 \n",
      "\n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.001219  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002551 \n",
      "\n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.009353  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002247 \n",
      "\n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000231  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002655 \n",
      "\n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.000371  [   32/  512]\n",
      "loss: 0.005474  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001214 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002696 \n",
      "\n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.000219  [   32/  512]\n",
      "loss: 0.000149  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000994 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.000463  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002461 \n",
      "\n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002609 \n",
      "\n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.000221  [   32/  512]\n",
      "loss: 0.007211  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.000068  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002650 \n",
      "\n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.000079  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002606 \n",
      "\n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002650 \n",
      "\n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002613 \n",
      "\n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.000070  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002666 \n",
      "\n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.000138  [   32/  512]\n",
      "loss: 0.009898  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002603 \n",
      "\n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.005192  [   32/  512]\n",
      "loss: 0.000081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002666 \n",
      "\n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000114  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002543 \n",
      "\n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002804 \n",
      "\n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.000287  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002865 \n",
      "\n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.000186  [   32/  512]\n",
      "loss: 0.000221  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002639 \n",
      "\n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.000050  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002467 \n",
      "\n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.003051  [   32/  512]\n",
      "loss: 0.002030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002802 \n",
      "\n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000145  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001111 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002534 \n",
      "\n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.007150  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002587 \n",
      "\n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.001639  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002701 \n",
      "\n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.002351  [   32/  512]\n",
      "loss: 0.000066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002673 \n",
      "\n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002704 \n",
      "\n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.003827  [   32/  512]\n",
      "loss: 0.000354  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003645 \n",
      "\n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.014025  [   32/  512]\n",
      "loss: 0.017503  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.003172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002538 \n",
      "\n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.006959  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001779 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003204 \n",
      "\n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.004426  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002954 \n",
      "\n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.000223  [   32/  512]\n",
      "loss: 0.000993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002850 \n",
      "\n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.006251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.002018  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002612 \n",
      "\n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.000057  [   32/  512]\n",
      "loss: 0.000124  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002754 \n",
      "\n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.003334  [   32/  512]\n",
      "loss: 0.002224  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002804 \n",
      "\n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.000105  [   32/  512]\n",
      "loss: 0.003557  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002565 \n",
      "\n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.003331  [   32/  512]\n",
      "loss: 0.000031  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002670 \n",
      "\n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.001317  [   32/  512]\n",
      "loss: 0.000101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002661 \n",
      "\n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.000033  [   32/  512]\n",
      "loss: 0.001306  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002639 \n",
      "\n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.006022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002868 \n",
      "\n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.001074  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.000040  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002711 \n",
      "\n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.001160  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002662 \n",
      "\n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002308  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002740 \n",
      "\n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.000037  [   32/  512]\n",
      "loss: 0.000070  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002653 \n",
      "\n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002656 \n",
      "\n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.002984  [   32/  512]\n",
      "loss: 0.001055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002691 \n",
      "\n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.000649  [   32/  512]\n",
      "loss: 0.004999  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002749 \n",
      "\n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.000875  [   32/  512]\n",
      "loss: 0.000285  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002877 \n",
      "\n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.000476  [   32/  512]\n",
      "loss: 0.003066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002687 \n",
      "\n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002940 \n",
      "\n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002673 \n",
      "\n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.000015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002728 \n",
      "\n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.005821  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002774 \n",
      "\n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.001447  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002486 \n",
      "\n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002845 \n",
      "\n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000006  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002868 \n",
      "\n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002837 \n",
      "\n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002784 \n",
      "\n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.000104  [   32/  512]\n",
      "loss: 0.003512  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002653 \n",
      "\n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.002739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002628 \n",
      "\n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.000157  [   32/  512]\n",
      "loss: 0.000005  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002695 \n",
      "\n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002713 \n",
      "\n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000076  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002822 \n",
      "\n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.000056  [   32/  512]\n",
      "loss: 0.007071  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002733 \n",
      "\n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.001818  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002766 \n",
      "\n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.003769  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002815 \n",
      "\n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.002770  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.001920  [   32/  512]\n",
      "loss: 0.009448  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002722 \n",
      "\n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.003496  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002721 \n",
      "\n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002825 \n",
      "\n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.001171  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002809 \n",
      "\n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.002203  [   32/  512]\n",
      "loss: 0.000108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002835 \n",
      "\n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.000741  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002767 \n",
      "\n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.007560  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002585 \n",
      "\n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003134 \n",
      "\n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.001366  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002774 \n",
      "\n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.003964  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002411 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002900 \n",
      "\n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000143  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003247 \n",
      "\n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002964 \n",
      "\n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.005012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002694 \n",
      "\n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.000133  [   32/  512]\n",
      "loss: 0.000174  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.000731  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002770 \n",
      "\n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002961 \n",
      "\n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.000707  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002679 \n",
      "\n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003004 \n",
      "\n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.004006  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002756 \n",
      "\n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.000065  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002640 \n",
      "\n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.002456  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002925 \n",
      "\n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003022 \n",
      "\n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.000056  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003015 \n",
      "\n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.000089  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.003381  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003002 \n",
      "\n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.000277  [   32/  512]\n",
      "loss: 0.000354  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003107 \n",
      "\n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.000059  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001435 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003170 \n",
      "\n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.000958  [   32/  512]\n",
      "loss: 0.000150  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002883 \n",
      "\n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.000270  [   32/  512]\n",
      "loss: 0.006014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003143 \n",
      "\n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.002939  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003158 \n",
      "\n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.000075  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003200 \n",
      "\n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002846 \n",
      "\n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.000044  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003049 \n",
      "\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 1000 # poner mas\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss, accuracy = train_loop(dataloader, model, loss_fn, optimizer)\n",
    "    print(f\"\\nTraining Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {loss:>8f} \\n\")\n",
    "    \n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3920, -2.2971]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.3600],\n",
       "        [0.6200],\n",
       "        [0.8800],\n",
       "        [1.1400],\n",
       "        [1.4000],\n",
       "        [1.6600],\n",
       "        [1.9200],\n",
       "        [2.1800],\n",
       "        [2.4400],\n",
       "        [2.7000],\n",
       "        [2.9600],\n",
       "        [3.2200],\n",
       "        [3.4800],\n",
       "        [3.7400],\n",
       "        [4.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_test = torch.tensor(np.linspace(0.1, 4, 16).reshape((-1, 1)), dtype=torch.float64)\n",
    "u_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora probamos como funciona para un x nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5031e-06, 5.2914e-06],\n",
       "        [5.8791e-06, 5.0125e-06],\n",
       "        [6.2946e-06, 4.1114e-06],\n",
       "        [1.5288e-05, 6.1703e-06],\n",
       "        [6.3201e-05, 7.6848e-06],\n",
       "        [2.8571e+00, 7.7249e-06],\n",
       "        [2.4096e+00, 8.3817e-06],\n",
       "        [2.0833e+00, 1.4402e-05],\n",
       "        [1.8349e+00, 1.8074e+00],\n",
       "        [1.6393e+00, 2.2303e+00],\n",
       "        [6.9978e-05, 3.3749e+00],\n",
       "        [1.2749e-05, 3.7000e+00],\n",
       "        [6.8515e-06, 4.0250e+00],\n",
       "        [1.1909e-05, 1.8498e-05],\n",
       "        [2.2888e-04, 1.3794e-05],\n",
       "        [9.9999e-01, 1.9565e-05]], dtype=torch.float64)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_test])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametricLPNet(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500]], dtype=torch.float64),\n",
       " tensor([[5.6596e-06, 5.1630e-06]], dtype=torch.float64))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([[0.25]], dtype=torch.float64)\n",
    "x = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u])\n",
    "u,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[0.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = model(torch.tensor([[0.25]]))\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.6596e-06, 5.1630e-06]], dtype=torch.float64),\n",
       " tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>),\n",
       " tensor(1.3617, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x_pred, torch.norm(x - x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar:\n",
    "- Función de pérdida ✔️\n",
    "- Función smooth_lp (a ver si puedo sustituir la funcion smooth_lp por la funcion de linprog de deep_inv_opt)\n",
    "- Organizar y explicar el código\n",
    "- Estudiar por qué no disminuye el loss cuando entreno el modelo: es porque está mostrando el loss en el conjunto de test y no en el de entrenamiento ✔️\n",
    "- Entrenar el modelo con más épocas y datos\n",
    "- Pensar qué optimizador es mejor ✔️\n",
    "- Pensar qué estructura de la red es mejor ✔️\n",
    "- Inicialización de los pesos de la red ✔️\n",
    "- Arreglar el porcentaje de aciertos ✔️\n",
    "\n",
    "\n",
    "\n",
    "Bitácora: ahora lo que pasa es que da error porque el problema de optimización no está acotado, lo que tengo que hacer es revisar en el paper el intervalo donde se mueve la u porque creo que lo he puesto mal. Cuando arregle esto, tengo que volver a entrenar el modelo y ver si se está entrenando bien. También tengo que probar resolviendo el problema de optimización con la función de linprog de deep_inv_opt y con la de cvxpy a ver si alguna de las dos funciona mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
