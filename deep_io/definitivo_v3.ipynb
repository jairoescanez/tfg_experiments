{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versi√≥n no tiene nada especial, la red simplemente devuelve un vector x que supongo yo que es el minimo del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import deep_inv_opt as io\n",
    "import deep_inv_opt.plot as iop\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 0  # Let the plots flow!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5000],\n",
       "        [-1.4941],\n",
       "        [-1.4883],\n",
       "        [-1.4824],\n",
       "        [-1.4765],\n",
       "        [-1.4706],\n",
       "        [-1.4648],\n",
       "        [-1.4589],\n",
       "        [-1.4530],\n",
       "        [-1.4472],\n",
       "        [-1.4413],\n",
       "        [-1.4354],\n",
       "        [-1.4295],\n",
       "        [-1.4237],\n",
       "        [-1.4178],\n",
       "        [-1.4119],\n",
       "        [-1.4061],\n",
       "        [-1.4002],\n",
       "        [-1.3943],\n",
       "        [-1.3885],\n",
       "        [-1.3826],\n",
       "        [-1.3767],\n",
       "        [-1.3708],\n",
       "        [-1.3650],\n",
       "        [-1.3591],\n",
       "        [-1.3532],\n",
       "        [-1.3474],\n",
       "        [-1.3415],\n",
       "        [-1.3356],\n",
       "        [-1.3297],\n",
       "        [-1.3239],\n",
       "        [-1.3180],\n",
       "        [-1.3121],\n",
       "        [-1.3063],\n",
       "        [-1.3004],\n",
       "        [-1.2945],\n",
       "        [-1.2886],\n",
       "        [-1.2828],\n",
       "        [-1.2769],\n",
       "        [-1.2710],\n",
       "        [-1.2652],\n",
       "        [-1.2593],\n",
       "        [-1.2534],\n",
       "        [-1.2476],\n",
       "        [-1.2417],\n",
       "        [-1.2358],\n",
       "        [-1.2299],\n",
       "        [-1.2241],\n",
       "        [-1.2182],\n",
       "        [-1.2123],\n",
       "        [-1.2065],\n",
       "        [-1.2006],\n",
       "        [-1.1947],\n",
       "        [-1.1888],\n",
       "        [-1.1830],\n",
       "        [-1.1771],\n",
       "        [-1.1712],\n",
       "        [-1.1654],\n",
       "        [-1.1595],\n",
       "        [-1.1536],\n",
       "        [-1.1477],\n",
       "        [-1.1419],\n",
       "        [-1.1360],\n",
       "        [-1.1301],\n",
       "        [-1.1243],\n",
       "        [-1.1184],\n",
       "        [-1.1125],\n",
       "        [-1.1067],\n",
       "        [-1.1008],\n",
       "        [-1.0949],\n",
       "        [-1.0890],\n",
       "        [-1.0832],\n",
       "        [-1.0773],\n",
       "        [-1.0714],\n",
       "        [-1.0656],\n",
       "        [-1.0597],\n",
       "        [-1.0538],\n",
       "        [-1.0479],\n",
       "        [-1.0421],\n",
       "        [-1.0362],\n",
       "        [-1.0303],\n",
       "        [-1.0245],\n",
       "        [-1.0186],\n",
       "        [-1.0127],\n",
       "        [-1.0068],\n",
       "        [-1.0010],\n",
       "        [-0.9951],\n",
       "        [-0.9892],\n",
       "        [-0.9834],\n",
       "        [-0.9775],\n",
       "        [-0.9716],\n",
       "        [-0.9658],\n",
       "        [-0.9599],\n",
       "        [-0.9540],\n",
       "        [-0.9481],\n",
       "        [-0.9423],\n",
       "        [-0.9364],\n",
       "        [-0.9305],\n",
       "        [-0.9247],\n",
       "        [-0.9188],\n",
       "        [-0.9129],\n",
       "        [-0.9070],\n",
       "        [-0.9012],\n",
       "        [-0.8953],\n",
       "        [-0.8894],\n",
       "        [-0.8836],\n",
       "        [-0.8777],\n",
       "        [-0.8718],\n",
       "        [-0.8659],\n",
       "        [-0.8601],\n",
       "        [-0.8542],\n",
       "        [-0.8483],\n",
       "        [-0.8425],\n",
       "        [-0.8366],\n",
       "        [-0.8307],\n",
       "        [-0.8249],\n",
       "        [-0.8190],\n",
       "        [-0.8131],\n",
       "        [-0.8072],\n",
       "        [-0.8014],\n",
       "        [-0.7955],\n",
       "        [-0.7896],\n",
       "        [-0.7838],\n",
       "        [-0.7779],\n",
       "        [-0.7720],\n",
       "        [-0.7661],\n",
       "        [-0.7603],\n",
       "        [-0.7544],\n",
       "        [-0.7485],\n",
       "        [-0.7427],\n",
       "        [-0.7368],\n",
       "        [-0.7309],\n",
       "        [-0.7250],\n",
       "        [-0.7192],\n",
       "        [-0.7133],\n",
       "        [-0.7074],\n",
       "        [-0.7016],\n",
       "        [-0.6957],\n",
       "        [-0.6898],\n",
       "        [-0.6840],\n",
       "        [-0.6781],\n",
       "        [-0.6722],\n",
       "        [-0.6663],\n",
       "        [-0.6605],\n",
       "        [-0.6546],\n",
       "        [-0.6487],\n",
       "        [-0.6429],\n",
       "        [-0.6370],\n",
       "        [-0.6311],\n",
       "        [-0.6252],\n",
       "        [-0.6194],\n",
       "        [-0.6135],\n",
       "        [-0.6076],\n",
       "        [-0.6018],\n",
       "        [-0.5959],\n",
       "        [-0.5900],\n",
       "        [-0.5841],\n",
       "        [-0.5783],\n",
       "        [-0.5724],\n",
       "        [-0.5665],\n",
       "        [-0.5607],\n",
       "        [-0.5548],\n",
       "        [-0.5489],\n",
       "        [-0.5431],\n",
       "        [-0.5372],\n",
       "        [-0.5313],\n",
       "        [-0.5254],\n",
       "        [-0.5196],\n",
       "        [-0.5137],\n",
       "        [-0.5078],\n",
       "        [-0.5020],\n",
       "        [-0.4961],\n",
       "        [-0.4902],\n",
       "        [-0.4843],\n",
       "        [-0.4785],\n",
       "        [-0.4726],\n",
       "        [-0.4667],\n",
       "        [-0.4609],\n",
       "        [-0.4550],\n",
       "        [-0.4491],\n",
       "        [-0.4432],\n",
       "        [-0.4374],\n",
       "        [-0.4315],\n",
       "        [-0.4256],\n",
       "        [-0.4198],\n",
       "        [-0.4139],\n",
       "        [-0.4080],\n",
       "        [-0.4022],\n",
       "        [-0.3963],\n",
       "        [-0.3904],\n",
       "        [-0.3845],\n",
       "        [-0.3787],\n",
       "        [-0.3728],\n",
       "        [-0.3669],\n",
       "        [-0.3611],\n",
       "        [-0.3552],\n",
       "        [-0.3493],\n",
       "        [-0.3434],\n",
       "        [-0.3376],\n",
       "        [-0.3317],\n",
       "        [-0.3258],\n",
       "        [-0.3200],\n",
       "        [-0.3141],\n",
       "        [-0.3082],\n",
       "        [-0.3023],\n",
       "        [-0.2965],\n",
       "        [-0.2906],\n",
       "        [-0.2847],\n",
       "        [-0.2789],\n",
       "        [-0.2730],\n",
       "        [-0.2671],\n",
       "        [-0.2613],\n",
       "        [-0.2554],\n",
       "        [-0.2495],\n",
       "        [-0.2436],\n",
       "        [-0.2378],\n",
       "        [-0.2319],\n",
       "        [-0.2260],\n",
       "        [-0.2202],\n",
       "        [-0.2143],\n",
       "        [-0.2084],\n",
       "        [-0.2025],\n",
       "        [-0.1967],\n",
       "        [-0.1908],\n",
       "        [-0.1849],\n",
       "        [-0.1791],\n",
       "        [-0.1732],\n",
       "        [-0.1673],\n",
       "        [-0.1614],\n",
       "        [-0.1556],\n",
       "        [-0.1497],\n",
       "        [-0.1438],\n",
       "        [-0.1380],\n",
       "        [-0.1321],\n",
       "        [-0.1262],\n",
       "        [-0.1204],\n",
       "        [-0.1145],\n",
       "        [-0.1086],\n",
       "        [-0.1027],\n",
       "        [-0.0969],\n",
       "        [-0.0910],\n",
       "        [-0.0851],\n",
       "        [-0.0793],\n",
       "        [-0.0734],\n",
       "        [-0.0675],\n",
       "        [-0.0616],\n",
       "        [-0.0558],\n",
       "        [-0.0499],\n",
       "        [-0.0440],\n",
       "        [-0.0382],\n",
       "        [-0.0323],\n",
       "        [-0.0264],\n",
       "        [-0.0205],\n",
       "        [-0.0147],\n",
       "        [-0.0088],\n",
       "        [-0.0029],\n",
       "        [ 0.0029],\n",
       "        [ 0.0088],\n",
       "        [ 0.0147],\n",
       "        [ 0.0205],\n",
       "        [ 0.0264],\n",
       "        [ 0.0323],\n",
       "        [ 0.0382],\n",
       "        [ 0.0440],\n",
       "        [ 0.0499],\n",
       "        [ 0.0558],\n",
       "        [ 0.0616],\n",
       "        [ 0.0675],\n",
       "        [ 0.0734],\n",
       "        [ 0.0793],\n",
       "        [ 0.0851],\n",
       "        [ 0.0910],\n",
       "        [ 0.0969],\n",
       "        [ 0.1027],\n",
       "        [ 0.1086],\n",
       "        [ 0.1145],\n",
       "        [ 0.1204],\n",
       "        [ 0.1262],\n",
       "        [ 0.1321],\n",
       "        [ 0.1380],\n",
       "        [ 0.1438],\n",
       "        [ 0.1497],\n",
       "        [ 0.1556],\n",
       "        [ 0.1614],\n",
       "        [ 0.1673],\n",
       "        [ 0.1732],\n",
       "        [ 0.1791],\n",
       "        [ 0.1849],\n",
       "        [ 0.1908],\n",
       "        [ 0.1967],\n",
       "        [ 0.2025],\n",
       "        [ 0.2084],\n",
       "        [ 0.2143],\n",
       "        [ 0.2202],\n",
       "        [ 0.2260],\n",
       "        [ 0.2319],\n",
       "        [ 0.2378],\n",
       "        [ 0.2436],\n",
       "        [ 0.2495],\n",
       "        [ 0.2554],\n",
       "        [ 0.2613],\n",
       "        [ 0.2671],\n",
       "        [ 0.2730],\n",
       "        [ 0.2789],\n",
       "        [ 0.2847],\n",
       "        [ 0.2906],\n",
       "        [ 0.2965],\n",
       "        [ 0.3023],\n",
       "        [ 0.3082],\n",
       "        [ 0.3141],\n",
       "        [ 0.3200],\n",
       "        [ 0.3258],\n",
       "        [ 0.3317],\n",
       "        [ 0.3376],\n",
       "        [ 0.3434],\n",
       "        [ 0.3493],\n",
       "        [ 0.3552],\n",
       "        [ 0.3611],\n",
       "        [ 0.3669],\n",
       "        [ 0.3728],\n",
       "        [ 0.3787],\n",
       "        [ 0.3845],\n",
       "        [ 0.3904],\n",
       "        [ 0.3963],\n",
       "        [ 0.4022],\n",
       "        [ 0.4080],\n",
       "        [ 0.4139],\n",
       "        [ 0.4198],\n",
       "        [ 0.4256],\n",
       "        [ 0.4315],\n",
       "        [ 0.4374],\n",
       "        [ 0.4432],\n",
       "        [ 0.4491],\n",
       "        [ 0.4550],\n",
       "        [ 0.4609],\n",
       "        [ 0.4667],\n",
       "        [ 0.4726],\n",
       "        [ 0.4785],\n",
       "        [ 0.4843],\n",
       "        [ 0.4902],\n",
       "        [ 0.4961],\n",
       "        [ 0.5020],\n",
       "        [ 0.5078],\n",
       "        [ 0.5137],\n",
       "        [ 0.5196],\n",
       "        [ 0.5254],\n",
       "        [ 0.5313],\n",
       "        [ 0.5372],\n",
       "        [ 0.5431],\n",
       "        [ 0.5489],\n",
       "        [ 0.5548],\n",
       "        [ 0.5607],\n",
       "        [ 0.5665],\n",
       "        [ 0.5724],\n",
       "        [ 0.5783],\n",
       "        [ 0.5841],\n",
       "        [ 0.5900],\n",
       "        [ 0.5959],\n",
       "        [ 0.6018],\n",
       "        [ 0.6076],\n",
       "        [ 0.6135],\n",
       "        [ 0.6194],\n",
       "        [ 0.6252],\n",
       "        [ 0.6311],\n",
       "        [ 0.6370],\n",
       "        [ 0.6429],\n",
       "        [ 0.6487],\n",
       "        [ 0.6546],\n",
       "        [ 0.6605],\n",
       "        [ 0.6663],\n",
       "        [ 0.6722],\n",
       "        [ 0.6781],\n",
       "        [ 0.6840],\n",
       "        [ 0.6898],\n",
       "        [ 0.6957],\n",
       "        [ 0.7016],\n",
       "        [ 0.7074],\n",
       "        [ 0.7133],\n",
       "        [ 0.7192],\n",
       "        [ 0.7250],\n",
       "        [ 0.7309],\n",
       "        [ 0.7368],\n",
       "        [ 0.7427],\n",
       "        [ 0.7485],\n",
       "        [ 0.7544],\n",
       "        [ 0.7603],\n",
       "        [ 0.7661],\n",
       "        [ 0.7720],\n",
       "        [ 0.7779],\n",
       "        [ 0.7838],\n",
       "        [ 0.7896],\n",
       "        [ 0.7955],\n",
       "        [ 0.8014],\n",
       "        [ 0.8072],\n",
       "        [ 0.8131],\n",
       "        [ 0.8190],\n",
       "        [ 0.8249],\n",
       "        [ 0.8307],\n",
       "        [ 0.8366],\n",
       "        [ 0.8425],\n",
       "        [ 0.8483],\n",
       "        [ 0.8542],\n",
       "        [ 0.8601],\n",
       "        [ 0.8659],\n",
       "        [ 0.8718],\n",
       "        [ 0.8777],\n",
       "        [ 0.8836],\n",
       "        [ 0.8894],\n",
       "        [ 0.8953],\n",
       "        [ 0.9012],\n",
       "        [ 0.9070],\n",
       "        [ 0.9129],\n",
       "        [ 0.9188],\n",
       "        [ 0.9247],\n",
       "        [ 0.9305],\n",
       "        [ 0.9364],\n",
       "        [ 0.9423],\n",
       "        [ 0.9481],\n",
       "        [ 0.9540],\n",
       "        [ 0.9599],\n",
       "        [ 0.9658],\n",
       "        [ 0.9716],\n",
       "        [ 0.9775],\n",
       "        [ 0.9834],\n",
       "        [ 0.9892],\n",
       "        [ 0.9951],\n",
       "        [ 1.0010],\n",
       "        [ 1.0068],\n",
       "        [ 1.0127],\n",
       "        [ 1.0186],\n",
       "        [ 1.0245],\n",
       "        [ 1.0303],\n",
       "        [ 1.0362],\n",
       "        [ 1.0421],\n",
       "        [ 1.0479],\n",
       "        [ 1.0538],\n",
       "        [ 1.0597],\n",
       "        [ 1.0656],\n",
       "        [ 1.0714],\n",
       "        [ 1.0773],\n",
       "        [ 1.0832],\n",
       "        [ 1.0890],\n",
       "        [ 1.0949],\n",
       "        [ 1.1008],\n",
       "        [ 1.1067],\n",
       "        [ 1.1125],\n",
       "        [ 1.1184],\n",
       "        [ 1.1243],\n",
       "        [ 1.1301],\n",
       "        [ 1.1360],\n",
       "        [ 1.1419],\n",
       "        [ 1.1477],\n",
       "        [ 1.1536],\n",
       "        [ 1.1595],\n",
       "        [ 1.1654],\n",
       "        [ 1.1712],\n",
       "        [ 1.1771],\n",
       "        [ 1.1830],\n",
       "        [ 1.1888],\n",
       "        [ 1.1947],\n",
       "        [ 1.2006],\n",
       "        [ 1.2065],\n",
       "        [ 1.2123],\n",
       "        [ 1.2182],\n",
       "        [ 1.2241],\n",
       "        [ 1.2299],\n",
       "        [ 1.2358],\n",
       "        [ 1.2417],\n",
       "        [ 1.2476],\n",
       "        [ 1.2534],\n",
       "        [ 1.2593],\n",
       "        [ 1.2652],\n",
       "        [ 1.2710],\n",
       "        [ 1.2769],\n",
       "        [ 1.2828],\n",
       "        [ 1.2886],\n",
       "        [ 1.2945],\n",
       "        [ 1.3004],\n",
       "        [ 1.3063],\n",
       "        [ 1.3121],\n",
       "        [ 1.3180],\n",
       "        [ 1.3239],\n",
       "        [ 1.3297],\n",
       "        [ 1.3356],\n",
       "        [ 1.3415],\n",
       "        [ 1.3474],\n",
       "        [ 1.3532],\n",
       "        [ 1.3591],\n",
       "        [ 1.3650],\n",
       "        [ 1.3708],\n",
       "        [ 1.3767],\n",
       "        [ 1.3826],\n",
       "        [ 1.3885],\n",
       "        [ 1.3943],\n",
       "        [ 1.4002],\n",
       "        [ 1.4061],\n",
       "        [ 1.4119],\n",
       "        [ 1.4178],\n",
       "        [ 1.4237],\n",
       "        [ 1.4295],\n",
       "        [ 1.4354],\n",
       "        [ 1.4413],\n",
       "        [ 1.4472],\n",
       "        [ 1.4530],\n",
       "        [ 1.4589],\n",
       "        [ 1.4648],\n",
       "        [ 1.4706],\n",
       "        [ 1.4765],\n",
       "        [ 1.4824],\n",
       "        [ 1.4883],\n",
       "        [ 1.4941],\n",
       "        [ 1.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_train = io.tensor(np.linspace(-1.5, 1.5, 1024).reshape((-1, 1)))\n",
    "u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000],\n",
       "        [-1.9365],\n",
       "        [-1.8730],\n",
       "        [-1.8095],\n",
       "        [-1.7460],\n",
       "        [-1.6825],\n",
       "        [-1.6190],\n",
       "        [-1.5556],\n",
       "        [-1.4921],\n",
       "        [-1.4286],\n",
       "        [-1.3651],\n",
       "        [-1.3016],\n",
       "        [-1.2381],\n",
       "        [-1.1746],\n",
       "        [-1.1111],\n",
       "        [-1.0476],\n",
       "        [-0.9841],\n",
       "        [-0.9206],\n",
       "        [-0.8571],\n",
       "        [-0.7937],\n",
       "        [-0.7302],\n",
       "        [-0.6667],\n",
       "        [-0.6032],\n",
       "        [-0.5397],\n",
       "        [-0.4762],\n",
       "        [-0.4127],\n",
       "        [-0.3492],\n",
       "        [-0.2857],\n",
       "        [-0.2222],\n",
       "        [-0.1587],\n",
       "        [-0.0952],\n",
       "        [-0.0317],\n",
       "        [ 0.0317],\n",
       "        [ 0.0952],\n",
       "        [ 0.1587],\n",
       "        [ 0.2222],\n",
       "        [ 0.2857],\n",
       "        [ 0.3492],\n",
       "        [ 0.4127],\n",
       "        [ 0.4762],\n",
       "        [ 0.5397],\n",
       "        [ 0.6032],\n",
       "        [ 0.6667],\n",
       "        [ 0.7302],\n",
       "        [ 0.7937],\n",
       "        [ 0.8571],\n",
       "        [ 0.9206],\n",
       "        [ 0.9841],\n",
       "        [ 1.0476],\n",
       "        [ 1.1111],\n",
       "        [ 1.1746],\n",
       "        [ 1.2381],\n",
       "        [ 1.3016],\n",
       "        [ 1.3651],\n",
       "        [ 1.4286],\n",
       "        [ 1.4921],\n",
       "        [ 1.5556],\n",
       "        [ 1.6190],\n",
       "        [ 1.6825],\n",
       "        [ 1.7460],\n",
       "        [ 1.8095],\n",
       "        [ 1.8730],\n",
       "        [ 1.9365],\n",
       "        [ 2.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_val = io.tensor(np.linspace(-2, 2, 64).reshape((-1, 1)))\n",
    "u_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora generamos los x correspondientes del modelo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamplePLP(io.ParametricLP):\n",
    "    # Generate an LP from a given feature vector u and weight vector w.\n",
    "    def generate(self, u, w):\n",
    "        c = [[torch.cos(w[0] + w[1]*u)],\n",
    "             [torch.sin(w[0] + w[1]*u)]]\n",
    "\n",
    "        A_ub = [[-1.0,  0.0],\n",
    "                [ 0.0, -1.0],\n",
    "                [ w[0], 1 + w[1]*u/3]]\n",
    "\n",
    "        b_ub = [[ 0.2*w[0]*u],\n",
    "                [-0.2*w[1]*u],\n",
    "                [ w[0] + 0.1*u]]\n",
    "        \n",
    "        return c, A_ub, b_ub, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plp_true = ExamplePLP(weights=[1.0, 1.0])\n",
    "\n",
    "# Generate training targets by solve the true PLP at each u value.\n",
    "x_train = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_train])\n",
    "torch.save(x_train, \"x_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_val = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_val])\n",
    "torch.save(x_val, \"x_val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4000,  1.2000],\n",
       "        [ 0.3873,  1.1821],\n",
       "        [ 0.3746,  1.1662],\n",
       "        [ 0.3619,  1.1520],\n",
       "        [ 0.3492,  1.1392],\n",
       "        [ 0.3365,  1.1277],\n",
       "        [ 0.3238,  1.1172],\n",
       "        [ 0.3111,  1.1077],\n",
       "        [ 0.2984,  1.0989],\n",
       "        [ 0.2857,  1.0909],\n",
       "        [ 0.2730,  1.0835],\n",
       "        [ 0.2603,  1.0766],\n",
       "        [ 0.2476,  1.0702],\n",
       "        [ 0.2349,  1.0643],\n",
       "        [ 0.2222,  1.0588],\n",
       "        [ 0.2095,  1.0535],\n",
       "        [ 0.1968, -0.1965],\n",
       "        [ 0.1841, -0.1841],\n",
       "        [ 0.1714, -0.1714],\n",
       "        [ 0.1587, -0.1587],\n",
       "        [ 0.1460, -0.1460],\n",
       "        [ 0.1333, -0.1333],\n",
       "        [ 0.1206, -0.1206],\n",
       "        [ 0.1079, -0.1079],\n",
       "        [ 0.0952, -0.0952],\n",
       "        [ 0.0825, -0.0825],\n",
       "        [ 0.0698, -0.0698],\n",
       "        [ 0.0571, -0.0571],\n",
       "        [ 0.0444, -0.0444],\n",
       "        [ 0.0318, -0.0317],\n",
       "        [ 0.0191, -0.0190],\n",
       "        [ 0.0064, -0.0063],\n",
       "        [-0.0063,  0.0064],\n",
       "        [-0.0190,  0.0191],\n",
       "        [-0.0317,  0.0318],\n",
       "        [-0.0444,  0.0444],\n",
       "        [-0.0571,  0.0571],\n",
       "        [-0.0698,  0.0698],\n",
       "        [-0.0825,  0.0825],\n",
       "        [-0.0952,  0.0952],\n",
       "        [-0.1078,  0.1079],\n",
       "        [ 0.9153,  0.1206],\n",
       "        [ 0.9037,  0.1333],\n",
       "        [ 0.8914,  0.1460],\n",
       "        [ 0.8786,  0.1587],\n",
       "        [ 0.8653,  0.1714],\n",
       "        [ 0.8514,  0.1841],\n",
       "        [ 0.8370,  0.1968],\n",
       "        [ 0.8221,  0.2095],\n",
       "        [ 0.8066,  0.2222],\n",
       "        [ 0.7905,  0.2349],\n",
       "        [ 0.7740,  0.2476],\n",
       "        [ 0.7569,  0.2603],\n",
       "        [ 0.7392,  0.2730],\n",
       "        [ 0.7211,  0.2857],\n",
       "        [ 0.7024,  0.2984],\n",
       "        [ 0.6831,  0.3111],\n",
       "        [ 0.6633,  0.3238],\n",
       "        [ 0.6430,  0.3365],\n",
       "        [ 0.6221,  0.3492],\n",
       "        [ 0.6007,  0.3619],\n",
       "        [ 0.5788,  0.3746],\n",
       "        [ 0.5563,  0.3873],\n",
       "        [ 0.5333,  0.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.load(\"x_val.pt\")\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 1.1000],\n",
       "        [0.2988, 1.0992],\n",
       "        [0.2977, 1.0984],\n",
       "        ...,\n",
       "        [0.7035, 0.2977],\n",
       "        [0.7017, 0.2988],\n",
       "        [0.7000, 0.3000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.load(\"x_train.pt\")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: definimos la red y la entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# ver si estoy usando GPU\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "tol=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el dataset\n",
    "class UDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data.clone().to(dtype=torch.float32) # nota: esta dando el warning porque estoy convirtiendo un tensor a otro, en ese caso es mejor usar clone()\n",
    "        # si los datos de entrada no los voy a dar como un tensor, entonces hay que poner lo que he puesto: self.data = torch.tensor(data, dtype=torch.float32), self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        self.targets = targets.clone().to(dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Dataset con pares (u, x)\n",
    "dataset = UDataset(u_train, x_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = UDataset(u_val, x_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que resuelve el problema de programacion lineal (por ahora nos la creemos, pero hay que revisarla)\n",
    "# hay que tener en cuenta que esta funcion debe realizarse con operaciones de pytorch para\n",
    "# preservar el grafo de computo para poder hacer backpropagation\n",
    "# def smooth_lp(c, A, b):\n",
    "#     # Inicializar x con gradientes habilitados\n",
    "#     x = torch.zeros(A.shape[1], requires_grad=True)\n",
    "#     optimizer = torch.optim.SGD([x], lr=1e-3)\n",
    "\n",
    "#     for _ in range(1000):\n",
    "#         optimizer.zero_grad()\n",
    "#         constraint_penalty = torch.sum(torch.relu(A @ x - b))\n",
    "#         objective = torch.dot(c, x) + 100.0 * constraint_penalty\n",
    "#         objective.backward(retain_graph=True)  # Mant√©n el grafo activo\n",
    "#         optimizer.step()\n",
    "#     return x  # Sin detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy descartado porque no funciona\n",
    "# voy a probar con cvxpy\n",
    "\n",
    "import torch\n",
    "import cvxpylayers.torch as cvx\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "def solver(c_, A_, b_):\n",
    "    m,n = A_.shape\n",
    "\n",
    "    A = cp.Parameter((m, n))\n",
    "    b = cp.Parameter(m)\n",
    "    c = cp.Parameter(n)\n",
    "    x = cp.Variable(n)\n",
    "\n",
    "    obj = cp.Minimize(c.T @ x)\n",
    "    cons = [ A @ x <= b ]\n",
    "    prob = cp.Problem(obj, cons)\n",
    "\n",
    "    layer = CvxpyLayer(prob, parameters=[c,A,b], variables=[x])\n",
    "\n",
    "    solution, = layer(c_, A_, b_)\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1616e-06, -6.1616e-06])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([-1.0, -1.0])\n",
    "\n",
    "A = torch.tensor([[1.0, 0.0],\n",
    "                  [0.0, 1.0]])\n",
    "b = torch.tensor([0.0,\n",
    "                  0.0])\n",
    "\n",
    "print(solver(c, A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta version es la red neuronal en la que la resolucion del problema de optimizacion esta dentro de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la red (hay que revisar la forma de la red y el por qu√©)\n",
    "class ParametricLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParametricLPNet, self).__init__()\n",
    "        # Entrada de dimensi√≥n 1, salida 8 (2 para c, 4 para A, 2 para b)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, u):\n",
    "        output = self.fc(u)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion de perdida\n",
    "# def loss_fn(rs, target):\n",
    "#     '''\n",
    "#     rs: lista de tensores que son las salidas de la red\n",
    "#     target: lista de tensores que son las salidas deseadas\n",
    "\n",
    "#     Esta funci√≥n calcula la suma de las distancias al cuadrado entre las salidas de la red y las salidas deseadas.\n",
    "#     '''\n",
    "#     return torch.sum(torch.linalg.vector_norm(rs-target, ord=2, dim=1).pow(2))\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la red neuronal\n",
    "model = ParametricLPNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # elegir una de las dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametricLPNet(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para ver el modelo\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamod los pesos de la red \n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu') # inicializamos los pesos de la red con Kaiming\n",
    "        nn.init.zeros_(m.bias) # inicializamos los bias a 0\n",
    "\n",
    "initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss_media = 0.0\n",
    "    accuracy = 0.0\n",
    "    batch_size = dataloader.batch_size\n",
    "    for batch, (u_batch, x_batch) in enumerate(dataloader):\n",
    "\n",
    "        rs = model(u_batch)\n",
    "        loss = loss_fn(rs, x_batch) # Calcular la p√©rdida\n",
    "\n",
    "        # Backpropagation y optimizaci√≥n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 8 == 0: # cambiar este numero para que salga cada cierto numero de iteraciones\n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        loss_media += loss\n",
    "        accuracy += near(rs, x_batch, tol)\n",
    "\n",
    "    return loss_media / num_batches, accuracy / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for u_batch, x_batch in dataloader:\n",
    "        rs = model(u_batch)\n",
    "        test_loss += loss_fn(rs, x_batch).item()\n",
    "        correct += near(rs, x_batch, tol) # consideramos correcto si se acerca a la solucion en la distancia euclidea \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.136345  [   32/  512]\n",
      "loss: 0.177001  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.138126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.140520 \n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.127070  [   32/  512]\n",
      "loss: 0.117360  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.118671 \n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.097086  [   32/  512]\n",
      "loss: 0.112366  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.112141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.108035 \n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.107938  [   32/  512]\n",
      "loss: 0.080704  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.105055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097675 \n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.111450  [   32/  512]\n",
      "loss: 0.116217  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088304 \n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.098432  [   32/  512]\n",
      "loss: 0.085534  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078577 \n",
      "\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.084010  [   32/  512]\n",
      "loss: 0.085983  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081072 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073202 \n",
      "\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.069819  [   32/  512]\n",
      "loss: 0.100163  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065916 \n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.081680  [   32/  512]\n",
      "loss: 0.069606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061383 \n",
      "\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.056641  [   32/  512]\n",
      "loss: 0.047458  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057279 \n",
      "\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.047467  [   32/  512]\n",
      "loss: 0.053353  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055300 \n",
      "\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.055281  [   32/  512]\n",
      "loss: 0.063544  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052242 \n",
      "\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.067742  [   32/  512]\n",
      "loss: 0.067510  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051634 \n",
      "\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.049660  [   32/  512]\n",
      "loss: 0.055976  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050970 \n",
      "\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.059286  [   32/  512]\n",
      "loss: 0.065701  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048604 \n",
      "\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.049397  [   32/  512]\n",
      "loss: 0.042020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048374 \n",
      "\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.045913  [   32/  512]\n",
      "loss: 0.050304  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047933 \n",
      "\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.029201  [   32/  512]\n",
      "loss: 0.051612  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047766 \n",
      "\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.063292  [   32/  512]\n",
      "loss: 0.034344  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045748 \n",
      "\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.062154  [   32/  512]\n",
      "loss: 0.043260  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045381 \n",
      "\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.043448  [   32/  512]\n",
      "loss: 0.040980  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044734 \n",
      "\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.042589  [   32/  512]\n",
      "loss: 0.056502  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043796 \n",
      "\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.027716  [   32/  512]\n",
      "loss: 0.041664  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042274 \n",
      "\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.051230  [   32/  512]\n",
      "loss: 0.046729  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044155 \n",
      "\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.030614  [   32/  512]\n",
      "loss: 0.027024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041797 \n",
      "\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.033402  [   32/  512]\n",
      "loss: 0.033567  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042916 \n",
      "\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.041811  [   32/  512]\n",
      "loss: 0.057220  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041364 \n",
      "\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.031211  [   32/  512]\n",
      "loss: 0.039685  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037617 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041397 \n",
      "\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.045011  [   32/  512]\n",
      "loss: 0.032580  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043093 \n",
      "\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.029385  [   32/  512]\n",
      "loss: 0.028251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040313 \n",
      "\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.027661  [   32/  512]\n",
      "loss: 0.022710  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042230 \n",
      "\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.040432  [   32/  512]\n",
      "loss: 0.022550  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042010 \n",
      "\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.024897  [   32/  512]\n",
      "loss: 0.022256  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041923 \n",
      "\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.028388  [   32/  512]\n",
      "loss: 0.024713  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041267 \n",
      "\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.020128  [   32/  512]\n",
      "loss: 0.039547  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045001 \n",
      "\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.028163  [   32/  512]\n",
      "loss: 0.031834  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044707 \n",
      "\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.023235  [   32/  512]\n",
      "loss: 0.024047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044221 \n",
      "\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.024384  [   32/  512]\n",
      "loss: 0.019516  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027083 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044544 \n",
      "\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.022057  [   32/  512]\n",
      "loss: 0.031125  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047884 \n",
      "\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.033580  [   32/  512]\n",
      "loss: 0.028233  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047275 \n",
      "\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.021684  [   32/  512]\n",
      "loss: 0.023010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049330 \n",
      "\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.019879  [   32/  512]\n",
      "loss: 0.032393  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047926 \n",
      "\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.030427  [   32/  512]\n",
      "loss: 0.026931  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045806 \n",
      "\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.018606  [   32/  512]\n",
      "loss: 0.027028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048868 \n",
      "\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.010575  [   32/  512]\n",
      "loss: 0.018257  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046534 \n",
      "\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.022864  [   32/  512]\n",
      "loss: 0.042656  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045668 \n",
      "\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.017844  [   32/  512]\n",
      "loss: 0.027359  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048793 \n",
      "\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.024188  [   32/  512]\n",
      "loss: 0.018738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020971 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047039 \n",
      "\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.014652  [   32/  512]\n",
      "loss: 0.022978  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049816 \n",
      "\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.021316  [   32/  512]\n",
      "loss: 0.020560  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047775 \n",
      "\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.028296  [   32/  512]\n",
      "loss: 0.017653  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051042 \n",
      "\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.003007  [   32/  512]\n",
      "loss: 0.015134  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050709 \n",
      "\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.013836  [   32/  512]\n",
      "loss: 0.022915  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044601 \n",
      "\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.021703  [   32/  512]\n",
      "loss: 0.016546  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050809 \n",
      "\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.018057  [   32/  512]\n",
      "loss: 0.012330  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047386 \n",
      "\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.005599  [   32/  512]\n",
      "loss: 0.011797  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047752 \n",
      "\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.020954  [   32/  512]\n",
      "loss: 0.029800  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048287 \n",
      "\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.014568  [   32/  512]\n",
      "loss: 0.021148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052512 \n",
      "\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.024351  [   32/  512]\n",
      "loss: 0.020365  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045096 \n",
      "\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.006587  [   32/  512]\n",
      "loss: 0.012158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048945 \n",
      "\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.012955  [   32/  512]\n",
      "loss: 0.006961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016348 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050795 \n",
      "\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.008237  [   32/  512]\n",
      "loss: 0.021138  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046605 \n",
      "\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.015643  [   32/  512]\n",
      "loss: 0.011890  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049505 \n",
      "\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.016449  [   32/  512]\n",
      "loss: 0.013497  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046075 \n",
      "\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.009815  [   32/  512]\n",
      "loss: 0.017892  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047529 \n",
      "\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.014279  [   32/  512]\n",
      "loss: 0.021249  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046912 \n",
      "\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.009785  [   32/  512]\n",
      "loss: 0.015473  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047794 \n",
      "\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.011317  [   32/  512]\n",
      "loss: 0.021275  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043226 \n",
      "\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.008724  [   32/  512]\n",
      "loss: 0.018047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049461 \n",
      "\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.010273  [   32/  512]\n",
      "loss: 0.014979  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014832 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045040 \n",
      "\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.014477  [   32/  512]\n",
      "loss: 0.018336  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047527 \n",
      "\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.018424  [   32/  512]\n",
      "loss: 0.018565  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049394 \n",
      "\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.008862  [   32/  512]\n",
      "loss: 0.009307  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045621 \n",
      "\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.008794  [   32/  512]\n",
      "loss: 0.025629  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049865 \n",
      "\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.011390  [   32/  512]\n",
      "loss: 0.022066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044813 \n",
      "\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.022364  [   32/  512]\n",
      "loss: 0.010543  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045711 \n",
      "\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.006635  [   32/  512]\n",
      "loss: 0.018081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013921 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047701 \n",
      "\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.006996  [   32/  512]\n",
      "loss: 0.023565  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013824 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043939 \n",
      "\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.019021  [   32/  512]\n",
      "loss: 0.015443  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048468 \n",
      "\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.004689  [   32/  512]\n",
      "loss: 0.027542  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045696 \n",
      "\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.020862  [   32/  512]\n",
      "loss: 0.010159  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050060 \n",
      "\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.011080  [   32/  512]\n",
      "loss: 0.020485  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045379 \n",
      "\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.015139  [   32/  512]\n",
      "loss: 0.007889  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040949 \n",
      "\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.014451  [   32/  512]\n",
      "loss: 0.004577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046434 \n",
      "\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.009025  [   32/  512]\n",
      "loss: 0.011494  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043321 \n",
      "\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.017780  [   32/  512]\n",
      "loss: 0.006529  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042457 \n",
      "\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.014274  [   32/  512]\n",
      "loss: 0.023830  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043818 \n",
      "\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.019413  [   32/  512]\n",
      "loss: 0.008795  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041969 \n",
      "\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.009740  [   32/  512]\n",
      "loss: 0.011927  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044062 \n",
      "\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.027095  [   32/  512]\n",
      "loss: 0.007952  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042292 \n",
      "\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.008929  [   32/  512]\n",
      "loss: 0.009030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012399 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039123 \n",
      "\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.014928  [   32/  512]\n",
      "loss: 0.007108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043542 \n",
      "\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.014280  [   32/  512]\n",
      "loss: 0.006673  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038215 \n",
      "\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.013331  [   32/  512]\n",
      "loss: 0.011099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044067 \n",
      "\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.007602  [   32/  512]\n",
      "loss: 0.018757  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012121 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038853 \n",
      "\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.016654  [   32/  512]\n",
      "loss: 0.020175  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038777 \n",
      "\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.006382  [   32/  512]\n",
      "loss: 0.010545  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039637 \n",
      "\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.011668  [   32/  512]\n",
      "loss: 0.012741  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040837 \n",
      "\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.007874  [   32/  512]\n",
      "loss: 0.013940  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011369 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038230 \n",
      "\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.009567  [   32/  512]\n",
      "loss: 0.019663  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039316 \n",
      "\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.012844  [   32/  512]\n",
      "loss: 0.002316  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037819 \n",
      "\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.020617  [   32/  512]\n",
      "loss: 0.011536  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011264 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038460 \n",
      "\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.006025  [   32/  512]\n",
      "loss: 0.008279  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037281 \n",
      "\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.009309  [   32/  512]\n",
      "loss: 0.005175  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035116 \n",
      "\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.008048  [   32/  512]\n",
      "loss: 0.015291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040112 \n",
      "\n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.007942  [   32/  512]\n",
      "loss: 0.013039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035958 \n",
      "\n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.018218  [   32/  512]\n",
      "loss: 0.018128  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037357 \n",
      "\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.017821  [   32/  512]\n",
      "loss: 0.018576  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033915 \n",
      "\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.010632  [   32/  512]\n",
      "loss: 0.007889  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033033 \n",
      "\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.013123  [   32/  512]\n",
      "loss: 0.006615  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034276 \n",
      "\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.007015  [   32/  512]\n",
      "loss: 0.012954  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034845 \n",
      "\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.006650  [   32/  512]\n",
      "loss: 0.014697  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010134 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035982 \n",
      "\n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.011344  [   32/  512]\n",
      "loss: 0.008634  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032973 \n",
      "\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.007428  [   32/  512]\n",
      "loss: 0.014191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032113 \n",
      "\n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.011769  [   32/  512]\n",
      "loss: 0.007148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010201 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032893 \n",
      "\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.011964  [   32/  512]\n",
      "loss: 0.002046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032828 \n",
      "\n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.015507  [   32/  512]\n",
      "loss: 0.004254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031845 \n",
      "\n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.017851  [   32/  512]\n",
      "loss: 0.006961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032670 \n",
      "\n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.002128  [   32/  512]\n",
      "loss: 0.012998  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031873 \n",
      "\n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.007214  [   32/  512]\n",
      "loss: 0.012665  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031551 \n",
      "\n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.007300  [   32/  512]\n",
      "loss: 0.011597  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032127 \n",
      "\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.017085  [   32/  512]\n",
      "loss: 0.005738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032796 \n",
      "\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.003923  [   32/  512]\n",
      "loss: 0.012600  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029951 \n",
      "\n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.009969  [   32/  512]\n",
      "loss: 0.014885  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029920 \n",
      "\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.017873  [   32/  512]\n",
      "loss: 0.011154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031713 \n",
      "\n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.014403  [   32/  512]\n",
      "loss: 0.010018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029839 \n",
      "\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.011160  [   32/  512]\n",
      "loss: 0.008935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008827 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030359 \n",
      "\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.001054  [   32/  512]\n",
      "loss: 0.010282  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028886 \n",
      "\n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.009714  [   32/  512]\n",
      "loss: 0.006677  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031077 \n",
      "\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.004124  [   32/  512]\n",
      "loss: 0.005291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027771 \n",
      "\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.005136  [   32/  512]\n",
      "loss: 0.006760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028872 \n",
      "\n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.006860  [   32/  512]\n",
      "loss: 0.006739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028331 \n",
      "\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.003851  [   32/  512]\n",
      "loss: 0.007195  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027157 \n",
      "\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.010592  [   32/  512]\n",
      "loss: 0.014502  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026472 \n",
      "\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.016248  [   32/  512]\n",
      "loss: 0.006960  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026438 \n",
      "\n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.011572  [   32/  512]\n",
      "loss: 0.012200  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027252 \n",
      "\n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.012919  [   32/  512]\n",
      "loss: 0.007852  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028545 \n",
      "\n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.004729  [   32/  512]\n",
      "loss: 0.005558  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029358 \n",
      "\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.016101  [   32/  512]\n",
      "loss: 0.002719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008104 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028056 \n",
      "\n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.003638  [   32/  512]\n",
      "loss: 0.003387  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028303 \n",
      "\n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.011219  [   32/  512]\n",
      "loss: 0.009251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027996 \n",
      "\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.006383  [   32/  512]\n",
      "loss: 0.012023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027279 \n",
      "\n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.007083  [   32/  512]\n",
      "loss: 0.009001  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024805 \n",
      "\n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.003545  [   32/  512]\n",
      "loss: 0.012390  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026200 \n",
      "\n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.007035  [   32/  512]\n",
      "loss: 0.009994  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007787 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025039 \n",
      "\n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.004438  [   32/  512]\n",
      "loss: 0.012129  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025647 \n",
      "\n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.002942  [   32/  512]\n",
      "loss: 0.010270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025162 \n",
      "\n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.006112  [   32/  512]\n",
      "loss: 0.001649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026498 \n",
      "\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.010194  [   32/  512]\n",
      "loss: 0.007315  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024286 \n",
      "\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.018394  [   32/  512]\n",
      "loss: 0.009657  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022802 \n",
      "\n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.001558  [   32/  512]\n",
      "loss: 0.006019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026198 \n",
      "\n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.005889  [   32/  512]\n",
      "loss: 0.002990  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023346 \n",
      "\n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.004316  [   32/  512]\n",
      "loss: 0.012524  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022794 \n",
      "\n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.013557  [   32/  512]\n",
      "loss: 0.009593  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022966 \n",
      "\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.001497  [   32/  512]\n",
      "loss: 0.004994  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023474 \n",
      "\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.005772  [   32/  512]\n",
      "loss: 0.008045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022927 \n",
      "\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.004094  [   32/  512]\n",
      "loss: 0.001912  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022296 \n",
      "\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.006825  [   32/  512]\n",
      "loss: 0.012369  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024794 \n",
      "\n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.009070  [   32/  512]\n",
      "loss: 0.002840  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021887 \n",
      "\n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.004319  [   32/  512]\n",
      "loss: 0.002734  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021724 \n",
      "\n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.001374  [   32/  512]\n",
      "loss: 0.003292  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021309 \n",
      "\n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.007996  [   32/  512]\n",
      "loss: 0.014559  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019406 \n",
      "\n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.001708  [   32/  512]\n",
      "loss: 0.002457  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021365 \n",
      "\n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.007307  [   32/  512]\n",
      "loss: 0.005728  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021288 \n",
      "\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.007570  [   32/  512]\n",
      "loss: 0.012699  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020193 \n",
      "\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.005743  [   32/  512]\n",
      "loss: 0.005832  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020721 \n",
      "\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.004409  [   32/  512]\n",
      "loss: 0.002926  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019842 \n",
      "\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.005613  [   32/  512]\n",
      "loss: 0.012780  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018843 \n",
      "\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.003303  [   32/  512]\n",
      "loss: 0.004033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019905 \n",
      "\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.009025  [   32/  512]\n",
      "loss: 0.001525  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019010 \n",
      "\n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.007357  [   32/  512]\n",
      "loss: 0.006552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017726 \n",
      "\n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.006555  [   32/  512]\n",
      "loss: 0.005483  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018969 \n",
      "\n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.008519  [   32/  512]\n",
      "loss: 0.000895  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020061 \n",
      "\n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.005086  [   32/  512]\n",
      "loss: 0.012048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019463 \n",
      "\n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.002012  [   32/  512]\n",
      "loss: 0.002248  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018191 \n",
      "\n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.001545  [   32/  512]\n",
      "loss: 0.003714  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019053 \n",
      "\n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.009185  [   32/  512]\n",
      "loss: 0.009376  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017396 \n",
      "\n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.001788  [   32/  512]\n",
      "loss: 0.004299  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017624 \n",
      "\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.006756  [   32/  512]\n",
      "loss: 0.004394  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018179 \n",
      "\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.001468  [   32/  512]\n",
      "loss: 0.003495  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017208 \n",
      "\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.002038  [   32/  512]\n",
      "loss: 0.000291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017400 \n",
      "\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.004529  [   32/  512]\n",
      "loss: 0.003963  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016859 \n",
      "\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.003124  [   32/  512]\n",
      "loss: 0.002310  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018630 \n",
      "\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.002339  [   32/  512]\n",
      "loss: 0.000927  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016298 \n",
      "\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.006266  [   32/  512]\n",
      "loss: 0.011052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015339 \n",
      "\n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.015266  [   32/  512]\n",
      "loss: 0.003203  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015275 \n",
      "\n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.008106  [   32/  512]\n",
      "loss: 0.006360  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015227 \n",
      "\n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.010681  [   32/  512]\n",
      "loss: 0.005690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015508 \n",
      "\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.007520  [   32/  512]\n",
      "loss: 0.003634  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016203 \n",
      "\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.002097  [   32/  512]\n",
      "loss: 0.001139  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015355 \n",
      "\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.013531  [   32/  512]\n",
      "loss: 0.005072  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015405 \n",
      "\n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.008224  [   32/  512]\n",
      "loss: 0.007771  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015600 \n",
      "\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.009813  [   32/  512]\n",
      "loss: 0.004422  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014017 \n",
      "\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.004002  [   32/  512]\n",
      "loss: 0.011788  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013406 \n",
      "\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.003858  [   32/  512]\n",
      "loss: 0.005051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014108 \n",
      "\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.004646  [   32/  512]\n",
      "loss: 0.004554  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014379 \n",
      "\n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.001168  [   32/  512]\n",
      "loss: 0.002905  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014896 \n",
      "\n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.001449  [   32/  512]\n",
      "loss: 0.003135  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014476 \n",
      "\n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.001615  [   32/  512]\n",
      "loss: 0.003404  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014214 \n",
      "\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.002513  [   32/  512]\n",
      "loss: 0.000696  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014145 \n",
      "\n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.001633  [   32/  512]\n",
      "loss: 0.006990  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012783 \n",
      "\n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.001453  [   32/  512]\n",
      "loss: 0.006059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004979 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012691 \n",
      "\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.003852  [   32/  512]\n",
      "loss: 0.006223  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013647 \n",
      "\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.005877  [   32/  512]\n",
      "loss: 0.010249  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004968 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014317 \n",
      "\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.004874  [   32/  512]\n",
      "loss: 0.016333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012743 \n",
      "\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.008110  [   32/  512]\n",
      "loss: 0.005011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011620 \n",
      "\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.001056  [   32/  512]\n",
      "loss: 0.003759  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012814 \n",
      "\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.002832  [   32/  512]\n",
      "loss: 0.001324  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012568 \n",
      "\n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.002780  [   32/  512]\n",
      "loss: 0.001501  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012641 \n",
      "\n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.006078  [   32/  512]\n",
      "loss: 0.007045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004752 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011857 \n",
      "\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.006673  [   32/  512]\n",
      "loss: 0.003294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012059 \n",
      "\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.002728  [   32/  512]\n",
      "loss: 0.007230  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011578 \n",
      "\n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.001005  [   32/  512]\n",
      "loss: 0.003998  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010902 \n",
      "\n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000777  [   32/  512]\n",
      "loss: 0.002164  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011562 \n",
      "\n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.002482  [   32/  512]\n",
      "loss: 0.008166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010996 \n",
      "\n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.001102  [   32/  512]\n",
      "loss: 0.008341  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010751 \n",
      "\n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.001288  [   32/  512]\n",
      "loss: 0.005925  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011328 \n",
      "\n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.005730  [   32/  512]\n",
      "loss: 0.008027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010444 \n",
      "\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.005192  [   32/  512]\n",
      "loss: 0.001552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010828 \n",
      "\n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.007693  [   32/  512]\n",
      "loss: 0.007661  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010804 \n",
      "\n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.002492  [   32/  512]\n",
      "loss: 0.000572  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010912 \n",
      "\n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.001704  [   32/  512]\n",
      "loss: 0.003909  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004576 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011174 \n",
      "\n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000752  [   32/  512]\n",
      "loss: 0.011002  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009544 \n",
      "\n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.005820  [   32/  512]\n",
      "loss: 0.005991  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009379 \n",
      "\n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.002807  [   32/  512]\n",
      "loss: 0.003431  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010029 \n",
      "\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.007886  [   32/  512]\n",
      "loss: 0.005140  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010524 \n",
      "\n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.004358  [   32/  512]\n",
      "loss: 0.000742  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009429 \n",
      "\n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000769  [   32/  512]\n",
      "loss: 0.007278  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009300 \n",
      "\n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.007083  [   32/  512]\n",
      "loss: 0.003699  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009588 \n",
      "\n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.009155  [   32/  512]\n",
      "loss: 0.001692  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008668 \n",
      "\n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000820  [   32/  512]\n",
      "loss: 0.001022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008993 \n",
      "\n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.004930  [   32/  512]\n",
      "loss: 0.003042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009524 \n",
      "\n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.001590  [   32/  512]\n",
      "loss: 0.003204  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008697 \n",
      "\n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000545  [   32/  512]\n",
      "loss: 0.000649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008549 \n",
      "\n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.007099  [   32/  512]\n",
      "loss: 0.001811  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008662 \n",
      "\n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.004521  [   32/  512]\n",
      "loss: 0.004028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008741 \n",
      "\n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.005071  [   32/  512]\n",
      "loss: 0.004548  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007870 \n",
      "\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.008376  [   32/  512]\n",
      "loss: 0.011012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004132 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008869 \n",
      "\n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.004003  [   32/  512]\n",
      "loss: 0.000441  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008530 \n",
      "\n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.002803  [   32/  512]\n",
      "loss: 0.008727  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006789 \n",
      "\n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.006285  [   32/  512]\n",
      "loss: 0.003492  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006875 \n",
      "\n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.007042  [   32/  512]\n",
      "loss: 0.003917  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007627 \n",
      "\n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.015266  [   32/  512]\n",
      "loss: 0.002270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007127 \n",
      "\n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.007205  [   32/  512]\n",
      "loss: 0.002452  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007476 \n",
      "\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.002818  [   32/  512]\n",
      "loss: 0.006364  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006931 \n",
      "\n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.004348  [   32/  512]\n",
      "loss: 0.010534  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007588 \n",
      "\n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.004467  [   32/  512]\n",
      "loss: 0.008004  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007082 \n",
      "\n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000391  [   32/  512]\n",
      "loss: 0.003472  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006624 \n",
      "\n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000521  [   32/  512]\n",
      "loss: 0.002637  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006888 \n",
      "\n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.003795  [   32/  512]\n",
      "loss: 0.007846  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006393 \n",
      "\n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000388  [   32/  512]\n",
      "loss: 0.014789  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008274 \n",
      "\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.003303  [   32/  512]\n",
      "loss: 0.002724  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007442 \n",
      "\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.008633  [   32/  512]\n",
      "loss: 0.007401  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003474 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006396 \n",
      "\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.005010  [   32/  512]\n",
      "loss: 0.002101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007430 \n",
      "\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.003717  [   32/  512]\n",
      "loss: 0.001237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006572 \n",
      "\n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.002306  [   32/  512]\n",
      "loss: 0.001433  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005838 \n",
      "\n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.006099  [   32/  512]\n",
      "loss: 0.003935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005638 \n",
      "\n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.009008  [   32/  512]\n",
      "loss: 0.002741  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005693 \n",
      "\n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000316  [   32/  512]\n",
      "loss: 0.000276  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006085 \n",
      "\n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.004897  [   32/  512]\n",
      "loss: 0.006989  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005328 \n",
      "\n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.006851  [   32/  512]\n",
      "loss: 0.006894  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006418 \n",
      "\n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.003193  [   32/  512]\n",
      "loss: 0.019760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004166 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005917 \n",
      "\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000211  [   32/  512]\n",
      "loss: 0.000294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005426 \n",
      "\n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.004208  [   32/  512]\n",
      "loss: 0.002911  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005395 \n",
      "\n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000448  [   32/  512]\n",
      "loss: 0.005011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005877 \n",
      "\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000121  [   32/  512]\n",
      "loss: 0.008693  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005735 \n",
      "\n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.012355  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005186 \n",
      "\n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.005385  [   32/  512]\n",
      "loss: 0.002936  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005606 \n",
      "\n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.009038  [   32/  512]\n",
      "loss: 0.007665  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005355 \n",
      "\n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.003402  [   32/  512]\n",
      "loss: 0.001758  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005863 \n",
      "\n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.007401  [   32/  512]\n",
      "loss: 0.004331  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004806 \n",
      "\n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.002887  [   32/  512]\n",
      "loss: 0.005057  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005365 \n",
      "\n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.006364  [   32/  512]\n",
      "loss: 0.004892  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005883 \n",
      "\n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.004097  [   32/  512]\n",
      "loss: 0.004272  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005077 \n",
      "\n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000148  [   32/  512]\n",
      "loss: 0.006670  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004484 \n",
      "\n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000133  [   32/  512]\n",
      "loss: 0.009168  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004803 \n",
      "\n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.004461  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004618 \n",
      "\n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.005635  [   32/  512]\n",
      "loss: 0.001739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005321 \n",
      "\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000175  [   32/  512]\n",
      "loss: 0.005042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004803 \n",
      "\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.005668  [   32/  512]\n",
      "loss: 0.000278  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005977 \n",
      "\n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.003075  [   32/  512]\n",
      "loss: 0.003154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004812 \n",
      "\n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.005550  [   32/  512]\n",
      "loss: 0.002284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003411 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004295 \n",
      "\n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000279  [   32/  512]\n",
      "loss: 0.004304  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004642 \n",
      "\n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000445  [   32/  512]\n",
      "loss: 0.001577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004703 \n",
      "\n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.000821  [   32/  512]\n",
      "loss: 0.005327  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004613 \n",
      "\n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.002759  [   32/  512]\n",
      "loss: 0.007123  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005092 \n",
      "\n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.000645  [   32/  512]\n",
      "loss: 0.000261  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004529 \n",
      "\n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.008719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004427 \n",
      "\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.003189  [   32/  512]\n",
      "loss: 0.001228  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005083 \n",
      "\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000643  [   32/  512]\n",
      "loss: 0.002047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004391 \n",
      "\n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.002462  [   32/  512]\n",
      "loss: 0.008431  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004138 \n",
      "\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000118  [   32/  512]\n",
      "loss: 0.001461  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005093 \n",
      "\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.002309  [   32/  512]\n",
      "loss: 0.001117  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004083 \n",
      "\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000203  [   32/  512]\n",
      "loss: 0.011285  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003743 \n",
      "\n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.005542  [   32/  512]\n",
      "loss: 0.001023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003660 \n",
      "\n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.006605  [   32/  512]\n",
      "loss: 0.006690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003827 \n",
      "\n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.004771  [   32/  512]\n",
      "loss: 0.001384  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003847 \n",
      "\n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.001378  [   32/  512]\n",
      "loss: 0.000831  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004960 \n",
      "\n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.002125  [   32/  512]\n",
      "loss: 0.002010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004894 \n",
      "\n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.002240  [   32/  512]\n",
      "loss: 0.003317  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004336 \n",
      "\n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.004412  [   32/  512]\n",
      "loss: 0.007284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004584 \n",
      "\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.000180  [   32/  512]\n",
      "loss: 0.005232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003154 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004125 \n",
      "\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.000968  [   32/  512]\n",
      "loss: 0.000380  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004345 \n",
      "\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.004188  [   32/  512]\n",
      "loss: 0.012664  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003806 \n",
      "\n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.001907  [   32/  512]\n",
      "loss: 0.009520  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002953 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003990 \n",
      "\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.005810  [   32/  512]\n",
      "loss: 0.006980  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003290 \n",
      "\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.000248  [   32/  512]\n",
      "loss: 0.000838  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004239 \n",
      "\n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.000095  [   32/  512]\n",
      "loss: 0.000070  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003966 \n",
      "\n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.000224  [   32/  512]\n",
      "loss: 0.001936  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003723 \n",
      "\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000396  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004058 \n",
      "\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.003503  [   32/  512]\n",
      "loss: 0.000067  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004316 \n",
      "\n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.001740  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004841 \n",
      "\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.000525  [   32/  512]\n",
      "loss: 0.013398  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003928 \n",
      "\n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.002638  [   32/  512]\n",
      "loss: 0.000666  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003365 \n",
      "\n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000218  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004899 \n",
      "\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.006599  [   32/  512]\n",
      "loss: 0.001441  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004355 \n",
      "\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.001838  [   32/  512]\n",
      "loss: 0.000215  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004165 \n",
      "\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.002666  [   32/  512]\n",
      "loss: 0.000937  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003444 \n",
      "\n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.004798  [   32/  512]\n",
      "loss: 0.004719  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004586 \n",
      "\n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.004674  [   32/  512]\n",
      "loss: 0.000577  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003766 \n",
      "\n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.000059  [   32/  512]\n",
      "loss: 0.003380  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003365 \n",
      "\n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.002685  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004022 \n",
      "\n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.000880  [   32/  512]\n",
      "loss: 0.000083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003658 \n",
      "\n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.003606  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003450 \n",
      "\n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.000074  [   32/  512]\n",
      "loss: 0.000287  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003370 \n",
      "\n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.002446  [   32/  512]\n",
      "loss: 0.004359  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003616 \n",
      "\n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.004378  [   32/  512]\n",
      "loss: 0.000483  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003439 \n",
      "\n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.004775  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004330 \n",
      "\n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.003073  [   32/  512]\n",
      "loss: 0.000193  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003357 \n",
      "\n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.000058  [   32/  512]\n",
      "loss: 0.000191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003965 \n",
      "\n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.007219  [   32/  512]\n",
      "loss: 0.000219  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004230 \n",
      "\n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.003321  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003705 \n",
      "\n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.001020  [   32/  512]\n",
      "loss: 0.000186  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003095 \n",
      "\n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.006519  [   32/  512]\n",
      "loss: 0.003165  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004171 \n",
      "\n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.002849  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003424 \n",
      "\n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.000201  [   32/  512]\n",
      "loss: 0.005537  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004160 \n",
      "\n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003204 \n",
      "\n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.000384  [   32/  512]\n",
      "loss: 0.009612  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.001695  [   32/  512]\n",
      "loss: 0.006795  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003169 \n",
      "\n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000247  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003473 \n",
      "\n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.003372  [   32/  512]\n",
      "loss: 0.003552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003093 \n",
      "\n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.000263  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003178 \n",
      "\n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.005488  [   32/  512]\n",
      "loss: 0.000606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004139 \n",
      "\n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.003769  [   32/  512]\n",
      "loss: 0.001690  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003187 \n",
      "\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.000249  [   32/  512]\n",
      "loss: 0.002800  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002859 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003102 \n",
      "\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.003269  [   32/  512]\n",
      "loss: 0.004746  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003033 \n",
      "\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.000181  [   32/  512]\n",
      "loss: 0.001931  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003528 \n",
      "\n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.001656  [   32/  512]\n",
      "loss: 0.000232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003757 \n",
      "\n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.002053  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003614 \n",
      "\n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.005188  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003580 \n",
      "\n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003999 \n",
      "\n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003474 \n",
      "\n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.000319  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.001151  [   32/  512]\n",
      "loss: 0.001570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003217 \n",
      "\n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.003004  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003808 \n",
      "\n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.005752  [   32/  512]\n",
      "loss: 0.001616  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002622 \n",
      "\n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.001680  [   32/  512]\n",
      "loss: 0.012328  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003604 \n",
      "\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.000892  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003385 \n",
      "\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003055 \n",
      "\n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.005664  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003403 \n",
      "\n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.000229  [   32/  512]\n",
      "loss: 0.000696  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003201 \n",
      "\n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.001031  [   32/  512]\n",
      "loss: 0.002993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003328 \n",
      "\n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.004126  [   32/  512]\n",
      "loss: 0.002288  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003252 \n",
      "\n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.001214  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003548 \n",
      "\n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.000128  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003134 \n",
      "\n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.000054  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003060 \n",
      "\n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.004328  [   32/  512]\n",
      "loss: 0.000181  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003471 \n",
      "\n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.000280  [   32/  512]\n",
      "loss: 0.003205  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003507 \n",
      "\n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.000089  [   32/  512]\n",
      "loss: 0.005861  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003378 \n",
      "\n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.008148  [   32/  512]\n",
      "loss: 0.001628  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003551 \n",
      "\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.005786  [   32/  512]\n",
      "loss: 0.000271  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004355 \n",
      "\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.003745  [   32/  512]\n",
      "loss: 0.000785  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003730 \n",
      "\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.000735  [   32/  512]\n",
      "loss: 0.000764  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002986 \n",
      "\n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.000882  [   32/  512]\n",
      "loss: 0.004548  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003419 \n",
      "\n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.000090  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003399 \n",
      "\n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.003633  [   32/  512]\n",
      "loss: 0.000135  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004465 \n",
      "\n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.003755  [   32/  512]\n",
      "loss: 0.000095  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002971 \n",
      "\n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.001245  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004157 \n",
      "\n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.000141  [   32/  512]\n",
      "loss: 0.006381  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003371 \n",
      "\n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.001736  [   32/  512]\n",
      "loss: 0.000667  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003279 \n",
      "\n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.000377  [   32/  512]\n",
      "loss: 0.001036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002262 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003715 \n",
      "\n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000961  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002988 \n",
      "\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.004597  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003108 \n",
      "\n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.000743  [   32/  512]\n",
      "loss: 0.003765  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004055 \n",
      "\n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.002987  [   32/  512]\n",
      "loss: 0.004856  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.000027  [   32/  512]\n",
      "loss: 0.000277  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003283 \n",
      "\n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.003520  [   32/  512]\n",
      "loss: 0.003165  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001995 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004331 \n",
      "\n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.008510  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003480 \n",
      "\n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.005951  [   32/  512]\n",
      "loss: 0.005016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002947 \n",
      "\n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.000134  [   32/  512]\n",
      "loss: 0.005315  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003520 \n",
      "\n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.000339  [   32/  512]\n",
      "loss: 0.000302  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003358 \n",
      "\n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.005096  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003436 \n",
      "\n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.000748  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002940 \n",
      "\n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.000115  [   32/  512]\n",
      "loss: 0.014115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003183 \n",
      "\n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.000100  [   32/  512]\n",
      "loss: 0.000294  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003422 \n",
      "\n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.002022  [   32/  512]\n",
      "loss: 0.007570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003252 \n",
      "\n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.004485  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003012 \n",
      "\n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.003962  [   32/  512]\n",
      "loss: 0.000349  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003447 \n",
      "\n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000026  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003171 \n",
      "\n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.003170  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003359 \n",
      "\n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.003464  [   32/  512]\n",
      "loss: 0.000202  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004731 \n",
      "\n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.000103  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002618 \n",
      "\n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.000099  [   32/  512]\n",
      "loss: 0.001266  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003483 \n",
      "\n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.003657  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003654 \n",
      "\n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.004820  [   32/  512]\n",
      "loss: 0.005887  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002782 \n",
      "\n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.000171  [   32/  512]\n",
      "loss: 0.002576  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003588 \n",
      "\n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.002344  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003325 \n",
      "\n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.000141  [   32/  512]\n",
      "loss: 0.004176  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002479 \n",
      "\n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.000461  [   32/  512]\n",
      "loss: 0.003138  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002958 \n",
      "\n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.000591  [   32/  512]\n",
      "loss: 0.000288  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002701 \n",
      "\n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.002959  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003629 \n",
      "\n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000212  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003317 \n",
      "\n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.000474  [   32/  512]\n",
      "loss: 0.006200  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003234 \n",
      "\n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.000333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002630 \n",
      "\n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.000185  [   32/  512]\n",
      "loss: 0.001968  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003719 \n",
      "\n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.000689  [   32/  512]\n",
      "loss: 0.000270  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003144 \n",
      "\n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.000287  [   32/  512]\n",
      "loss: 0.011265  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003229 \n",
      "\n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.000074  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003230 \n",
      "\n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.002485  [   32/  512]\n",
      "loss: 0.004831  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002672 \n",
      "\n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000386  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003288 \n",
      "\n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.002470  [   32/  512]\n",
      "loss: 0.003116  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003098 \n",
      "\n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.003103  [   32/  512]\n",
      "loss: 0.005616  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003572 \n",
      "\n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.000717  [   32/  512]\n",
      "loss: 0.000296  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002626 \n",
      "\n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.004144  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003059 \n",
      "\n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.007343  [   32/  512]\n",
      "loss: 0.000096  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003254 \n",
      "\n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.010695  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.000687  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003281 \n",
      "\n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.000653  [   32/  512]\n",
      "loss: 0.003348  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003620 \n",
      "\n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.006897  [   32/  512]\n",
      "loss: 0.002979  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002977 \n",
      "\n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.002954  [   32/  512]\n",
      "loss: 0.007114  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002841 \n",
      "\n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.004977  [   32/  512]\n",
      "loss: 0.000077  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001992 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003048 \n",
      "\n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.001119  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003221 \n",
      "\n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.006237  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003454 \n",
      "\n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.002977  [   32/  512]\n",
      "loss: 0.011074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002480 \n",
      "\n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.000068  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004000 \n",
      "\n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.007032  [   32/  512]\n",
      "loss: 0.000850  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002295 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002275 \n",
      "\n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.009418  [   32/  512]\n",
      "loss: 0.000457  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003248 \n",
      "\n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.001568  [   32/  512]\n",
      "loss: 0.001414  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003220 \n",
      "\n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.000727  [   32/  512]\n",
      "loss: 0.000064  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002750 \n",
      "\n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.002503  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003103 \n",
      "\n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.000652  [   32/  512]\n",
      "loss: 0.000280  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003466 \n",
      "\n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.000058  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002608 \n",
      "\n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.000113  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002973 \n",
      "\n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.004648  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002816 \n",
      "\n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.000248  [   32/  512]\n",
      "loss: 0.004269  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003762 \n",
      "\n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.001280  [   32/  512]\n",
      "loss: 0.011427  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.000109  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003003 \n",
      "\n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002981 \n",
      "\n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.000930  [   32/  512]\n",
      "loss: 0.004735  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002962 \n",
      "\n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.001183  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002840 \n",
      "\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.001058  [   32/  512]\n",
      "loss: 0.000823  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002972 \n",
      "\n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.000046  [   32/  512]\n",
      "loss: 0.001083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002927 \n",
      "\n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.000175  [   32/  512]\n",
      "loss: 0.000423  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002828 \n",
      "\n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.002359  [   32/  512]\n",
      "loss: 0.002836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001621 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003190 \n",
      "\n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.010554  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002935 \n",
      "\n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.000949  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002992 \n",
      "\n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.002621  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003162 \n",
      "\n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.002033  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002960 \n",
      "\n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.004158  [   32/  512]\n",
      "loss: 0.000100  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.000967  [   32/  512]\n",
      "loss: 0.000205  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003308 \n",
      "\n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002840 \n",
      "\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.003823  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002502 \n",
      "\n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.000349  [   32/  512]\n",
      "loss: 0.007235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002025 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003255 \n",
      "\n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.003049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002341 \n",
      "\n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.014579  [   32/  512]\n",
      "loss: 0.000969  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004131 \n",
      "\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.000625  [   32/  512]\n",
      "loss: 0.003449  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002844 \n",
      "\n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.004039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003196 \n",
      "\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.001007  [   32/  512]\n",
      "loss: 0.007141  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002588 \n",
      "\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.000050  [   32/  512]\n",
      "loss: 0.007084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002824 \n",
      "\n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.000065  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002991 \n",
      "\n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.000836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002222 \n",
      "\n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.000081  [   32/  512]\n",
      "loss: 0.006968  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001741 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003245 \n",
      "\n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.004006  [   32/  512]\n",
      "loss: 0.000279  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002836 \n",
      "\n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001860 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002318 \n",
      "\n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.006989  [   32/  512]\n",
      "loss: 0.000547  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003072 \n",
      "\n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.002897  [   32/  512]\n",
      "loss: 0.000237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.003774  [   32/  512]\n",
      "loss: 0.000237  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002705 \n",
      "\n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.003599  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003302 \n",
      "\n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.002600  [   32/  512]\n",
      "loss: 0.004563  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002601 \n",
      "\n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002906 \n",
      "\n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000078  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.002692  [   32/  512]\n",
      "loss: 0.000007  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002813 \n",
      "\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.003607  [   32/  512]\n",
      "loss: 0.005635  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003392 \n",
      "\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.000182  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002587 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002443 \n",
      "\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.008622  [   32/  512]\n",
      "loss: 0.001055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003076 \n",
      "\n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.000097  [   32/  512]\n",
      "loss: 0.001026  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002867 \n",
      "\n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.005287  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002835 \n",
      "\n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.001948  [   32/  512]\n",
      "loss: 0.000254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002537 \n",
      "\n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002882 \n",
      "\n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.000191  [   32/  512]\n",
      "loss: 0.000930  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002879 \n",
      "\n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.000649  [   32/  512]\n",
      "loss: 0.017955  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002630 \n",
      "\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.002771  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004116 \n",
      "\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.000295  [   32/  512]\n",
      "loss: 0.000106  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002229 \n",
      "\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.004479  [   32/  512]\n",
      "loss: 0.000218  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002754 \n",
      "\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.002595  [   32/  512]\n",
      "loss: 0.000071  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002525 \n",
      "\n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002971 \n",
      "\n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002668 \n",
      "\n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.004498  [   32/  512]\n",
      "loss: 0.005671  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003070 \n",
      "\n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.003645  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002655 \n",
      "\n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000238  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002823 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002796 \n",
      "\n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.001907  [   32/  512]\n",
      "loss: 0.000191  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002338 \n",
      "\n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003620 \n",
      "\n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.000079  [   32/  512]\n",
      "loss: 0.005273  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002386 \n",
      "\n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.002579  [   32/  512]\n",
      "loss: 0.000190  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001627 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002732 \n",
      "\n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.001309  [   32/  512]\n",
      "loss: 0.000013  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003253 \n",
      "\n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.000031  [   32/  512]\n",
      "loss: 0.000015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002702 \n",
      "\n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002444 \n",
      "\n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.000375  [   32/  512]\n",
      "loss: 0.001939  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001734 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002933 \n",
      "\n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.000146  [   32/  512]\n",
      "loss: 0.007539  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002919 \n",
      "\n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.003046  [   32/  512]\n",
      "loss: 0.000535  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002876 \n",
      "\n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.000973  [   32/  512]\n",
      "loss: 0.011194  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003505 \n",
      "\n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002518 \n",
      "\n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.000160  [   32/  512]\n",
      "loss: 0.000062  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003003 \n",
      "\n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.000218  [   32/  512]\n",
      "loss: 0.000143  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002963 \n",
      "\n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.005580  [   32/  512]\n",
      "loss: 0.003361  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003148 \n",
      "\n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.000180  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.003346  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003195 \n",
      "\n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.006277  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002865 \n",
      "\n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.004792  [   32/  512]\n",
      "loss: 0.000083  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003141 \n",
      "\n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.004450  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002921 \n",
      "\n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.004649  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002761 \n",
      "\n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.004857  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002602 \n",
      "\n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002805 \n",
      "\n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.002786  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002844 \n",
      "\n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.000025  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002596 \n",
      "\n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.005286  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002768 \n",
      "\n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.004879  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003349 \n",
      "\n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.000231  [   32/  512]\n",
      "loss: 0.000326  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002366 \n",
      "\n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.004653  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002988 \n",
      "\n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.000049  [   32/  512]\n",
      "loss: 0.000131  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.000276  [   32/  512]\n",
      "loss: 0.000417  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002102 \n",
      "\n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003433 \n",
      "\n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000057  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002716 \n",
      "\n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.000358  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001565 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003082 \n",
      "\n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.000097  [   32/  512]\n",
      "loss: 0.005609  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.000178  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002518 \n",
      "\n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.002313  [   32/  512]\n",
      "loss: 0.003254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002603 \n",
      "\n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.000491  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002707 \n",
      "\n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.005115  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002540 \n",
      "\n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.000069  [   32/  512]\n",
      "loss: 0.004751  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003023 \n",
      "\n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002543 \n",
      "\n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.004612  [   32/  512]\n",
      "loss: 0.000972  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.000216  [   32/  512]\n",
      "loss: 0.000059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002897 \n",
      "\n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.005940  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002353 \n",
      "\n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003076 \n",
      "\n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.000372  [   32/  512]\n",
      "loss: 0.005705  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002649 \n",
      "\n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.002953  [   32/  512]\n",
      "loss: 0.000991  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002372 \n",
      "\n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.005905  [   32/  512]\n",
      "loss: 0.000154  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001437 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003042 \n",
      "\n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.001771  [   32/  512]\n",
      "loss: 0.000177  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002512 \n",
      "\n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.000151  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002274 \n",
      "\n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.002143  [   32/  512]\n",
      "loss: 0.000031  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002820 \n",
      "\n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.007808  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002618 \n",
      "\n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.000066  [   32/  512]\n",
      "loss: 0.006119  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002437 \n",
      "\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.000186  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003043 \n",
      "\n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.000108  [   32/  512]\n",
      "loss: 0.000258  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001334 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002388 \n",
      "\n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.005048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002572 \n",
      "\n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.000091  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.000295  [   32/  512]\n",
      "loss: 0.000318  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003264 \n",
      "\n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.002696  [   32/  512]\n",
      "loss: 0.000836  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002624 \n",
      "\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.000290  [   32/  512]\n",
      "loss: 0.016493  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003056 \n",
      "\n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.000159  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002753 \n",
      "\n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.000048  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002443 \n",
      "\n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.003394  [   32/  512]\n",
      "loss: 0.000101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002571 \n",
      "\n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.001696  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001830 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003200 \n",
      "\n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.000207  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002274 \n",
      "\n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.001187  [   32/  512]\n",
      "loss: 0.000602  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002520 \n",
      "\n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002696 \n",
      "\n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.003780  [   32/  512]\n",
      "loss: 0.000235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002876 \n",
      "\n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.001067  [   32/  512]\n",
      "loss: 0.002526  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001557 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002570 \n",
      "\n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.001080  [   32/  512]\n",
      "loss: 0.002438  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002838 \n",
      "\n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.000122  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002194 \n",
      "\n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002855 \n",
      "\n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.000962  [   32/  512]\n",
      "loss: 0.007834  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002519 \n",
      "\n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.000038  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002471 \n",
      "\n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.002152  [   32/  512]\n",
      "loss: 0.002140  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.008517  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002088 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002812 \n",
      "\n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.000210  [   32/  512]\n",
      "loss: 0.002193  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002503 \n",
      "\n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.000207  [   32/  512]\n",
      "loss: 0.000774  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002761 \n",
      "\n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.004320  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002915 \n",
      "\n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.000380  [   32/  512]\n",
      "loss: 0.000206  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002924 \n",
      "\n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000451  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002461 \n",
      "\n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.001727  [   32/  512]\n",
      "loss: 0.010482  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001721 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002887 \n",
      "\n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.004763  [   32/  512]\n",
      "loss: 0.011040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002665 \n",
      "\n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.000138  [   32/  512]\n",
      "loss: 0.010816  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002319 \n",
      "\n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.000167  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002638 \n",
      "\n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002450 \n",
      "\n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.003784  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001254 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002321 \n",
      "\n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.003997  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002563 \n",
      "\n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002411 \n",
      "\n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.000103  [   32/  512]\n",
      "loss: 0.000092  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002311 \n",
      "\n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002727 \n",
      "\n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.000132  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002414 \n",
      "\n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002717  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.002475  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002773 \n",
      "\n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.005146  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002256 \n",
      "\n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.000500  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003403 \n",
      "\n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.000205  [   32/  512]\n",
      "loss: 0.000056  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.000052  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002267 \n",
      "\n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.000162  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003265 \n",
      "\n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.000130  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002477 \n",
      "\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.000058  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002641 \n",
      "\n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.000278  [   32/  512]\n",
      "loss: 0.000352  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002615 \n",
      "\n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.000502  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002715 \n",
      "\n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.002557  [   32/  512]\n",
      "loss: 0.000073  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002854 \n",
      "\n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.003041  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001421 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002332 \n",
      "\n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.004218  [   32/  512]\n",
      "loss: 0.001067  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002522 \n",
      "\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002578 \n",
      "\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.000096  [   32/  512]\n",
      "loss: 0.000169  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002264 \n",
      "\n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.000146  [   32/  512]\n",
      "loss: 0.000639  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002477 \n",
      "\n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.000184  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003077 \n",
      "\n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.002389  [   32/  512]\n",
      "loss: 0.002081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002323 \n",
      "\n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.000202  [   32/  512]\n",
      "loss: 0.000197  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002331 \n",
      "\n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003231 \n",
      "\n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.000096  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002551 \n",
      "\n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.004026  [   32/  512]\n",
      "loss: 0.005047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002795 \n",
      "\n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.002965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002385 \n",
      "\n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000050  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002468 \n",
      "\n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.004385  [   32/  512]\n",
      "loss: 0.006570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002410 \n",
      "\n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.004656  [   32/  512]\n",
      "loss: 0.002015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002309 \n",
      "\n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002832 \n",
      "\n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002271 \n",
      "\n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.003855  [   32/  512]\n",
      "loss: 0.000105  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002734 \n",
      "\n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.001467  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.003903  [   32/  512]\n",
      "loss: 0.001094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002263 \n",
      "\n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000040  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002916 \n",
      "\n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.000220  [   32/  512]\n",
      "loss: 0.000263  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.002044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002897 \n",
      "\n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.000411  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002190 \n",
      "\n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.003367  [   32/  512]\n",
      "loss: 0.004518  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002950 \n",
      "\n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000183  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.002229  [   32/  512]\n",
      "loss: 0.000097  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.000250  [   32/  512]\n",
      "loss: 0.000282  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002485 \n",
      "\n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.000117  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002899 \n",
      "\n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.001934  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002197 \n",
      "\n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.001036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001343 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000174  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002357 \n",
      "\n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.002155  [   32/  512]\n",
      "loss: 0.001641  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002692 \n",
      "\n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.000182  [   32/  512]\n",
      "loss: 0.000132  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001617 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002249 \n",
      "\n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.003864  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002651 \n",
      "\n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.001618  [   32/  512]\n",
      "loss: 0.000775  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002290 \n",
      "\n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.001445  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002488 \n",
      "\n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.000869  [   32/  512]\n",
      "loss: 0.003158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002091 \n",
      "\n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.000201  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002556 \n",
      "\n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.008570  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002286 \n",
      "\n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.000030  [   32/  512]\n",
      "loss: 0.000454  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002362 \n",
      "\n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.003606  [   32/  512]\n",
      "loss: 0.000123  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003155 \n",
      "\n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.004144  [   32/  512]\n",
      "loss: 0.000091  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002442 \n",
      "\n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.000219  [   32/  512]\n",
      "loss: 0.000152  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002517 \n",
      "\n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002168 \n",
      "\n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000967  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002401 \n",
      "\n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.000193  [   32/  512]\n",
      "loss: 0.000199  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002121 \n",
      "\n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.000037  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002632 \n",
      "\n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.000140  [   32/  512]\n",
      "loss: 0.001764  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001318 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002292 \n",
      "\n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.000031  [   32/  512]\n",
      "loss: 0.008438  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002279 \n",
      "\n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.000112  [   32/  512]\n",
      "loss: 0.000451  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002392 \n",
      "\n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.001217  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002686 \n",
      "\n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.002324  [   32/  512]\n",
      "loss: 0.000089  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002636 \n",
      "\n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.001470  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003929 \n",
      "\n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.000197  [   32/  512]\n",
      "loss: 0.005075  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001973 \n",
      "\n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.001162  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002296 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003321 \n",
      "\n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000059  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002616 \n",
      "\n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002502 \n",
      "\n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002529 \n",
      "\n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.000397  [   32/  512]\n",
      "loss: 0.002481  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003329 \n",
      "\n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002128 \n",
      "\n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.000816  [   32/  512]\n",
      "loss: 0.000044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002224 \n",
      "\n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.003337  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002459 \n",
      "\n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.000513  [   32/  512]\n",
      "loss: 0.002948  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002327 \n",
      "\n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.000140  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002429 \n",
      "\n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002307 \n",
      "\n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.010158  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002432 \n",
      "\n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.000098  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002051 \n",
      "\n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002067 \n",
      "\n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.000105  [   32/  512]\n",
      "loss: 0.003803  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002093 \n",
      "\n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.000043  [   32/  512]\n",
      "loss: 0.000044  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002448 \n",
      "\n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.001935  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002604 \n",
      "\n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.001158  [   32/  512]\n",
      "loss: 0.000125  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002234 \n",
      "\n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.002763  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002953 \n",
      "\n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.000119  [   32/  512]\n",
      "loss: 0.000962  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002216 \n",
      "\n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.002397  [   32/  512]\n",
      "loss: 0.000074  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002624 \n",
      "\n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002168 \n",
      "\n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.006867  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002748 \n",
      "\n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.002863  [   32/  512]\n",
      "loss: 0.000225  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002405 \n",
      "\n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.001646  [   32/  512]\n",
      "loss: 0.000776  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002248 \n",
      "\n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.000165  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000980 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002530 \n",
      "\n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.000183  [   32/  512]\n",
      "loss: 0.010580  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002658 \n",
      "\n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.000493  [   32/  512]\n",
      "loss: 0.005280  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002834 \n",
      "\n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.000209  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.006209  [   32/  512]\n",
      "loss: 0.000346  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003425 \n",
      "\n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.010927  [   32/  512]\n",
      "loss: 0.000202  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002548 \n",
      "\n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.000160  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003063 \n",
      "\n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.002254  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002078 \n",
      "\n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.004241  [   32/  512]\n",
      "loss: 0.001232  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001738 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002314 \n",
      "\n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.002524  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002240 \n",
      "\n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002180 \n",
      "\n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.005056  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002702  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.007942  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002449 \n",
      "\n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002231 \n",
      "\n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.000077  [   32/  512]\n",
      "loss: 0.007014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002612 \n",
      "\n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.007601  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002070 \n",
      "\n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002353 \n",
      "\n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.002761  [   32/  512]\n",
      "loss: 0.004266  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002359 \n",
      "\n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.000149  [   32/  512]\n",
      "loss: 0.006518  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000824  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002240 \n",
      "\n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.000057  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002381 \n",
      "\n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.013993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002269 \n",
      "\n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.000671  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002508 \n",
      "\n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.000044  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001192 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.003147  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002220 \n",
      "\n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.009003  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001170 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002171 \n",
      "\n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000284  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002449 \n",
      "\n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.000023  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002582 \n",
      "\n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000967  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001306 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002219 \n",
      "\n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.001168  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002661 \n",
      "\n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.000599  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.004832  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002249 \n",
      "\n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.001375  [   32/  512]\n",
      "loss: 0.003491  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002319 \n",
      "\n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.002525  [   32/  512]\n",
      "loss: 0.000018  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002241 \n",
      "\n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002076 \n",
      "\n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.000144  [   32/  512]\n",
      "loss: 0.004760  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002588 \n",
      "\n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.000170  [   32/  512]\n",
      "loss: 0.006490  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002276 \n",
      "\n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.006177  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.004890  [   32/  512]\n",
      "loss: 0.002793  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002283 \n",
      "\n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000201  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002234 \n",
      "\n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002344 \n",
      "\n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.000176  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001252 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002281 \n",
      "\n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000257  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001291 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002619 \n",
      "\n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.001080  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001138 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002294 \n",
      "\n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002211 \n",
      "\n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.003973  [   32/  512]\n",
      "loss: 0.009651  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002450 \n",
      "\n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002333 \n",
      "\n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.003501  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001261 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002265 \n",
      "\n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.000019  [   32/  512]\n",
      "loss: 0.002953  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000953 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002160 \n",
      "\n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.008517  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002243 \n",
      "\n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.003217  [   32/  512]\n",
      "loss: 0.000016  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002265 \n",
      "\n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.000283  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000095  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002447 \n",
      "\n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.004044  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002263 \n",
      "\n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000400  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002403 \n",
      "\n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002196 \n",
      "\n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.000100  [   32/  512]\n",
      "loss: 0.000055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002233 \n",
      "\n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.004700  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002176 \n",
      "\n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.000292  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001155 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002314 \n",
      "\n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.001468  [   32/  512]\n",
      "loss: 0.004556  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002228 \n",
      "\n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.000070  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002088 \n",
      "\n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002521 \n",
      "\n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000010  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002054 \n",
      "\n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.000092  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002440 \n",
      "\n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.000029  [   32/  512]\n",
      "loss: 0.001000  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002294 \n",
      "\n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.007232  [   32/  512]\n",
      "loss: 0.007552  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002178 \n",
      "\n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.000008  [   32/  512]\n",
      "loss: 0.000014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002255 \n",
      "\n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002344 \n",
      "\n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.001050  [   32/  512]\n",
      "loss: 0.009519  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002164 \n",
      "\n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.000016  [   32/  512]\n",
      "loss: 0.000090  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002130 \n",
      "\n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.002356  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001342 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002196 \n",
      "\n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.002491  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002226 \n",
      "\n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.000492  [   32/  512]\n",
      "loss: 0.002648  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000989 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002374 \n",
      "\n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.001658  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002214 \n",
      "\n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002261 \n",
      "\n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.004363  [   32/  512]\n",
      "loss: 0.000107  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.000043  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002345 \n",
      "\n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000091  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002312 \n",
      "\n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.001325  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002318 \n",
      "\n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000148  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002242 \n",
      "\n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.000101  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002253 \n",
      "\n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.000066  [   32/  512]\n",
      "loss: 0.003784  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002415 \n",
      "\n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002527 \n",
      "\n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.002221  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002381 \n",
      "\n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.005735  [   32/  512]\n",
      "loss: 0.000108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002342 \n",
      "\n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.000033  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002349 \n",
      "\n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.001404  [   32/  512]\n",
      "loss: 0.007687  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002202 \n",
      "\n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.012965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002390 \n",
      "\n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.000072  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002341 \n",
      "\n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.000125  [   32/  512]\n",
      "loss: 0.000113  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002288 \n",
      "\n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.000048  [   32/  512]\n",
      "loss: 0.002313  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002324 \n",
      "\n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.000062  [   32/  512]\n",
      "loss: 0.000106  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002375 \n",
      "\n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.004561  [   32/  512]\n",
      "loss: 0.001957  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002193 \n",
      "\n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000056  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002284 \n",
      "\n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.004231  [   32/  512]\n",
      "loss: 0.000291  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002647 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003025 \n",
      "\n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002296 \n",
      "\n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002595 \n",
      "\n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000076  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002267 \n",
      "\n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.002993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002271 \n",
      "\n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.000060  [   32/  512]\n",
      "loss: 0.000049  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002569 \n",
      "\n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.000130  [   32/  512]\n",
      "loss: 0.007409  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002608 \n",
      "\n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.002782  [   32/  512]\n",
      "loss: 0.003171  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002369 \n",
      "\n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000357  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002637 \n",
      "\n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.000312  [   32/  512]\n",
      "loss: 0.001085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002651 \n",
      "\n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.000875  [   32/  512]\n",
      "loss: 0.000176  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002714 \n",
      "\n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.000525  [   32/  512]\n",
      "loss: 0.005868  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002215 \n",
      "\n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000023  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002247 \n",
      "\n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.004192  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002316 \n",
      "\n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.005749  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002428 \n",
      "\n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.000910  [   32/  512]\n",
      "loss: 0.000748  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002384 \n",
      "\n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.000098  [   32/  512]\n",
      "loss: 0.001606  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002418 \n",
      "\n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.000090  [   32/  512]\n",
      "loss: 0.000051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002468 \n",
      "\n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.000137  [   32/  512]\n",
      "loss: 0.009391  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002358 \n",
      "\n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.005183  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002545 \n",
      "\n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002367 \n",
      "\n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.002261  [   32/  512]\n",
      "loss: 0.012603  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002478 \n",
      "\n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.000019  [   32/  512]\n",
      "loss: 0.001757  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002360 \n",
      "\n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.000382  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002402 \n",
      "\n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.003557  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001272 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002383 \n",
      "\n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.001444  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001131 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002356 \n",
      "\n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.000064  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002553 \n",
      "\n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.000076  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002326 \n",
      "\n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.000004  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002226 \n",
      "\n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.000467  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002782 \n",
      "\n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.000086  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001864 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002348 \n",
      "\n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.000220  [   32/  512]\n",
      "loss: 0.019333  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002278 \n",
      "\n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.012722  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002366 \n",
      "\n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.000054  [   32/  512]\n",
      "loss: 0.001702  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000971 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002419 \n",
      "\n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002373 \n",
      "\n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.001123  [   32/  512]\n",
      "loss: 0.003823  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004106 \n",
      "\n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002352 \n",
      "\n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.009306  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001566 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002392 \n",
      "\n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.002580  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002536 \n",
      "\n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.000331  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002331 \n",
      "\n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.000158  [   32/  512]\n",
      "loss: 0.000068  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002441 \n",
      "\n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.000670  [   32/  512]\n",
      "loss: 0.000099  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000925 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002178 \n",
      "\n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000144  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002393 \n",
      "\n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.000283  [   32/  512]\n",
      "loss: 0.010993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002455 \n",
      "\n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.003027  [   32/  512]\n",
      "loss: 0.000048  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002423 \n",
      "\n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.000136  [   32/  512]\n",
      "loss: 0.000115  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002692 \n",
      "\n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.000716  [   32/  512]\n",
      "loss: 0.000077  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002428 \n",
      "\n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.000078  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002445 \n",
      "\n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.003116  [   32/  512]\n",
      "loss: 0.003149  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002323 \n",
      "\n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.000988  [   32/  512]\n",
      "loss: 0.000093  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002791 \n",
      "\n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.000128  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002332 \n",
      "\n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.000046  [   32/  512]\n",
      "loss: 0.001391  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002684 \n",
      "\n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000013  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000803  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002320 \n",
      "\n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002500 \n",
      "\n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.000749  [   32/  512]\n",
      "loss: 0.000073  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002497 \n",
      "\n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.000250  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002289 \n",
      "\n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.000006  [   32/  512]\n",
      "loss: 0.008786  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002688 \n",
      "\n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000103  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002333 \n",
      "\n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.009540  [   32/  512]\n",
      "loss: 0.000126  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002726 \n",
      "\n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.000120  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002600 \n",
      "\n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.001525  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.000171  [   32/  512]\n",
      "loss: 0.003727  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002505 \n",
      "\n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.006013  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002327 \n",
      "\n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.000095  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002462 \n",
      "\n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.000424  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002379 \n",
      "\n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.000505  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002478 \n",
      "\n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.002110  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.000729  [   32/  512]\n",
      "loss: 0.000011  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002322 \n",
      "\n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.000091  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002527 \n",
      "\n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000062  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002801 \n",
      "\n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.003285  [   32/  512]\n",
      "loss: 0.000238  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.003508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004958 \n",
      "\n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.000131  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002458 \n",
      "\n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.000148  [   32/  512]\n",
      "loss: 0.000063  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002875 \n",
      "\n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.000079  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002280 \n",
      "\n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002387 \n",
      "\n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.007213  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002417 \n",
      "\n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.000084  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002454 \n",
      "\n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.000423  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002355 \n",
      "\n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.000026  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002573 \n",
      "\n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.007507  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002316 \n",
      "\n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.005166  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002398 \n",
      "\n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.000024  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002407 \n",
      "\n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.000087  [   32/  512]\n",
      "loss: 0.000045  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002670 \n",
      "\n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.000178  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002732 \n",
      "\n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.000154  [   32/  512]\n",
      "loss: 0.000155  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002305 \n",
      "\n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.000236  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002759 \n",
      "\n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.000064  [   32/  512]\n",
      "loss: 0.000325  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002499 \n",
      "\n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.000267  [   32/  512]\n",
      "loss: 0.003051  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002457 \n",
      "\n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.000082  [   32/  512]\n",
      "loss: 0.001829  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002592 \n",
      "\n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000134  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002589 \n",
      "\n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.001879  [   32/  512]\n",
      "loss: 0.000299  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.000035  [   32/  512]\n",
      "loss: 0.003381  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002522 \n",
      "\n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.001997  [   32/  512]\n",
      "loss: 0.000017  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002308 \n",
      "\n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.001696  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002699 \n",
      "\n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.001522  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002599 \n",
      "\n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002406 \n",
      "\n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002416 \n",
      "\n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.002965  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002558 \n",
      "\n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.003095  [   32/  512]\n",
      "loss: 0.003738  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002532 \n",
      "\n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.002041  [   32/  512]\n",
      "loss: 0.000112  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002512 \n",
      "\n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.000149  [   32/  512]\n",
      "loss: 0.000088  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002550 \n",
      "\n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.000071  [   32/  512]\n",
      "loss: 0.000033  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000955 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002485 \n",
      "\n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.001127  [   32/  512]\n",
      "loss: 0.003404  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002657 \n",
      "\n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.000049  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002409 \n",
      "\n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.000009  [   32/  512]\n",
      "loss: 0.000008  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002705 \n",
      "\n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.000021  [   32/  512]\n",
      "loss: 0.001219  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002551 \n",
      "\n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.009353  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002247 \n",
      "\n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000231  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002655 \n",
      "\n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.000371  [   32/  512]\n",
      "loss: 0.005474  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001214 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002696 \n",
      "\n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.000219  [   32/  512]\n",
      "loss: 0.000149  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000994 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002671 \n",
      "\n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.000463  [   32/  512]\n",
      "loss: 0.000034  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002461 \n",
      "\n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000080  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002609 \n",
      "\n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.000221  [   32/  512]\n",
      "loss: 0.007211  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.000068  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002650 \n",
      "\n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.000107  [   32/  512]\n",
      "loss: 0.000079  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002606 \n",
      "\n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.000069  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002650 \n",
      "\n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.000109  [   32/  512]\n",
      "loss: 0.000065  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002613 \n",
      "\n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.000070  [   32/  512]\n",
      "loss: 0.000085  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002666 \n",
      "\n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.000138  [   32/  512]\n",
      "loss: 0.009898  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002603 \n",
      "\n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.000018  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002368 \n",
      "\n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.005192  [   32/  512]\n",
      "loss: 0.000081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002666 \n",
      "\n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.000114  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002543 \n",
      "\n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.000083  [   32/  512]\n",
      "loss: 0.000235  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002804 \n",
      "\n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.000287  [   32/  512]\n",
      "loss: 0.000084  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002865 \n",
      "\n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.000186  [   32/  512]\n",
      "loss: 0.000221  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002639 \n",
      "\n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.000050  [   32/  512]\n",
      "loss: 0.000041  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002467 \n",
      "\n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.003051  [   32/  512]\n",
      "loss: 0.002030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002802 \n",
      "\n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000145  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002465 \n",
      "\n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000042  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001111 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002534 \n",
      "\n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.007150  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002587 \n",
      "\n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.000080  [   32/  512]\n",
      "loss: 0.001639  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002701 \n",
      "\n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.002351  [   32/  512]\n",
      "loss: 0.000066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002673 \n",
      "\n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.000055  [   32/  512]\n",
      "loss: 0.000029  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002704 \n",
      "\n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.000015  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.003827  [   32/  512]\n",
      "loss: 0.000354  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.001801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003645 \n",
      "\n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.014025  [   32/  512]\n",
      "loss: 0.017503  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.003172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002538 \n",
      "\n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.006959  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001779 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003204 \n",
      "\n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.004426  [   32/  512]\n",
      "loss: 0.000035  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002954 \n",
      "\n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.000223  [   32/  512]\n",
      "loss: 0.000993  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002850 \n",
      "\n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.006251  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002496 \n",
      "\n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.002018  [   32/  512]\n",
      "loss: 0.000047  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002612 \n",
      "\n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.000045  [   32/  512]\n",
      "loss: 0.000054  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002510 \n",
      "\n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.000057  [   32/  512]\n",
      "loss: 0.000124  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002754 \n",
      "\n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.003334  [   32/  512]\n",
      "loss: 0.002224  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002804 \n",
      "\n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.000105  [   32/  512]\n",
      "loss: 0.003557  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002565 \n",
      "\n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.003331  [   32/  512]\n",
      "loss: 0.000031  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002670 \n",
      "\n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.001317  [   32/  512]\n",
      "loss: 0.000101  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002661 \n",
      "\n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.000033  [   32/  512]\n",
      "loss: 0.001306  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002639 \n",
      "\n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.000014  [   32/  512]\n",
      "loss: 0.006022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002868 \n",
      "\n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.001074  [   32/  512]\n",
      "loss: 0.000028  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002631 \n",
      "\n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.000040  [   32/  512]\n",
      "loss: 0.000053  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002711 \n",
      "\n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.000073  [   32/  512]\n",
      "loss: 0.001160  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002662 \n",
      "\n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.000013  [   32/  512]\n",
      "loss: 0.002308  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002740 \n",
      "\n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.000037  [   32/  512]\n",
      "loss: 0.000070  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002653 \n",
      "\n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.000042  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002656 \n",
      "\n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.002984  [   32/  512]\n",
      "loss: 0.001055  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002691 \n",
      "\n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.000649  [   32/  512]\n",
      "loss: 0.004999  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002749 \n",
      "\n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.000875  [   32/  512]\n",
      "loss: 0.000285  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002877 \n",
      "\n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.000476  [   32/  512]\n",
      "loss: 0.003066  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002687 \n",
      "\n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.000028  [   32/  512]\n",
      "loss: 0.000060  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002940 \n",
      "\n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.000114  [   32/  512]\n",
      "loss: 0.000030  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002673 \n",
      "\n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.000015  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002728 \n",
      "\n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.000012  [   32/  512]\n",
      "loss: 0.005821  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002774 \n",
      "\n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.001447  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002486 \n",
      "\n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.000041  [   32/  512]\n",
      "loss: 0.000052  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002845 \n",
      "\n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.000159  [   32/  512]\n",
      "loss: 0.000006  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002868 \n",
      "\n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.000007  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002837 \n",
      "\n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.000053  [   32/  512]\n",
      "loss: 0.000022  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002784 \n",
      "\n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.000104  [   32/  512]\n",
      "loss: 0.003512  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002653 \n",
      "\n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.002739  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002628 \n",
      "\n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.000157  [   32/  512]\n",
      "loss: 0.000005  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002695 \n",
      "\n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000037  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002713 \n",
      "\n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.000017  [   32/  512]\n",
      "loss: 0.000076  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002822 \n",
      "\n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.000056  [   32/  512]\n",
      "loss: 0.007071  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002733 \n",
      "\n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.000034  [   32/  512]\n",
      "loss: 0.001818  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002766 \n",
      "\n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.000085  [   32/  512]\n",
      "loss: 0.003769  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002815 \n",
      "\n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.002770  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002542 \n",
      "\n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.001920  [   32/  512]\n",
      "loss: 0.009448  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002722 \n",
      "\n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.000022  [   32/  512]\n",
      "loss: 0.003496  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002721 \n",
      "\n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000020  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002825 \n",
      "\n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.000039  [   32/  512]\n",
      "loss: 0.001171  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002809 \n",
      "\n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.002203  [   32/  512]\n",
      "loss: 0.000108  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002835 \n",
      "\n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.000741  [   32/  512]\n",
      "loss: 0.000036  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002767 \n",
      "\n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.007560  [   32/  512]\n",
      "loss: 0.000046  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002585 \n",
      "\n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.000061  [   32/  512]\n",
      "loss: 0.000039  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003134 \n",
      "\n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.001366  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002774 \n",
      "\n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.000116  [   32/  512]\n",
      "loss: 0.003964  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002411 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002900 \n",
      "\n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.000187  [   32/  512]\n",
      "loss: 0.000143  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003247 \n",
      "\n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.000063  [   32/  512]\n",
      "loss: 0.000081  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002964 \n",
      "\n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.000320  [   32/  512]\n",
      "loss: 0.005012  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002694 \n",
      "\n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.000133  [   32/  512]\n",
      "loss: 0.000174  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002777 \n",
      "\n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.000731  [   32/  512]\n",
      "loss: 0.000025  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002770 \n",
      "\n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.000032  [   32/  512]\n",
      "loss: 0.000024  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002961 \n",
      "\n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.000707  [   32/  512]\n",
      "loss: 0.000061  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002679 \n",
      "\n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.000010  [   32/  512]\n",
      "loss: 0.000009  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003004 \n",
      "\n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.000047  [   32/  512]\n",
      "loss: 0.004006  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002756 \n",
      "\n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.000065  [   32/  512]\n",
      "loss: 0.000021  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002640 \n",
      "\n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.002456  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002925 \n",
      "\n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.000036  [   32/  512]\n",
      "loss: 0.000027  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003022 \n",
      "\n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.000056  [   32/  512]\n",
      "loss: 0.000038  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003015 \n",
      "\n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.000089  [   32/  512]\n",
      "loss: 0.000102  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002764 \n",
      "\n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.003381  [   32/  512]\n",
      "loss: 0.000043  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003002 \n",
      "\n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.000277  [   32/  512]\n",
      "loss: 0.000354  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003107 \n",
      "\n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.000059  [   32/  512]\n",
      "loss: 0.000121  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001435 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003170 \n",
      "\n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.000958  [   32/  512]\n",
      "loss: 0.000150  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002883 \n",
      "\n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.000270  [   32/  512]\n",
      "loss: 0.006014  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003143 \n",
      "\n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.002939  [   32/  512]\n",
      "loss: 0.000094  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003158 \n",
      "\n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.000051  [   32/  512]\n",
      "loss: 0.000075  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003200 \n",
      "\n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.000020  [   32/  512]\n",
      "loss: 0.000032  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.001607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002846 \n",
      "\n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.000044  [   32/  512]\n",
      "loss: 0.000019  [  288/  512]\n",
      "\n",
      "Training Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003049 \n",
      "\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 1000 # poner mas\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss, accuracy = train_loop(dataloader, model, loss_fn, optimizer)\n",
    "    print(f\"\\nTraining Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {loss:>8f} \\n\")\n",
    "    \n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3920, -2.2971]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.3600],\n",
       "        [0.6200],\n",
       "        [0.8800],\n",
       "        [1.1400],\n",
       "        [1.4000],\n",
       "        [1.6600],\n",
       "        [1.9200],\n",
       "        [2.1800],\n",
       "        [2.4400],\n",
       "        [2.7000],\n",
       "        [2.9600],\n",
       "        [3.2200],\n",
       "        [3.4800],\n",
       "        [3.7400],\n",
       "        [4.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_test = torch.tensor(np.linspace(0.1, 4, 16).reshape((-1, 1)), dtype=torch.float64)\n",
    "u_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora probamos como funciona para un x nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5031e-06, 5.2914e-06],\n",
       "        [5.8791e-06, 5.0125e-06],\n",
       "        [6.2946e-06, 4.1114e-06],\n",
       "        [1.5288e-05, 6.1703e-06],\n",
       "        [6.3201e-05, 7.6848e-06],\n",
       "        [2.8571e+00, 7.7249e-06],\n",
       "        [2.4096e+00, 8.3817e-06],\n",
       "        [2.0833e+00, 1.4402e-05],\n",
       "        [1.8349e+00, 1.8074e+00],\n",
       "        [1.6393e+00, 2.2303e+00],\n",
       "        [6.9978e-05, 3.3749e+00],\n",
       "        [1.2749e-05, 3.7000e+00],\n",
       "        [6.8515e-06, 4.0250e+00],\n",
       "        [1.1909e-05, 1.8498e-05],\n",
       "        [2.2888e-04, 1.3794e-05],\n",
       "        [9.9999e-01, 1.9565e-05]], dtype=torch.float64)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u_test])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametricLPNet(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500]], dtype=torch.float64),\n",
       " tensor([[5.6596e-06, 5.1630e-06]], dtype=torch.float64))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([[0.25]], dtype=torch.float64)\n",
    "x = torch.cat([io.linprog(*plp_true(ui)).detach().t() for ui in u])\n",
    "u,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[0.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = model(torch.tensor([[0.25]]))\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.6596e-06, 5.1630e-06]], dtype=torch.float64),\n",
       " tensor([[-0.9870, -0.9380]], grad_fn=<StackBackward0>),\n",
       " tensor(1.3617, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x_pred, torch.norm(x - x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar:\n",
    "- Funci√≥n de p√©rdida ‚úîÔ∏è\n",
    "- Funci√≥n smooth_lp (a ver si puedo sustituir la funcion smooth_lp por la funcion de linprog de deep_inv_opt)\n",
    "- Organizar y explicar el c√≥digo\n",
    "- Estudiar por qu√© no disminuye el loss cuando entreno el modelo: es porque est√° mostrando el loss en el conjunto de test y no en el de entrenamiento ‚úîÔ∏è\n",
    "- Entrenar el modelo con m√°s √©pocas y datos\n",
    "- Pensar qu√© optimizador es mejor ‚úîÔ∏è\n",
    "- Pensar qu√© estructura de la red es mejor ‚úîÔ∏è\n",
    "- Inicializaci√≥n de los pesos de la red ‚úîÔ∏è\n",
    "- Arreglar el porcentaje de aciertos ‚úîÔ∏è\n",
    "\n",
    "\n",
    "\n",
    "Bit√°cora: ahora lo que pasa es que da error porque el problema de optimizaci√≥n no est√° acotado, lo que tengo que hacer es revisar en el paper el intervalo donde se mueve la u porque creo que lo he puesto mal. Cuando arregle esto, tengo que volver a entrenar el modelo y ver si se est√° entrenando bien. Tambi√©n tengo que probar resolviendo el problema de optimizaci√≥n con la funci√≥n de linprog de deep_inv_opt y con la de cvxpy a ver si alguna de las dos funciona mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
